[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biostatistics",
    "section": "",
    "text": "Welcome to the website of the course “Biostatistics” of the master’s programme “Translational Neuroscience” of the Julius-Maximilians-University Würzburg.\nPlease use the navigation on the left to select the slides for each session (recommendation: Open in new tab).\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport"
  },
  {
    "objectID": "W1_Intro.html#hello",
    "href": "W1_Intro.html#hello",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Who am I?\n. . .\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?\n\n\n\nSurvey (Zoom) + Moodmeter (pick a stamp - top of screen, select annotate…)\nToo many people to have an introduction round!\nI know that you probably don’t know each other yet, there will be some break-out sessions where you can get to know each other a bit (and talk about stats!) ;)\nStats Anxiety: It will be packed, but it will be ok (You can always reach me with questions!)!"
  },
  {
    "objectID": "W1_Intro.html#using-the-slides",
    "href": "W1_Intro.html#using-the-slides",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "These slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\""
  },
  {
    "objectID": "W1_Intro.html#organizational-issues",
    "href": "W1_Intro.html#organizational-issues",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": ". . .\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n. . .\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is an option via Zoom\n\n\n. . .\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked in WueCampus):\n\nStatistical Thinking for the 21st Century: https://statsthinking21.github.io/statsthinking21-core-site/index.html\nFor the R part: Fundamentals of Quantitative Analysis: https://psyteachr.github.io/quant-fun-v2/\n\n\n\n\nOnline: Participation, videos, chat…\nOr R Session on Tuesday and video before? Some can’t make it on Wednesdays… (chat or speak out)\nAttendance: If 2x per week sync: max. 3 missed classes, if 1x per week: max. 2 missed classes (unless I know your reasons for missing Wednesdays!) –&gt; if you missed more, I can’t admit you for the exam/report\nThe input and hands-on sessions will be highly based on these two textbooks. You don’t need to read the textbooks, but it will of course help if you either read the chapter before or after the sessions: Repetition is always helpful!"
  },
  {
    "objectID": "W1_Intro.html#contents",
    "href": "W1_Intro.html#contents",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "From basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset (exam with pass or fail grading)\n\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy –&gt; so that you can go through the slides afterwards again (but textbook might also be helpful)"
  },
  {
    "objectID": "W1_Intro.html#project",
    "href": "W1_Intro.html#project",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": ". . .\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n. . .\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long."
  },
  {
    "objectID": "W1_Intro.html#calender",
    "href": "W1_Intro.html#calender",
    "title": "01a Introduction to Biostatistics",
    "section": "Calender",
    "text": "Calender\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport\n\n\n\n\n\nThe first four weeks will be basics, the next 4 will be analyses.\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)"
  },
  {
    "objectID": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "href": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is it important that YOU know statistics?",
    "text": "Why is it important that YOU know statistics?\n\n\nYou’re doing a research master!\n\nResearch = Reading & understanding papers (esp. the analyses)\nDesigning your own experiments, analyze data, interpret results\n\nWe live in an increasingly data-centric world\n\nKnowing how to wrangle and analyze data is a valuable skill\n\nFacts & data literacy matter more than ever!\n\nFake News, “Lying with stats”, Reproducibility Crisis\nBeing able to call bullshit (https://www.callingbullshit.org/)\n\n“I only believe in statistics that I doctored myself” ― Winston S. Churchill\n\nHowever: “It is easy to lie with statistics, but easier to lie without them” ― Frederick Mosteller\n\n\n\n\nbreak-out session, 3 min.\n–&gt; Afterwards: write in chat or speak, what did you come up with?\npossibly show empirical cycle or the like to indicate that stats are necessary at almost every step"
  },
  {
    "objectID": "W1_Intro.html#what-is-statistical-thinking",
    "href": "W1_Intro.html#what-is-statistical-thinking",
    "title": "01a Introduction to Biostatistics",
    "section": "What is Statistical Thinking?",
    "text": "What is Statistical Thinking?\n\n\n“a systematic way of thinking about how we describe the world and use data [to] make decisions and predictions, all in the context of the inherent uncertainty that exists in the real world.” (Poldrack, Preface of ST21)\n“Statistical thinking is a way of understanding a complex world by describing it in relatively simple terms that nonetheless capture essential aspects of its structure or function, and that also provide us some idea of how uncertain we are about that knowledge.” (Poldrack, Chapter 1)\n\n\n\nbreak down complexity, include uncertainty"
  },
  {
    "objectID": "W1_Intro.html#why-is-statistical-thinking-important",
    "href": "W1_Intro.html#why-is-statistical-thinking-important",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is Statistical Thinking Important?",
    "text": "Why is Statistical Thinking Important?\n\n\ndata literacy vs. intuition/heuristics/anecdotal evidence\n\nPublic discourse about Covid-19, migration, etc. (e.g., “50% of people in intensive care are vaccinated”)\n\n\n\n. . .\n\n\n\nBase Rate Fallacy\n\n\n\nWrite in chat! (after first bullet point!)\nexample availability heuristic from book (or any other example where intuition is wrong, i.e. vaccinations/covid…)\n--&gt; test in class? Ask for opinion/intuition, show data"
  },
  {
    "objectID": "W1_Intro.html#what-can-statistics-do-for-us",
    "href": "W1_Intro.html#what-can-statistics-do-for-us",
    "title": "01a Introduction to Biostatistics",
    "section": "What can Statistics Do For Us?",
    "text": "What can Statistics Do For Us?\n\nDescribe patterns by summarizing/breaking down data (“descriptive statistics”)\nDecide whether one thing is better than another, given the uncertainty (“inferential statistics”)\nPredict how other people would “behave” (generalize to new observations)\n\n\ndescribe: not useful to look at every single data point/person, but we need s.th. like tendencies/trends…"
  },
  {
    "objectID": "W1_Intro.html#the-big-ideas",
    "href": "W1_Intro.html#the-big-ideas",
    "title": "01a Introduction to Biostatistics",
    "section": "The Big Ideas",
    "text": "The Big Ideas\n\n\nLearning from data: Update our beliefs\nAggregation: How to summarize the data to draw meaningful conclusions?\nUncertainty: Probabilistic evidence\nSampling from the population: Which people etc. do we select?\n\n\n\nask for every point what I could mean w/ it?\nLfD: gather new knowledge\nAgg: Can’t look at all ind data points, need to find trends etc. (should not go to far! throwing out data)\nuncert: stats = tools for making decisions under uncert, we can never prove anything but provide evidence, there is no 100% certainty for an outcome (cancer)\nsampling: how do we represent the population? What is the population? how much data do we need? More is better, but payoff decreases…"
  },
  {
    "objectID": "W1_Intro.html#causality",
    "href": "W1_Intro.html#causality",
    "title": "01a Introduction to Biostatistics",
    "section": "Causality",
    "text": "Causality\nCorrelation does not imply causation… but is a hint!\n. . .\nExample: Smoking = less risk for Parkinson’s disease? (Godwin-Austen et al., 1982; Chen et al., 2010)\n. . .\n--&gt; confounding factors?\n. . .\ne.g., individual dopaminergic activity =&gt; addiction & motor function\n. . .\nRandomized Controlled Trials (RCT) as the solution?\n\ngive example! Eat more fat = living longer? Confounders (richer people, healthier diets, less stress, better health care…)\nRCT: exp control and manipulation, removes confounds if done well\nAt least some more causal evidence!\nQUESTIONS so far?"
  },
  {
    "objectID": "W1_Intro.html#what-are-data",
    "href": "W1_Intro.html#what-are-data",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data?",
    "text": "What are Data?\n\nWhat do you think are data?\n\n\n\nqualitative vs. quantitative\n\nqualitative?\n\nopen questions, descriptions… can potentially be coded into categories\n\nquantitative?\n\nnumeric, can be averaged etc.\n\n\n\n\n\nChat –&gt; after showing slide! Come up with examples for “Data”\nCollect: Do you have ideas? What are data you encounter in your lives/work etc? What are differences between these data?"
  },
  {
    "objectID": "W1_Intro.html#what-are-data-2",
    "href": "W1_Intro.html#what-are-data-2",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data? (2)",
    "text": "What are Data? (2)\n\n\nData types\n\ncharacter/string: text (qualitative)\nfactors/categories\ntypes of numbers (quantitative)\n\nbinary: 0 or 1, TRUE or FALSE (logical)\nintegers: whole numbers\nreal numbers: decimals/fractions\n\n\ndiscrete vs. continuous\n\ndiscrete: finite set of particular values (0 or 1, scale from 1 to 10)\ncontinuous: real numbers that fall into particular range (e.g., brain activity, visual analoge scale)\n\nWhat data type is eye color?\n\n\n\ndiscrete vs. continuous: question for examples or quiz\nFurther classify data examples mentioned in chat"
  },
  {
    "objectID": "W1_Intro.html#what-is-a-data-set",
    "href": "W1_Intro.html#what-is-a-data-set",
    "title": "01a Introduction to Biostatistics",
    "section": "What is a Data Set?",
    "text": "What is a Data Set?\n\na collection of data\nusually organized into rows and columns (like an excel spreadsheet)\n\nrows: participants/animals/cells…\ncolumns: variables!\n\neach variable contains one type of measurement\n\ntable cells = unique observations of variables per participant etc.\n\n\n\n\n\nNHANES dataset\n\n\n\npossibly go through columns and ask for data types?"
  },
  {
    "objectID": "W1_Intro.html#what-makes-a-good-measurement",
    "href": "W1_Intro.html#what-makes-a-good-measurement",
    "title": "01a Introduction to Biostatistics",
    "section": "What Makes a Good Measurement?",
    "text": "What Makes a Good Measurement?\n\n\n\nWhat is being measured?\n\nconstructs vs. proxies: need to be well-defined! (Difficult)\nmeasurement error\n\nrandom: e.g., variation in reaction times of same participant across trials\nsystematic: e.g., miscalibrated eye-tracking device\n\n\nDo we have a “gold standard” to compare the measurement to?\n\n\n\nBreak-Out session: Brainstorm what makes a good vs. bad measurement!\nGroup work/brainstorm:\n\nWhat are problems?\nWhich kind of errors/when is data NOT good\nhow can we minimize error?"
  },
  {
    "objectID": "W1_Intro.html#reliability",
    "href": "W1_Intro.html#reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Reliability",
    "text": "Reliability\nCorrelation of a measurement with “itself”\n\n\nInternal reliability (consistency)\nTest-retest reliability (stability)\nInter-rater reliability (agreement)\n\n\n. . .\nCorrelation with other variables can’t be higher than reliability (cf., Wilmer et al., 2012, Table 1)!"
  },
  {
    "objectID": "W1_Intro.html#validity",
    "href": "W1_Intro.html#validity",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity",
    "text": "Validity\nAre we measuring the construct we’re interested in?\n\n\nFace validity: Does it intuitively make sense? First reality check!\nConstruct validity\n\nconvergent validity: Related to similar measures that should measure the same construct\ndivergent validity: Is it unrelated to other measures?\n\nPredictive validity: Is it predictive of other outcomes? (e.g., intelligence & job success)\n\n\n. . .\n\n\n\nReliability & Validity"
  },
  {
    "objectID": "W1_Intro.html#summarizing-data",
    "href": "W1_Intro.html#summarizing-data",
    "title": "01a Introduction to Biostatistics",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\n\nThrowing away (some of the) information!\n\nextract the quintessence of the data (important for forming models)\nmake predictions\n\nCounts, frequencies, percentages, averages"
  },
  {
    "objectID": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "href": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "title": "01b Intro to R",
    "section": "General: Working with R in this course",
    "text": "General: Working with R in this course\nDuring Class\n\nYou should have RStudio open and your Biostats project loaded (we will set up the project today).\nHave the slides open in the background. You will need them to copy R code (top right button on any code chunk) or click on links.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\n\nRemember: You can navigate through the slides quickly by clicking on the three dashes in the bottom left.\n\n\n\nAt Home\nIf possible, use two screens with the slides (Zoom) opened on one and RStudio on the other"
  },
  {
    "objectID": "W1b_IntroR.html#why-write-code",
    "href": "W1b_IntroR.html#why-write-code",
    "title": "01b Intro to R",
    "section": "Why write code?",
    "text": "Why write code?\n\n\nDoing statistical calculation by hand? Tedious & error prone! Computer is faster…\nUsing spreadsheets? Limited options, change data accidentally…\nUsing point-and-click software (e.g., SPSS)?\n\nproprietary software = expensive\nR = open, extensible (community)\nreproducible!\n\nScience/Academia is a marathon and not a sprint\n=&gt; it is worthwhile investing in skills with a slow learning curve that will pay off in the long run\n\n\n\nChat: What are advantages (or disadvantages!) of coding?"
  },
  {
    "objectID": "W1b_IntroR.html#install-r-rstudio",
    "href": "W1b_IntroR.html#install-r-rstudio",
    "title": "01b Intro to R",
    "section": "Install R & RStudio",
    "text": "Install R & RStudio\nYou should all have installed R & RStudio by now! Who had problems doing so?"
  },
  {
    "objectID": "W1b_IntroR.html#overview-rstudio",
    "href": "W1b_IntroR.html#overview-rstudio",
    "title": "01b Intro to R",
    "section": "Overview RStudio",
    "text": "Overview RStudio\n\nRStudio Interface\nopen R!"
  },
  {
    "objectID": "W1b_IntroR.html#rstudio-panes",
    "href": "W1b_IntroR.html#rstudio-panes",
    "title": "01b Intro to R",
    "section": "RStudio Panes",
    "text": "RStudio Panes\n\n\n\nScript pane: view, edit, & save your code\nConsole: here the commands are run and rudimentary output may be provided\nEnvironment: which variables/data are available\nFiles, plots, help etc.\n\n\n\n\n\n\n\nRStudio Interface\n\n\n\n\n\nConsole vs. Script (Rmarkdown later)"
  },
  {
    "objectID": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "href": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "title": "01b Intro to R",
    "section": "Using the Console as a Calculator",
    "text": "Using the Console as a Calculator\n\n100 + 1\n\n[1] 101\n\n2*3\n\n[1] 6\n\nsqrt(9)\n\n[1] 3\n\n\n\nConsole used as calculator\ntry it out!\nWe can’t really do much with these values, they will just be written in the console."
  },
  {
    "objectID": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "href": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "title": "01b Intro to R",
    "section": "Saving the Results as a Variable/Object",
    "text": "Saving the Results as a Variable/Object\n\na &lt;- 100 + 1\n\nmulti &lt;- 2*3\n\nSqrtOfNine &lt;- sqrt(9)\n\nword &lt;- \"Hello\"\n\n\n\n“&lt;-” is used to assign values to variables (“=” is also possible but not common in the R community)\na, multi etc. are the variable names, which can be words, some special characters are allowed but not whitespace\n\nYou can find those now in your Environment! (top right)\nFor saving variables, there is no feedback in the console (2*3 outputs 6 but multi &lt;- 2*3 does not)\n\nas you can see, the variables can contain different types: Numbers, strings/characters (= words) etc.\nthe variables contain the calculated value (i.e. 101) and not the calculation/formula (100+1)\nYou can use those variables for further calculations, e.g., a + multi\n\n\n\nType first command in console, what happens?\nWhy don’t we see anything in the console?\nWhat happens if we type in a in the console?\nIs there anything else that you find interesting?\nWhat is sqrt()?"
  },
  {
    "objectID": "W1b_IntroR.html#functions",
    "href": "W1b_IntroR.html#functions",
    "title": "01b Intro to R",
    "section": "Functions",
    "text": "Functions\nThis code with sqrt(9) looked unfamiliar. sqrt() is an R function that calculates the square root of a number. 9 is the argument that we hand over to the function.\nIf you want to know what a function does, which arguments it takes, or which output it generates, you can type into the console: ?functionname\n\n?sqrt\n\nThis will open the help file in the Help Pane on the lower right of RStudio.\nYou can also click on a function in the script or console pane and press the F1 key.\n\nDo this now! Anything unclear?"
  },
  {
    "objectID": "W1b_IntroR.html#functions-2",
    "href": "W1b_IntroR.html#functions-2",
    "title": "01b Intro to R",
    "section": "Functions 2",
    "text": "Functions 2\nFunctions often take more than one argument:\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1) #this outputs the same as above\n\n# By the way, # denotes a line-end comment (ignored by R), which are very important for code documentation!\n\nYou can explicitly state which argument you are handing over (check the help file for the argument names!) or just state the values (but these have to be in the correct order then! See help file)."
  },
  {
    "objectID": "W1b_IntroR.html#packages",
    "href": "W1b_IntroR.html#packages",
    "title": "01b Intro to R",
    "section": "Packages",
    "text": "Packages\nThere are a number of functions that are already included with Base R (i.e., R after a new installation), but you can greatly extend the power of R by loading packages (and we will!). Packages are like collections of functions or even data types that someone else wrote.\nOn the top, click on Tools and then Install Packages…. Search for tidyverse and install!\n\n\n\nYou can also download a package using the install.packages() function:\n\ninstall.packages(\"tidyverse\")\n\n(It may be necessary to install Rtools for some packages: https://cran.r-project.org/bin/windows/Rtools/)\n\n\n\n\nBut installing is not enough to be able to actually use the functions from that package directly. Usually, you also want to load the package (i.e., make it directly available) with the library() function. This is the first thing you do on the top of an R script:\n\nlibrary(\"tidyverse\") # or library(tidyverse)\n\n(If you don’t load a package, you have to call functions explicitly by packagename::function)\n\nOpen Source! Anyone can write a package!\nBase R = mobile phone, comes with some functions, packages = apps\npossibly necessary to install Rtools!"
  },
  {
    "objectID": "W1b_IntroR.html#new-project",
    "href": "W1b_IntroR.html#new-project",
    "title": "01b Intro to R",
    "section": "New Project",
    "text": "New Project\nCreate a new project by clicking on “File” in the top left and then “New Project…”\nWe usually want to create a “New Directory” and then choose a standard “New Project” on the top of the list\n(we will only need standard projects during this class)\nChoose the project name, e.g., as “Biostats R” (this will create a folder in which the whole project is living)\nBrowse any kind of path you want to contain your project folder,\ne.g., “D:/Documents/Studies/Translational Neuroscience/Biostats”\n\nNew Project final window"
  },
  {
    "objectID": "W1b_IntroR.html#existing-projects",
    "href": "W1b_IntroR.html#existing-projects",
    "title": "01b Intro to R",
    "section": "Existing Projects",
    "text": "Existing Projects\nYou will find the current project on the top right corner of RStudio\nIf you click on the current project, you can open new projects by choosing “Open Project” and select the .Rproj file of the project.\nYou can also just double click on .Rproj files and RStudio will open with the project loaded.\n\nExisting projects"
  },
  {
    "objectID": "W1b_IntroR.html#using-scripts",
    "href": "W1b_IntroR.html#using-scripts",
    "title": "01b Intro to R",
    "section": "Using Scripts",
    "text": "Using Scripts\nTo open a new script, click File -&gt; New File -&gt; R Script. (Ctrl + Shift + N)\nTo run a line of the script, you can either click Run at the top right of the pane or Ctrl + Enter. It will run the code that is highlighted/selected or automatically select the current line (or the complete multi-line command).\nTo run the whole script/chunk, press Ctrl + Shift + Enter (with full console output) or Ctrl + Shift + S (limited output).\n\n\nUsing scripts"
  },
  {
    "objectID": "W1b_IntroR.html#read-in-data",
    "href": "W1b_IntroR.html#read-in-data",
    "title": "01b Intro to R",
    "section": "Read in Data",
    "text": "Read in Data\nTo read in data files, you need to know which format these files have, e.g. .txt. or .csv files or some other (proprietary) format. There are packages that enable you to read in data of different formats.\nWe will use the files from Fundamentals of Quantitative Analysis: ahi-cesd.csv and participant-info.csv. Save these directly in your project folder on your computer (do not open them!).\n\n\n\nDid you find the files? Here are the direct links:\n\nhttps://psyteachr.github.io/quant-fun-v2/ahi-cesd.csv\nhttps://psyteachr.github.io/quant-fun-v2/participant-info.csv\n\n\n\n\n\nCreate a new script with the following content:\n\n#install.packages(\"tidyverse\") #if you have not yet installed the tidyverse, uncomment and run\nlibrary(tidyverse) # we will use a function from the tidyverse to read in the data\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nRun the code!"
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data",
    "href": "W1b_IntroR.html#looking-at-the-data",
    "title": "01b Intro to R",
    "section": "Looking at the Data",
    "text": "Looking at the Data\n\nThere are several options to get a glimpse at the data:\n\nClick on dat and pinfo in your Environment.\nType View(dat) into the console or into the script pane and run it.\nRun str(dat) or str(pinfo) to get an overview of the data.\nRun summary(dat).\nRun head(dat), print(dat), or even just dat.\nWhat is the difference between these commands?"
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data-2",
    "href": "W1b_IntroR.html#looking-at-the-data-2",
    "title": "01b Intro to R",
    "section": "Looking at the Data 2",
    "text": "Looking at the Data 2\nWhat is the difference to the objects/variables, that you assigned/saved in your Environment earlier and these objects?\n\n\nThe two objects we just read in are data frames, which consist of full datasets. The objects we assigned earlier were simpler variables, which only consisted of single values/words.\nData frames usually have several rows and columns. Remember, the columns are the variables and the rows are the observations."
  },
  {
    "objectID": "W2_Models.html#what-is-a-model",
    "href": "W2_Models.html#what-is-a-model",
    "title": "02 Models",
    "section": "What is a Model?",
    "text": "What is a Model?\n\n“models” are generally simplifications of things in the real world that nonetheless convey the essence of the thing being modeled\nAll models are wrong but some are useful (George Box)\n\n(ST21, Ch 5)\nAim: Find the model that efficiently and accurately summarizes the data.\nBasic structure of statistical models:\n\\[\ndata=model+error\n\\]\n\na statistical model is generally much simpler than the data being described; it is meant to capture the structure of the data as simply as possible.\nTwo parts:\n\none portion that is described by a statistical model, which expresses the values that we expect the data to take given our knowledge,\nerror that reflects the difference between the model’s predictions and the observed data."
  },
  {
    "objectID": "W2_Models.html#statistical-models",
    "href": "W2_Models.html#statistical-models",
    "title": "02 Models",
    "section": "Statistical Models",
    "text": "Statistical Models\nIn general, we want to predict single observations (denoted by i) from the model. The fact that we are looking at predictions of observations and not actual values of the data is denoted by the “hat”:\n\\[\n\\widehat{data_i} = model_i\n\\] The error is then simply the deviation of the actual data from the predicted values:\n\\[\nerror_i = data_i - \\widehat{data_i}\n\\] If this doesn’t make much sense yet, let’s look at an example.\n\nThis means that the predicted value of the data for observation i is equal to the value of the model for that observation."
  },
  {
    "objectID": "W2_Models.html#some-data",
    "href": "W2_Models.html#some-data",
    "title": "02 Models",
    "section": "Some Data",
    "text": "Some Data\nLet’s say we want to have a model of height of children based on the NHANES dataset (also used in ST21). What would you do?\nHere is how (the beginning of) the dataset looks like:"
  },
  {
    "objectID": "W2_Models.html#a-simple-model",
    "href": "W2_Models.html#a-simple-model",
    "title": "02 Models",
    "section": "A Simple Model",
    "text": "A Simple Model\nWhat do you think would be a good model for the height of a person?\n(Or: Which value should we guess for a particular child?)"
  },
  {
    "objectID": "W2_Models.html#a-simple-model-2",
    "href": "W2_Models.html#a-simple-model-2",
    "title": "02 Models",
    "section": "A Simple Model 2",
    "text": "A Simple Model 2\nThe simplest model would be to predict the mean of the height values for every child! This would imply that individual deviations of the mean would be interpreted to be (prediction) errors in such a model.\nWe can write such a simple model as a formula:\n\\[\ny_i = \\beta + \\epsilon\n\\]\n\\(y_i\\) denotes the individual observations (hence the \\(i\\)) of heights, \\(\\beta\\) is a so-called parameter, and \\(\\epsilon\\) is the error term. In this example, the parameter \\(\\beta\\) would be the same value (= the mean height) for everyone (hence it doesn’t need an \\(i\\) subscript). Parameters are values that we optimize to find the best model."
  },
  {
    "objectID": "W2_Models.html#a-simple-model-3",
    "href": "W2_Models.html#a-simple-model-3",
    "title": "02 Models",
    "section": "A Simple Model 3",
    "text": "A Simple Model 3\nHow do we find parameters that belong to the best fitting model?\n\nWe try to minimize the error!\nRemember, the error is the difference between the actual and predicted values of \\(y\\) (height):\n\\[\nerror_i = y_i - \\hat{y_i}\n\\]\nIf we select a predicted value of 400cm, all individuals’ errors would hugely deviate (because no one is 4m tall). If we average these errors, it would still be a big value.\nA better candidate for such a simple model is thus the arithmetic mean or average:\n\\[\n\\bar{X} = \\frac{\\sum_{i=1}^{n}x_i}{n}\n\\]\nSumming up all individual’s heights and dividing that number by the number of individuals gives us the mean. By definition, the average (directed) error is now 0 (see book for proof, the individual errors cancel out)! This means that the average has no bias to over- or underestimate observations (while 4m would have been a clear overestimation)."
  },
  {
    "objectID": "W2_Models.html#a-note-on-errors",
    "href": "W2_Models.html#a-note-on-errors",
    "title": "02 Models",
    "section": "A Note on Errors",
    "text": "A Note on Errors\nWe usually don’t simply average across the individual (signed) errors, but across the squared errors.\nThe reason is that we do not want positive and negative errors to cancel each other out.\nThe mean squared error would be in a different unit than the data (e.g., cm2), which is why we usually take the square root of that value to bring it back to the original unit: This leaves us with the root mean squared error (RMSE)!\nNote: We could also use the absolute values of errors, sum those up, and avoid any of these problems. For historical reasons, we do not."
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model",
    "href": "W2_Models.html#a-slightly-more-complex-model",
    "title": "02 Models",
    "section": "A Slightly More Complex Model",
    "text": "A Slightly More Complex Model\nObviously, the model for predicting height from the average is not very good (RMSE = 27 cm). How can we improve this model?\n\nWe can account for other information that we might have!\nFor example, to account for age might be a good idea: Older children are likely taller than younger ones. We plot height against age to visually inspect the relationship:\n\n\n\n\n\n\n\n\nRMSE: On average, 27 cm “wrong” per individual!\nA: raw data, visible strong relationship\nB: only age (linear relationship)\nC: intercept/constant\nD: also account for gender\n--&gt; line fits data increasingly better!"
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model-2",
    "href": "W2_Models.html#a-slightly-more-complex-model-2",
    "title": "02 Models",
    "section": "A Slightly More Complex Model 2",
    "text": "A Slightly More Complex Model 2\nAs we can see, the line (~ model) fits the data points increasingly well, e.g. if we include a constant (also called “intercept”) and age. We would write this as this formula:\n\\[\n\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} * age_i\n\\]\nRemember from linear algebra that this defines a line:\n\\[\ny = intercept + slope * x\n\\]\nThus \\(\\beta_0\\) is the parameter for the intercept and \\(\\beta_1\\) for the slope of age!\nThe model fit is now much better: RMSE = 8.36 cm.\n\nAdding gender? Does not improve model too much! (compared to age)\n\nw/o intercept: A, no \\(\\beta_0\\)\nStats Software will estimate best values for \\(\\beta\\)’s"
  },
  {
    "objectID": "W2_Models.html#what-is-a-good-model",
    "href": "W2_Models.html#what-is-a-good-model",
    "title": "02 Models",
    "section": "What is a “Good” Model?",
    "text": "What is a “Good” Model?\nTwo aims:\n\nDescribe data well (= low error/RMSE)\nGeneralize to new data (low error when applied to new data)\n\nCan be conflicting!\n\nWhere does error come from?\n\n\nmeasurement error (noise): random variation in data\n\ndependent variable is hard to measure precisely (difficult/noisy conditions)\ncheap/inadequate equipment for measuring\n\nwrong model specification\n\nimportant variable is missing from model (age!)\ne.g., height has a quadratic relationship with age (old people shrink again)"
  },
  {
    "objectID": "W2_Models.html#examples-measurement-error",
    "href": "W2_Models.html#examples-measurement-error",
    "title": "02 Models",
    "section": "Examples Measurement Error",
    "text": "Examples Measurement Error\n\nSimulated relationship between blood alcohol content and reaction time on a driving test, with best-fitting linear model represented by the line. A: linear relationship with low measurement error. B: linear relationship with higher measurement error. C: Nonlinear relationship with low measurement error and (incorrect) linear model\nA: very little error, all points close to fitted line\nB: same relationship much more variability across individuals\nC. wrongly specified model (caffeine!), not a linear relationship. Error high (deviations points - line)"
  },
  {
    "objectID": "W2_Models.html#can-a-model-be-too-good",
    "href": "W2_Models.html#can-a-model-be-too-good",
    "title": "02 Models",
    "section": "Can a Model be “too Good”?",
    "text": "Can a Model be “too Good”?\nYes! This is called overfitting.\n\nIf we fit a line too closely to the data (e.g., with an 8th degree polynomial), the model might not be able to generalize to other data well.\n\n\n\n\n\nAn example of overfitting. Both datasets were generated using the same model, with different random noise added to generate each set. The left panel shows the data used to fit the model, with a simple linear fit in blue and a complex (8th order polynomial) fit in red. The root mean square error (RMSE) values for each model are shown in the figure; in this case, the complex model has a lower RMSE than the simple model. The right panel shows the second dataset, with the same model overlaid on it and the RMSE values computed using the model obtained from the first dataset. Here we see that the simpler model actually fits the new dataset better than the more complex model, which was overfitted to the first dataset.\n\n\n\n\n\nsame formula, different noise (simulation) ~ different individuals\nsimpler model fits new data better!"
  },
  {
    "objectID": "W2_Models.html#central-tendency",
    "href": "W2_Models.html#central-tendency",
    "title": "02 Models",
    "section": "Central Tendency",
    "text": "Central Tendency\nWhy summarize data?\n\nA summary is a model & describes the data! E.g., mean = central tendency of the data\n\n\nMean, Median, Mode?\n\n\nMean = “Balance point” of data; minimizes sum of squared error, but highly influenced by outliers!\nMedian = “middle” of ranked data; minimizes sum of absolute error, less influenced by extreme values\nMode = most often occurring value (i.e., absolute peak)\n\n\nExample:\nIf 4 people earn 50,000 Euros per year and 1 person earns 1,000,000:\nMean: 240,000 Euros\nMedian: (Rank order: 10,000; 10,000; 10,000; 10,000; 1,000,000) -&gt; middle value = 10,000 Euros\nMode: 10,000 Euros\n\nexamples\nmean: income –&gt; if one person earns a million and 3 only 10.000 –&gt; mean = 257.500"
  },
  {
    "objectID": "W2_Models.html#variability",
    "href": "W2_Models.html#variability",
    "title": "02 Models",
    "section": "Variability",
    "text": "Variability\nHow widespread are the data?\n\nVariance and Standard Deviation\nVariance = Mean Squared Error\n\\[\n\\sigma^2 = \\frac{SSE}{N} = \\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{N}\n\\]\n(Note: \\(x_i\\) = value of ind. observation, \\(\\mu\\) = population mean instead of \\(\\hat{X}\\) = sample mean)\n\n\nStandard Deviation = Root Mean Squared Error\n\\[\nSD = \\sigma = \\sqrt{\\sigma^2}\n\\]\n\n\nWe usually don’t know the population mean \\(\\mu\\), that’s why we estimate the sample variance using the sample mean \\(\\hat{X}\\) (both with the “hat”) and the sample size \\(n\\) instead of the population size \\(N\\):\n\\[\n\\hat\\sigma^2 = \\frac{\\sum_{i=1}^n (x_i - \\hat{X})^2}{n-1}\n\\]\nNote: \\(n-1\\) is used to make the estimate more robust/less biased (I cannot give you an intuition why this is better… please trust me!).\n\nRemember plot above: Points either close to line or wide spread\nVariance = sigma^2, deviations of data points from mean (\\(\\mu\\)) squared and summed, divided by number of oberservations\n\\(n-1\\) = Degrees of Freedom, one value is fixed if we know the mean."
  },
  {
    "objectID": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "href": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "title": "02 Models",
    "section": "Comparing apples and oranges: Z-Scores",
    "text": "Comparing apples and oranges: Z-Scores\n\\[\nZ_i(x) = \\frac{x_i - \\mu}{\\sigma}\n\\]\n\n\nstandardizes the distribution: How far is any data point from the mean in units of SD?\ndoesn’t change original relationship of data points!\n\nshifts distribution to have a mean = 0 and scales it to have SD = 1.\n\nuseful if we compare (or use in a model) variables on different scales/units!\n\n\n\n\n\n\n\n\nDensity (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at one standard deviation above/below the mean.\n\n\n\n\n\nZ of x\nx_i is single value/data point\nmu, sigma\nz-scores: Now you can compare apples to oranges! Imagine two siblings from different classes battling it out on test results:\n- I got 70 points, you got only 60!\n- My test only had 70 points in total, yours had 85. I got 86% correct, you only 82%!\n- My test was harder! The average result was 60 with a standard deviation of 10, so I am 1 SD above the class average!\n- On my test, an average of 52 was achieved with an SD of 8, so I am also 1 SD above the class average. But people in your class are really stupid so that’s a very low standard to compare yourself.\nNarrator: And this was the end of comparability between apples and oranges :)"
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns",
    "text": "Accessing Variables/Columns\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# create a small data set for this example:\ntestdata &lt;- data.frame(a = c(1, 2, 3),  # c() creates a (column)vector!\n                       b = c(\"a\", \"b\", \"c\"),\n                       c = c(4, 5, 6),\n                       d = c(7, 8, 9),\n                       e = c(10, 11, 12))\n\nprint(testdata)\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n3 3 c 6 9 12\n\nstr(testdata)\n\n'data.frame':   3 obs. of  5 variables:\n $ a: num  1 2 3\n $ b: chr  \"a\" \"b\" \"c\"\n $ c: num  4 5 6\n $ d: num  7 8 9\n $ e: num  10 11 12\n\n\n\ndata.frame() = function to create a data.frame, which is what holds a data set! (tibbles..)\nc() = function to make a vector. A vector is just like one single column of a data frame: It can hold several values, but all of the same type."
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 2",
    "text": "Accessing Variables/Columns 2\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# in baseR, we access elements of a data.frame with square brackets\ntestdata[1, 2] #get cell that is in first row and second column\n\n[1] \"a\"\n\ntestdata[1:2, 4:5] #use a colon to create ranges of values: first two rows and column numbers 4 and 5\n\n  d  e\n1 7 10\n2 8 11\n\n# we can leave one part empty to select ALL available columns/rows\ntestdata[1:2,] #first two rows, all columns\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n\ntestdata[, 4:5] #columns number 4 and 5, all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n# it is usually better to access columns by their column name:\ntestdata[, c(\"d\", \"e\")] #columns with names \"d\" and \"e\", all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n\n\nsubsetting: rows, columns –&gt; leave empty!\nSelect range!\nUse either name or index of column!"
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 3",
    "text": "Accessing Variables/Columns 3\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# access a column only:\ntestdata[, \"a\"] #if possible, R will give you just a vector instead of a data.frame\n\n[1] 1 2 3\n\ntestdata$a #short notation to get column \"a\" as a vector\n\n[1] 1 2 3\n\n# tidy versions (see next slides)\n#library(tidyverse) #load tidyverse (if not already done)\npull(testdata, a) #same as testdata$a but can be used better in pipes (see next slide)\n\n[1] 1 2 3\n\nselect(testdata, a) #get column(s) as a data.frame (we usually want this only if we select several columns)\n\n  a\n1 1\n2 2\n3 3\n\n\n\ndata.frame() = function to create a data.frame, which is what holds a data set! (tibbles..)\nc() = function to make a vector. A vector is just like one single column of a data frame: It can hold several values, but all of the same type.\nsubsetting: rows, columns –&gt; leave empty!\nSelect range!\nUse either name or index of column!\nselect –&gt; tidyverse"
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-2",
    "href": "W3_DataWranglingR.html#tidyverse-2",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 2",
    "text": "Tidyverse 2\nBase R:\noutput_data1 &lt;- function1(data)\noutput_data2 &lt;- function2(output_data1, param1)\noutput_data3 &lt;- function3(output_data2, param2, param3)\n\nOr:\noutput_data &lt;- function3(function2(function1(data), param1), param2, param3)\n\n\nTidyverse:\noutput_data &lt;- data %&gt;% function1() %&gt;% function2(param1) %&gt;% function3(param2, param3)\n\n\nYou can insert a pipe %&gt;% (including spaces) by pressing Ctrl + Shift + M\n\n\nBe aware, though, that coding in the tidyverse style is very different than in Base R!\nBase R is more similar to “traditional” programming and other programming languages.\nFor example, you could wrap functions, which would then be carried out from the most nested to the outer function:\noutput_data &lt;- function3(function2(function1(data)))\nfunction1() will be carried out first, followed by function2(), then function3() .\n. . .\nIn the tidyverse, the same would look like this:\noutput_data &lt;- data %&gt;% function1() %&gt;% function2() %&gt;% function(3)\n%&gt;% is called “the pipe” and will “hand over” whatever has been done to the next part. In this example, the data is handed over to function1(), which is then carried out, the result of which is handed over to function2() etc.\nTidyverse style programming is thus a bit easier to read!\nThere’s also the new pipe Base R |&gt;, which is similar to %&gt;%.\n\n\n\n%&gt;% is called the pipe. It takes the output of whatever happens to its left and “hands it over” to the right. There’s also a new base-R-pipe: |&gt;. It is very similar, but sometimes the functionality differs."
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-3",
    "href": "W3_DataWranglingR.html#tidyverse-3",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 3",
    "text": "Tidyverse 3\nlibrary(tidyverse) will load a number of packages, such as dplyr, ggplot2, readr, forcats, tibble etc., which are all usefuls for data wrangling.\nWe will work mainly with functions from the dplyr package, but also use readr to read in data. We will also use ggplot2 to visualize data.\nThe most important dplyr functions for data wrangling are:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nselect()\nInclude or exclude certain columns (variables)\n\n\nfilter()\nInclude or exclude certain rows (observations)\n\n\nmutate()\nCreate new columns (variables)\n\n\nsummarize()\nCreate new columns that aggregate data/create summary variables for groups of observations (data frame will become smaller)\n\n\ngroup_by()\nOrganize the rows (observations) into groups\n\n\narrange()\nChange the order of rows (observations)\n\n\n\n\nfunction names very self-explanatory!\nWe don’t create new observations in R - this is job of the data acquisition - we just read the existing data"
  },
  {
    "objectID": "W3_DataWranglingR.html#setting-up-libraries",
    "href": "W3_DataWranglingR.html#setting-up-libraries",
    "title": "03 Data Wrangling",
    "section": "Setting up libraries",
    "text": "Setting up libraries\n\nOpen your Biostats R project.\nCreate a new R script and save it, e.g. as “DataWrangling1.R”.\nInsert code to make sure the packages “tidyverse” and “babynames” are installed and loaded.\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"babynames\")\n\nlibrary(babynames)\nlibrary(tidyverse)\n\n\nload tidyverse last, otherwise functions with same name will be masked from package that is loaded first. Since we often need tidyverse functions, it’s safest to load it last!"
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data",
    "href": "W3_DataWranglingR.html#look-at-the-data",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\n\n\nType the word babynames into your console pane and press enter. What kind of information do you get?\n\n“A tibble: 1,924,665 x 5”\n\ntibble is an extension of the data.frame with more convenient output (e.g., values rounded to significant digits)\n~1.9 million rows/observations\n5 columns/variables\n\n\nWhat kind of columns/variables do we have?\n\ndbl = double/numeric (can take decimals)\nchr = character/string (letters or words)\nint = integer (only whole numbers)\n\n\n\n\nask first for 1 and 2"
  },
  {
    "objectID": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "href": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "title": "03 Data Wrangling",
    "section": "Selecting Variables of Interest",
    "text": "Selecting Variables of Interest\nUse select() to choose only the columns year, sex, name, and prop and store it as a new tibble called babynames_reduced.\nRemember that you can run ?select in the console if you need help about, e.g., input/arguments to the function.\n\n\n# my favorite:\nbabynames_reduced &lt;- babynames %&gt;% \n  select(year, sex, name, prop)\n\n# or without the pipe operator:\nbabynames_reduced &lt;- select(.data = babynames, year, sex, name, prop)\n\n# or alternatively:\nbabynames_reduced &lt;- babynames %&gt;% \n  select(-n) # remove columns by using -\n\nRemoving columns vs. selecting columns: Results may change if the data get updated!"
  },
  {
    "objectID": "W3_DataWranglingR.html#arranging-data",
    "href": "W3_DataWranglingR.html#arranging-data",
    "title": "03 Data Wrangling",
    "section": "Arranging Data",
    "text": "Arranging Data\nChange the order of the data (oberservations/rows)!\n\n\nUsing arrange(), try sorting the data according to the names column. What happens?\nHow can you sort a column in a descending fashion? Check out the help file (?arrange).\nLet’s sort by year descendingly and within each year, sort names alphabetically.\n\n\n\n\nsort_asc &lt;- babynames %&gt;% arrange(name)\n\nsort_desc &lt;- babynames %&gt;% arrange(desc(year)) \n\nbabynames %&gt;% arrange(desc(year), name) \n\n# A tibble: 1,924,665 × 5\n    year sex   name          n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1  2017 M     Aaban        11 0.0000056 \n 2  2017 F     Aabriella     6 0.0000032 \n 3  2017 M     Aadam        18 0.00000917\n 4  2017 M     Aadan         8 0.00000407\n 5  2017 M     Aadarsh      15 0.00000764\n 6  2017 M     Aaden       240 0.000122  \n 7  2017 M     Aadesh        7 0.00000357\n 8  2017 M     Aadhav       31 0.0000158 \n 9  2017 M     Aadhavan      6 0.00000306\n10  2017 M     Aadhi        10 0.00000509\n# ℹ 1,924,655 more rows\n\n\n\nremember to save data in new tibble/data frame!"
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-observations",
    "href": "W3_DataWranglingR.html#filter-observations",
    "title": "03 Data Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe have already used select() to keep only certain variables (columns), but often we also want to keep only certain observations (rows), e.g. babies born in the year 2000 and later.\nWe use the function filter() for this.\n\nLook at the following code and think about what it might do.\n\nbabynames %&gt;% filter(year &gt; 2000)\n\n\n\n\n\n# A tibble: 562,156 × 5\n    year sex   name          n    prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n 1  2001 F     Emily     25055 0.0127 \n 2  2001 F     Madison   22164 0.0112 \n 3  2001 F     Hannah    20712 0.0105 \n 4  2001 F     Ashley    16526 0.00835\n 5  2001 F     Alexis    16401 0.00828\n 6  2001 F     Sarah     15896 0.00803\n 7  2001 F     Samantha  15862 0.00801\n 8  2001 F     Abigail   14807 0.00748\n 9  2001 F     Elizabeth 14784 0.00747\n10  2001 F     Olivia    13978 0.00706\n# ℹ 562,146 more rows\n\n\nThe data starts at 2001! :("
  },
  {
    "objectID": "W3_DataWranglingR.html#detour-boolean-expressions",
    "href": "W3_DataWranglingR.html#detour-boolean-expressions",
    "title": "03 Data Wrangling",
    "section": "Detour: Boolean Expressions",
    "text": "Detour: Boolean Expressions\nThe second argument, year &gt; 2000, is a Boolean or logical expression, which means that it results in a value of either TRUE or FALSE. filter() runs this expression and then removes all values/rows that contain FALSE.\nThere are also other Boolean expressions:\n\nBoolean expressions\n\n\n\n\n\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\n\n\nA double equality sign == is a comparison, a single equals = is a variable or parameter assignment.\nThis is why R users like to make the distinction even bigger by using &lt;- for variable assignment (your environment in the top right pane) and = for parameter assignment in functions (a hidden so-called local environment only visible to the function)."
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more",
    "href": "W3_DataWranglingR.html#filter-some-more",
    "title": "03 Data Wrangling",
    "section": "Filter some more",
    "text": "Filter some more\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\n\nFirst task:\n\nmarys &lt;- babynames %&gt;% filter(name == \"Mary\")\n\n\n\nThe second task might be difficult because you have two expressions, name != \"Mary\" and year &gt; 2000. You can simply add several expressions separated by commas in filter (commas are treated like a “logical and” &):\n\nno_marys_young &lt;- babynames %&gt;% filter(name != \"Mary\", year &gt; 2000)\n\n\n\nThird task:\n\nqueens &lt;- babynames %&gt;% filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\"))\n\n\n\nThe fourth task is tricky! You could use three filters in a row with name != \"Mary\", name != \"Elizabeth\", name != \"Victoria\". Or you could use %in%, but then you can’t use the ! in front of the %in%. The trick is to negate the whole expression with == FALSE:\n\nno_queens &lt;- babynames %&gt;% filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\") == FALSE)"
  },
  {
    "objectID": "W3_DataWranglingR.html#your-first-plot",
    "href": "W3_DataWranglingR.html#your-first-plot",
    "title": "03 Data Wrangling",
    "section": "Your First Plot",
    "text": "Your First Plot\nIn your script, insert and run the following code:\n\ndat &lt;- babynames %&gt;% \n  filter(sex==\"F\", #only female babies\n         name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\")) #reduce to these 4 names\n\ndat %&gt;% ggplot(aes(x = year, y = prop, colour = name)) +\n  geom_line(size=2) #plot data as a line (with increased size)\n\n\n\nAlter the code to check for male babies with the same names (change sex==\"F\" to sex==\"M\").\nOptional: Plot the absolute number n instead of the relative proportion prop."
  },
  {
    "objectID": "W3_DataWranglingR.html#create-new-variables",
    "href": "W3_DataWranglingR.html#create-new-variables",
    "title": "03 Data Wrangling",
    "section": "Create New Variables",
    "text": "Create New Variables\nIf we want to create variables that do not exist yet (i.e. by calculating values, combining other variables, etc.), we can use mutate()!\n\nAdd a variable called “country” that contains the value “USA” for all observations\n\n\n\nbaby_where &lt;- babynames %&gt;% mutate(country = \"USA\")\n\n\n\nBut mutate is much more powerful and can create variables that differ per observation, depending on other values in the tibble/data frame:\n\nCreate a variable that denotes the decade a baby was born:\n\n\n\n\n#we can only use floor to round down to full numbers =&gt; divide year by 10, floor it, and then multiply by 10 again\nbaby_decades &lt;- babynames %&gt;% mutate(decade = floor(year/10) *10) #round(year, -1) works but not floor(year, -1) :(\n\n\n\n# A tibble: 10 × 2\n    year decade\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  1884   1880\n 2  1911   1910\n 3  1921   1920\n 4  1923   1920\n 5  1945   1940\n 6  1949   1940\n 7  1965   1960\n 8  1972   1970\n 9  1983   1980\n10  2016   2010"
  },
  {
    "objectID": "W3_DataWranglingR.html#summarizing",
    "href": "W3_DataWranglingR.html#summarizing",
    "title": "03 Data Wrangling",
    "section": "Summarizing",
    "text": "Summarizing\nThe goal of data wrangling is often to summarize (or aggregate) the data, e.g. to have an average value per condition. Sometimes you’d also want to calculate descriptive statistics to report.\n\nYou can do so using the function summarise():\n\n# run the filter function just like above again:\ndat &lt;- babynames %&gt;% \n  filter(name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"), \n         sex == \"F\")\n\n# summarize the data, calculating the number of oberservations:\ndat_sum &lt;- dat %&gt;% summarise(total = sum(n))\ndat_sum\n\n# A tibble: 1 × 1\n    total\n    &lt;int&gt;\n1 2161374\n\n\nAs you can see, a new variable named total is created, which contains the total number of observations (in this case, it is different from the number of rows because each row already contains a count n).\nThere’s just one row in the resulting data frame, because summarise() reduces the data frame (to only include the necessary information)!"
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\nOften, we want to summarize data for specific subgroups. For this aim, summarise() has the .by parameter:\n\ngroup_sum &lt;- dat %&gt;% summarise(total = sum(n), .by=name) \ngroup_sum\n\n# A tibble: 4 × 2\n  name       total\n  &lt;chr&gt;      &lt;int&gt;\n1 Emily     841491\n2 Kathleen  711605\n3 Beverly   376914\n4 Alexandra 231364\n\n\n\nYou can also subgroup by a combination of variables:\n\nbabynames %&gt;% filter(name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\")) %&gt;% #we start with the 4 names regardless of sex\n  summarise(total = sum(n), .by=c(name, sex)) #and then summarise by name, separated for sex\n\n# A tibble: 8 × 3\n  name      sex    total\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Emily     F     841491\n2 Kathleen  F     711605\n3 Beverly   M       4633\n4 Beverly   F     376914\n5 Alexandra F     231364\n6 Emily     M       1744\n7 Kathleen  M       1692\n8 Alexandra M        859"
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 2",
    "text": "Grouping and Summarizing 2\nIn earlier versions, we had to use summarise() together with group_by():\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarise(total = sum(n)) \ngroup_sum\n\n# A tibble: 4 × 2\n  name       total\n  &lt;chr&gt;      &lt;int&gt;\n1 Alexandra 231364\n2 Beverly   376914\n3 Emily     841491\n4 Kathleen  711605\n\n\nWe avoid using group_by() because it can have unintended side effects.\nIt is just part of this class because you will likely encounter it in somebody else’s (old) code.\n\nIf you do have to use it, make sure to ungroup() after summarise() (or mutate()) to avoid unintended effects:\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarise(total = sum(n)) %&gt;% ungroup()"
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 3",
    "text": "Grouping and Summarizing 3\nUse the baby_decades data frame to calculate the mean and median number of observations, grouped by sex & decade.\n\n\nbaby_decades %&gt;% summarise(mean_year = mean(n),\n                           median_year = median(n),\n                           .by=c(sex, decade))\n\n# A tibble: 28 × 4\n   sex   decade mean_year median_year\n   &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 F       1880     111.           13\n 2 M       1880     101.           12\n 3 F       1890     128.           13\n 4 M       1890      93.6          12\n 5 F       1900     131.           12\n 6 M       1900      94.4          12\n 7 F       1910     187.           12\n 8 M       1910     181.           12\n 9 F       1920     211.           12\n10 M       1920     227.           13\n# ℹ 18 more rows"
  },
  {
    "objectID": "W3_DataWranglingR.html#counting-data",
    "href": "W3_DataWranglingR.html#counting-data",
    "title": "03 Data Wrangling",
    "section": "Counting Data",
    "text": "Counting Data\nThere are several ways to get the number of rows per group. You can use the function n() within a call to summarise() (or mutate()). A shortcut is to use count():\n\ndat %&gt;% summarise(n = n(), .by=name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Emily       138\n2 Kathleen    138\n3 Beverly     122\n4 Alexandra   117\n\ndat %&gt;% count(name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Alexandra   117\n2 Beverly     122\n3 Emily       138\n4 Kathleen    138\n\n\nInterestingly, the order of the output may vary. summarise() leaves the data in the original order (i.e., by prop, which (likely) translates to an order by n()). count() arranges the output by the variables for which the counting is done (here: alphabetically by name)."
  },
  {
    "objectID": "W3_DataWranglingR.html#bigger-pipes",
    "href": "W3_DataWranglingR.html#bigger-pipes",
    "title": "03 Data Wrangling",
    "section": "Bigger Pipes!",
    "text": "Bigger Pipes!\nSo far we have often saved intermediate steps in tibbles and used those as input for the next function. With the pipe, we can chain several functions and save relevant results only, no need for crowding the environment with intermediate data.frames or tibbles!\n\npipe_summary &lt;- babynames %&gt;%\n  mutate(decade = floor(year/10) *10) %&gt;%\n  filter(name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"), \n         sex==\"F\") %&gt;%\n  summarise(mean_decade = mean(n), .by=c(name, decade))\n\nIt’s not easy to decide which intermediate steps to save and which not. Usually, it involves some sort of trial and error. Sometimes you go back and break a pipe apart. Sometimes you get overwhelmed by the number of variables in your environment and create bigger pipes.\nAs a rule of thumb: If an intermediate step is only used once, you should probably delete it (unless it makes the code easier to comprehend)."
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data",
    "href": "W3_DataWranglingR.html#tidy-data",
    "title": "03 Data Wrangling",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data: Data that is easily processed by tidyverse functions (also for visualizations and statistical analyses).\nThree principles:\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.\n\n\nWide vs. long format data?\n\n\nWide format: Each participant/animal has one row;\nrepeated observations are in several columns\n\n\n\nID\nTime_1\nTime_2\n\n\n\n\na1\n230\n310\n\n\na2\n195\n220\n\n\na3\n245\n290\n\n\n\n\nLong format: Each observation has its own row;\nthere are (usually) several rows per participant\n\n\n\nID\nTime\nValue\n\n\n\n\na1\n1\n230\n\n\na1\n2\n310\n\n\na2\n1\n195\n\n\na3\n2\n220\n\n\na3\n1\n245\n\n\na3\n2\n290\n\n\n\n\n\n\n\nWide format implements a sparser representation of the data but less tidy!\nIf you want to convert Time from milliseconds into seconds, what do you have to do in both formats?\n\nData often does not come in this format but is rather messy! That’s why we wrangle.\nTidy data is in between wide and long (you can always go longer! :D)"
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data-2",
    "href": "W3_DataWranglingR.html#tidy-data-2",
    "title": "03 Data Wrangling",
    "section": "Tidy Data 2",
    "text": "Tidy Data 2\nWhat do you think, which of the following data sets is tidy?\n\n\n\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\n\n\n\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n\n\n\n# A tibble: 3 × 5\n  country     `1999_cases` `2000_cases` `1999_population` `2000_population`\n  &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 Afghanistan          745         2666          19987071          20595360\n2 Brazil             37737        80488         172006362         174504898\n3 China             212258       213766        1272915272        1280428583\n\n\n\n\n\nTable1 is tidy! (upper)"
  },
  {
    "objectID": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "href": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "title": "03 Data Wrangling",
    "section": "Analyzing the Autism Spectrum Quotient",
    "text": "Analyzing the Autism Spectrum Quotient\nFor the following activities, we will need the following files:\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\npinfo.csv containing participant information such as Age, Sex and importantly ID number."
  },
  {
    "objectID": "W3_DataWranglingR.html#set-up",
    "href": "W3_DataWranglingR.html#set-up",
    "title": "03 Data Wrangling",
    "section": "Set Up",
    "text": "Set Up\nFor the following activities, we will need the following files:\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\npinfo.csv containing participant information such as Age, Sex and importantly ID number.\n\n\nCreate a new script, e.g. as “DataWrangling3.R” (remember we skipped #2 in the book).\nDownload the data into your project folder.\nOptional: Clear your environment (the brush in the top right pane) and/or restart the R session (Session -&gt; Restart R)."
  },
  {
    "objectID": "W3_DataWranglingR.html#load-the-data",
    "href": "W3_DataWranglingR.html#load-the-data",
    "title": "03 Data Wrangling",
    "section": "Load the Data",
    "text": "Load the Data\nFor the following activities, we will need the following files:\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\npinfo.csv containing participant information such as Age, Sex and importantly ID number.\n\n\nLoad the four .csv files into your environment, e.g.:\n\n\nresponses &lt;- read_csv(\"responses.csv\") \nqformats &lt;- read_csv(\"qformats.csv\")\nscoring &lt;- read_csv(\"scoring.csv\")\npinfo &lt;- read_csv(\"pinfo.csv\")"
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data-1",
    "href": "W3_DataWranglingR.html#look-at-the-data-1",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\nIs the data (responses) in a tidy format?\n\n\n# A tibble: 6 × 11\n     Id Q1                 Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9    Q10  \n  &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1    16 Slightly Disagree  Defi… Slig… Defi… Slig… Slig… Slig… Defi… Slig… Slig…\n2    17 Definitely Agree   Slig… Slig… Defi… Defi… Defi… Slig… Slig… Slig… Slig…\n3    18 Definitely Agree   Defi… Slig… Defi… Defi… Defi… Slig… Defi… Defi… Defi…\n4    19 Definitely Agree   Defi… Defi… Slig… Defi… Defi… Slig… Slig… Defi… Slig…\n5    20 Definitely Disagr… Slig… Defi… Slig… Slig… Slig… Slig… Slig… Slig… Slig…\n6    21 Slightly Disagree  Slig… Defi… Slig… Slig… Slig… Defi… Defi… Slig… Slig…\n\n\n\nWhy is it not tidy?\n\nwide format"
  },
  {
    "objectID": "W3_DataWranglingR.html#reformatting-the-data",
    "href": "W3_DataWranglingR.html#reformatting-the-data",
    "title": "03 Data Wrangling",
    "section": "Reformatting the Data",
    "text": "Reformatting the Data\nLet’s bring the wide data in a longer, tidy format!\n\nThere are several functions in R to reformat data, but the newest ones are pivot_longer() and pivot_wider().\nRun the code and see what changes:\n\nrlong &lt;- responses %&gt;% pivot_longer(cols = Q1:Q10, #we can select a range of column names\n                                    #cols = starts_with(\"Q\"), #alternative\n                                    names_to = \"Question\", \n                                    values_to = \"Response\")\n\n\n\nDescribe what the function does, what does the input/the arguments mean?"
  },
  {
    "objectID": "W3_DataWranglingR.html#joining-the-data",
    "href": "W3_DataWranglingR.html#joining-the-data",
    "title": "03 Data Wrangling",
    "section": "Joining the Data",
    "text": "Joining the Data\nWe now want to combine the different data sets: We want to have the information how the questionnaire has to be scored included with the items.\nWe can find the scoring information (i.e. how the questions are framed, positive or negative/whether they need to be reversed) in the qformats tibble. Furthermore, we can find how many points are given to each item/response in scoring.\nWe can use the function inner_join() to merge the tibbles into one bigger tibble.\n\nActivity: Replace the NULL values in the below code with the necessary variable names to join rlong and qformats by Question.\n\nrlong2 &lt;- inner_join(x = NULL, \n                     y = NULL, \n                     by = \"NULL\")\n\n\n\n\nrlong2 &lt;- inner_join(x = rlong, \n                     y = qformats, \n                     by = \"Question\")\n\n\nDescribe what happened?\nwhat is forward and reverse scoring?"
  },
  {
    "objectID": "W3_DataWranglingR.html#combining-more-data",
    "href": "W3_DataWranglingR.html#combining-more-data",
    "title": "03 Data Wrangling",
    "section": "Combining more Data",
    "text": "Combining more Data\nYou can only join two data frames/tibbles at once.\nNow add the scoring data:\n\nrscores &lt;- rlong2 %&gt;% inner_join(scoring, \n                                 c(\"QFormat\", \"Response\"))"
  },
  {
    "objectID": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "href": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "title": "03 Data Wrangling",
    "section": "Calculate the Questionnaire Scores",
    "text": "Calculate the Questionnaire Scores\nHow do we need to group and summarize the data to get a sum score per person? (Ignoring the reverse coding for now!) Add the correct column names instead of the NULL.\n\naq_scores &lt;- rscores %&gt;% summarise(AQ = sum(NULL), .by=NULL)\n\n\n\naq_scores &lt;- rscores %&gt;% summarise(AQ = sum(Score), .by=Id) # sum column Score to obtain AQ scores."
  },
  {
    "objectID": "W3_DataWranglingR.html#pipe-it-all-together",
    "href": "W3_DataWranglingR.html#pipe-it-all-together",
    "title": "03 Data Wrangling",
    "section": "Pipe it all together!",
    "text": "Pipe it all together!\n\naq_scores2 &lt;- responses %&gt;% \n  pivot_longer(cols = Q1:Q10,\n               names_to = \"Question\", \n               values_to = \"Response\") %&gt;%  \n  inner_join(qformats, \"Question\") %&gt;% \n  inner_join(scoring, c(\"QFormat\", \"Response\")) %&gt;% \n  summarise(AQ = sum(Score), .by=Id)"
  },
  {
    "objectID": "W3_DataWranglingR.html#background",
    "href": "W3_DataWranglingR.html#background",
    "title": "03 Data Wrangling",
    "section": "Background",
    "text": "Background\nWe’ll use data from a paper that investigates whether the ability to perform an action influences perception. In particular, the authors wondered whether participants who played Pong would perceive the ball to move faster when they have a small paddle.\n\n\nDownload the data, create a new script.\nClear the environment if you prefer.\nLook at the data."
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions",
    "href": "W3_DataWranglingR.html#solutions",
    "title": "03 Data Wrangling",
    "section": "Solutions",
    "text": "Solutions\n\nlibrary(\"tidyverse\")\npong_data &lt;- read_csv(\"Data/PongBlueRedBack 1-16 Codebook.csv\")\nsummary(pong_data)\n\n  Participant     JudgedSpeed      PaddleLength   BallSpeed    TrialNumber    \n Min.   : 1.00   Min.   :0.0000   Min.   : 50   Min.   :2.0   Min.   :  1.00  \n 1st Qu.: 4.75   1st Qu.:0.0000   1st Qu.: 50   1st Qu.:3.0   1st Qu.: 72.75  \n Median : 8.50   Median :1.0000   Median :150   Median :4.5   Median :144.50  \n Mean   : 8.50   Mean   :0.5471   Mean   :150   Mean   :4.5   Mean   :144.50  \n 3rd Qu.:12.25   3rd Qu.:1.0000   3rd Qu.:250   3rd Qu.:6.0   3rd Qu.:216.25  \n Max.   :16.00   Max.   :1.0000   Max.   :250   Max.   :7.0   Max.   :288.00  \n BackgroundColor      HitOrMiss       BlockNumber   \n Length:4608        Min.   :0.0000   Min.   : 1.00  \n Class :character   1st Qu.:0.0000   1st Qu.: 3.75  \n Mode  :character   Median :1.0000   Median : 6.50  \n                    Mean   :0.6866   Mean   : 6.50  \n                    3rd Qu.:1.0000   3rd Qu.: 9.25  \n                    Max.   :1.0000   Max.   :12.00  \n\n# look at the data (can also use summary(), str(), head() etc.)\nglimpse(pong_data)\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …"
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions-2",
    "href": "W3_DataWranglingR.html#solutions-2",
    "title": "03 Data Wrangling",
    "section": "Solutions 2",
    "text": "Solutions 2\n\nnew_pong_data &lt;- pong_data %&gt;% \n  select(BallSpeed, HitOrMiss, JudgedSpeed, Participant, \n         TrialNumber) %&gt;% \n  arrange(desc(HitOrMiss), desc(JudgedSpeed)) %&gt;% \n  filter(JudgedSpeed == 1,\n         BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"),\n         HitOrMiss == 0) %&gt;% \n  filter(TrialNumber &gt; 2) %&gt;% \n  mutate(TrialNumber = TrialNumber -1) \n  \n  # summarize (use old data frame because we removed variables)\npong_data_hits &lt;- pong_data %&gt;% \n  summarise(total_hits = sum(HitOrMiss, na.rm = TRUE),\n            meanhits = mean(HitOrMiss, na.rm = TRUE),\n            .by=c(BackgroundColor, PaddleLength))"
  },
  {
    "objectID": "W4_DataVizR.html#ggplot",
    "href": "W4_DataVizR.html#ggplot",
    "title": "04 Data Visualization",
    "section": "ggplot",
    "text": "ggplot\nWe will use a package called ggplot2 (which is part of the tidyverse). ggplot2 is a very versatile package and allows us to make beautiful figure, which are immediately ready for publication.\nThe main function to “start” plotting is ggplot() - we will then add layers of data and layers to tweak the appearance.\n\nLayers of a ggplot"
  },
  {
    "objectID": "W4_DataVizR.html#activity-1-set-up",
    "href": "W4_DataVizR.html#activity-1-set-up",
    "title": "04 Data Visualization",
    "section": "Activity 1: Set Up",
    "text": "Activity 1: Set Up\n\nOpen RStudio and load your Biostats R project. Create a new script called DataVisualisation1.R.\nMake sure you have the following two files downloaded into your project folder (we already used them in Intro to R presentation): ahi-cesd.csv and participant-info.csv.\nCopy and run the code below to load the tidyverse package and the data files:\n\n\nlibrary(tidyverse) \n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\n\nRun the following code to combine both files and select our variables of interest:\n\n\nall_dat &lt;- dat %&gt;% inner_join(pinfo, \n                              by=c(\"id\", \"intervention\")) %&gt;% \n  arrange(id, occasion) #joining messes up the order of the data frame =&gt; arrange again\n\n#we throw out several variables even though they would be important for a comprehensive data analysis\nsummarydata &lt;- all_dat %&gt;% select(id, ahiTotal, cesdTotal, #ID & questionnaire scores\n                                  sex, age, educ, income) #demographic variables\n\n\nwhat happens in the code chunk?"
  },
  {
    "objectID": "W4_DataVizR.html#look-at-the-data",
    "href": "W4_DataVizR.html#look-at-the-data",
    "title": "04 Data Visualization",
    "section": "Look at the Data",
    "text": "Look at the Data\nHave a look at the types of data:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;dbl&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;dbl&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;dbl&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\n\nWhat do you see?\n\nAll variables are loaded as numeric. However, are all of those numeric?\n\n\nsex, educ and income don’t seem to really be numbers but factors with individual categories (factor levels)!\nWe should convert these data to factor. Checking and adjusting data types (as part of data wrangling) will be important for plotting and analyzing the data, you might otherwise get strange/wrong results!"
  },
  {
    "objectID": "W4_DataVizR.html#activity-2-transform-data-type",
    "href": "W4_DataVizR.html#activity-2-transform-data-type",
    "title": "04 Data Visualization",
    "section": "Activity 2: Transform Data Type",
    "text": "Activity 2: Transform Data Type\nCopy and run the below code to change the categories to factors.\n\nSo for example, the 1s in sex change to categorical factors instead of numerical 1s.\nIf you mutate a new column with the same name as the old one, it will overwrite the column.\nYou can read each line of the mutate as “overwrite the data that is in that column with the same values now considered factors and not doubles”\n\n\nsummarydata1 &lt;- summarydata %&gt;%\n  mutate(sex = as_factor(sex),\n         educ = as_factor(educ),\n         income = as_factor(income))\n\nglimpse(summarydata1)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;fct&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;fct&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;fct&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\nsummarydata1 %&gt;% pull(educ) %&gt;% unique()\n\n[1] 5 1 4 2 3\nLevels: 1 2 3 4 5"
  },
  {
    "objectID": "W4_DataVizR.html#transform-data-type-2",
    "href": "W4_DataVizR.html#transform-data-type-2",
    "title": "04 Data Visualization",
    "section": "Transform Data Type 2",
    "text": "Transform Data Type 2\nA simple change to a factor is not always helpful. We still don’t know what a 1 in sex or a 5 in educ stands for:\n\n\nsex: 1 = female, 2 = male\neduc: 1 = no graduation, 2 = school graduation, 3 = vocational training, 4 = bachelor’s degree, 5 = post graduate\nincome: 1 = low, 2 = middle, 3 = high\n\n\nsummarydata2 = summarydata1 %&gt;% mutate(sex = sex %&gt;% recode(\"1\" = \"female\", \"2\" = \"male\"),\n                                       educ = educ %&gt;% recode(\"1\" = \"no graduation\",\n                                                              \"2\" = \"school graduation\",\n                                                              \"3\" = \"vocational training\",\n                                                              \"4\" = \"bachelor's degree\",\n                                                              \"5\" = \"post grad\"),\n                                       income = income %&gt;% recode(\"1\" = \"low\",\n                                                                  \"2\" = \"middle\",\n                                                                  \"3\" = \"high\"))\n\n#glimpse(summarydata2)\nsummarydata2 %&gt;% pull(educ) %&gt;% unique()\n\n[1] post grad           no graduation       bachelor's degree  \n[4] school graduation   vocational training\n5 Levels: no graduation school graduation ... post grad\n\n\n\nThere is very sparse information on the variables at https://doi.org/10.5334/jopd.35, so I guesstimated some of the factor levels."
  },
  {
    "objectID": "W4_DataVizR.html#transform-data-type-3",
    "href": "W4_DataVizR.html#transform-data-type-3",
    "title": "04 Data Visualization",
    "section": "Transform Data Type 3",
    "text": "Transform Data Type 3\nrecode() only works with data that are already factors. What if we start with the original data (i.e., summarydata instead of summarydata1)?\n\n# no factors yet =&gt; refer to original data as numbers WITHOUT quotation marks\nsummarydata3 = summarydata %&gt;% mutate(sex = if_else(sex==1, \"female\", \"male\") %&gt;% as_factor(), #could also use case_match\n                       educ = educ %&gt;% case_match(1 ~ \"no graduation\",\n                                                  2 ~ \"school graduation\",\n                                                  3 ~ \"vocational training\",\n                                                  4 ~ \"bachelor's degree\",\n                                                  5 ~ \"post grad\") %&gt;% as_factor(),\n                       income = income %&gt;% case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% as_factor())\n\n#glimpse(summarydata3)\nsummarydata3 %&gt;% pull(educ) %&gt;% unique()\n\n[1] post grad           no graduation       bachelor's degree  \n[4] school graduation   vocational training\n5 Levels: post grad no graduation bachelor's degree ... vocational training\n\n\n\nFactor is now ordered by occurrence in data! :(\n\n\n\nIf data are factors coded as numbers, do as_factor() first and then recode()\nIf data are factors coded as characters, make sure that the ordering is correct (use arrange() for alphabetical order) or create a new factor() with explicit ordering: income %&gt;% factor(levels=c(\"low\", \"middle\", \"high\")))"
  },
  {
    "objectID": "W4_DataVizR.html#the-first-layer",
    "href": "W4_DataVizR.html#the-first-layer",
    "title": "04 Data Visualization",
    "section": "The First Layer",
    "text": "The First Layer\n\nThe first line (or layer) sets up the base of the graph: the data to use and the aesthetics (what will go on the x and y axis, how the plot will be grouped).\naes() can take both an x and y argument, however, with a bar plot you are just asking R to plot the number of data points in each group onto the y-axis, so you do not specify y here.\n\n\n\nggplot(summarydata1, aes(x = sex))"
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer",
    "href": "W4_DataVizR.html#the-second-layer",
    "title": "04 Data Visualization",
    "section": "The Second Layer",
    "text": "The Second Layer\nThe next layer adds a geom or a shape. In this case we use geom_bar() as we want to draw a bar plot.\n\nNote that we are adding layers, using a + between layers. This is a very important difference between pipes and visualization.\n\n\n\nggplot(summarydata1, aes(x = sex)) +\n  geom_bar()"
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer-with-color",
    "href": "W4_DataVizR.html#the-second-layer-with-color",
    "title": "04 Data Visualization",
    "section": "The Second Layer with color",
    "text": "The Second Layer with color\n\nAdding fill to the first layer will separate the data into each level of the grouping variable and give it a different color. In this case, there is a different colored bar for each level of sex.\nWe can get rid of the (in this case redundant legend) with show.legend = FALSE.\n\n\n\nggplot(summarydata1, aes(x = sex, fill = sex)) +\n  geom_bar() #geom_bar(show.legend = FALSE)"
  },
  {
    "objectID": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "href": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "title": "04 Data Visualization",
    "section": "The Next Layers - Improving the Plot",
    "text": "The Next Layers - Improving the Plot\nWe might want to make the plot a bit prettier and easier to read. What would you improve?\n\nWe might want to add better axis labels and change the colors of the bars. We can do so with the functions scale_x_discrete() and scale_y_continuous(), which will adjust the x and y axes.\nWe will use these two arguments in those functions:\n\nname controls/overwrites the axis name (e.g. Groups)\nlabels controls the break points on the axis, i.e. what are the conditions called? The order is important here!\n\n\n\nggplot(summarydata1, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \"Male\")) + #if we didn't set factor labels, we can do here manually (not recommended!)\n  scale_y_continuous(name = \"Number of participants\")\n\n\n\n\n\n\n\nThere’s also the counterparts scale_x_continuous() and scale_y_discrete(). What do you think, why do we use the ones mentioned above and when would we use the other ones?"
  },
  {
    "objectID": "W4_DataVizR.html#themes-changing-the-appearance",
    "href": "W4_DataVizR.html#themes-changing-the-appearance",
    "title": "04 Data Visualization",
    "section": "Themes: Changing the Appearance",
    "text": "Themes: Changing the Appearance\nThere are a number of built-in themes that you can use to change the appearance (background, whether axes are shown etc.), but you can also tweak the themes further manually.\nWe will now change the default theme to theme_minimal(), but you can also try other themes (just type “theme_” and see what the autocomplete brings up).\n\n\nggplot(summarydata2, aes(x = sex, fill = sex)) + #now with summarydata2\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") + #no need to set labels\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal()"
  },
  {
    "objectID": "W4_DataVizR.html#colors",
    "href": "W4_DataVizR.html#colors",
    "title": "04 Data Visualization",
    "section": "Colors",
    "text": "Colors\nThere are various ways to change the colors of the bars. You can manually indicate the colors you want to use but you can also easily use pre-determined color palettes that are already checked for color-blind friendliness.\nA popular palette is viridis. We can simply add a function/layer to your ggplot named scale_fill_viridis_d() (d for discrete). The function has an option parameter that takes 5 different values (A - E).\n\nType and run the below code into a new code chunk. Try changing the option to either A, B, C or D and see which one you like!\n\n\n\nggplot(summarydata1, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")"
  },
  {
    "objectID": "W4_DataVizR.html#transparency",
    "href": "W4_DataVizR.html#transparency",
    "title": "04 Data Visualization",
    "section": "Transparency",
    "text": "Transparency\nYou can also add transparency to your plot, which can be helpful if you plot several layers of data.\nTo do so, you can simply add alpha to the geom_bar():\n\n\nggplot(summarydata1, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")"
  },
  {
    "objectID": "W4_DataVizR.html#grouped-plots",
    "href": "W4_DataVizR.html#grouped-plots",
    "title": "04 Data Visualization",
    "section": "Grouped Plots",
    "text": "Grouped Plots\nLet’s go back to the bar plot (but works similarly for other plots as well): Imagine that you have several factors that you want to use to group your data, such as gender and income. In this case, you could use a grouped bar plot:\n\n\nggplot(summarydata1, aes(x = sex, fill = income)) +\n  geom_bar(position = \"dodge\", #prevents \"stacked\" barplots\n           show.legend = TRUE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\n\n\n\n\nWithout position = dodge, you would get a stacked barplot"
  },
  {
    "objectID": "W4_DataVizR.html#facetting",
    "href": "W4_DataVizR.html#facetting",
    "title": "04 Data Visualization",
    "section": "Facetting",
    "text": "Facetting\nYou could also use facets to divide your data visualizations into several subplots: facet_wrap for one variable.\n\nggplot(summarydata2, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_wrap(vars(income)) #in this function, you need to use vars() around variable names\n\n\n\nWhat is problematic here? We needed percentages for females and males for a better comparison"
  },
  {
    "objectID": "W4_DataVizR.html#facetting-2",
    "href": "W4_DataVizR.html#facetting-2",
    "title": "04 Data Visualization",
    "section": "Facetting 2",
    "text": "Facetting 2\nYou could also use facets to divide your data visualizations into several subplots: facet_grid for a matrix of (combinations of) two variables.\n\nggplot(summarydata2, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_grid(rows=vars(income), \n             cols=vars(educ),\n             labeller = \"label_both\") #this adds the variable name into the facet legends"
  },
  {
    "objectID": "W4_DataVizR.html#violin-boxplot",
    "href": "W4_DataVizR.html#violin-boxplot",
    "title": "04 Data Visualization",
    "section": "Violin-Boxplot",
    "text": "Violin-Boxplot\nLet’s look at the code. How does the code differ from the one for the barplot above?\n\n\nggplot(summarydata1, aes(x = income, \n                        y = ahiTotal, #new variable!\n                        fill = income)) +\n  geom_violin(trim = FALSE, #smooth on edges\n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, #small boxplot contained in violin\n               show.legend = FALSE, \n               alpha = .7)+\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\nIn this case, not the count on the y-axis, but another cont. variable!"
  },
  {
    "objectID": "W4_DataVizR.html#layer-order",
    "href": "W4_DataVizR.html#layer-order",
    "title": "04 Data Visualization",
    "section": "Layer Order",
    "text": "Layer Order\nThe order of layers is crucial, as the plot will be built up in that order (later layers on top):\n\n\n\nggplot(summarydata1, aes(x = income, y = ahiTotal)) +\n  geom_violin() +\n  geom_boxplot()\n\n\n\n\n\n\nggplot(summarydata1, aes(x = income, y = ahiTotal)) +\n  geom_boxplot() +\n  geom_violin()"
  },
  {
    "objectID": "W4_DataVizR.html#scatterplot",
    "href": "W4_DataVizR.html#scatterplot",
    "title": "04 Data Visualization",
    "section": "Scatterplot",
    "text": "Scatterplot\nIf we have continuous data of two variables, we often want to make a scatter plot:\n\n\nggplot(summarydata1, aes(x = age, y = cesdTotal)) +\n  geom_point() +\n  geom_smooth(method=lm) # if you don't want the shaded CI, add se = FALSE to this"
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures",
    "href": "W4_DataVizR.html#saving-your-figures",
    "title": "04 Data Visualization",
    "section": "Saving your Figures",
    "text": "Saving your Figures\nYou can use ggsave() to save your plots. If you don’t tell ggsave() which plot you want to save, by default it will save the last plot you created.\nYou just have to enter the name of the file to be saved (in your working directory) like this:\n\nggsave(\"violin-boxplot.png\")\n\nCheck whether indeed the last plot was saved!\n\n\n\nYou can also specify the dimensions of your plot to be saved:\n\nggsave(\"violin-boxplot.png\",\n       width = 8.5, #width of a typical page in inches (according to APA format)\n       height = 8.5 / sqrt(2), #golden ratio :)\n       units = \"in\")\n\nor\n\nggsave(\"violin-boxplot.png\",\n       width = 1920,\n       height = 1080,\n       units = \"px\") #full HD picture in pixels: 1920 x 1080"
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures-2",
    "href": "W4_DataVizR.html#saving-your-figures-2",
    "title": "04 Data Visualization",
    "section": "Saving your Figures 2",
    "text": "Saving your Figures 2\nYou can also assign the plot to a variable in your environment (just like we did with the tibbles previously) and then tell ggsave() which object to save. This is a bit safer.\nRun the code for the violin-boxplot again and save the plot in an object called viobox. You’d then have to explicitly tell ggsave() to save the object viobox:\n\nviobox &lt;- summarydata1 %&gt;%\n  ggplot(aes(x = income,\n             y = ahiTotal,\n             fill = income)) +\n  geom_violin(trim = FALSE, \n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, \n               show.legend = FALSE, \n               alpha = .7) +\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\nggsave(\"violin-boxplot-stored.png\", plot = viobox)\n\n\nDo not add ggsave() to the plot with a +. Instead run it on a separate line!\nIf plot is assigned to object, it won’t be displayed unless you type viobox in the console!"
  },
  {
    "objectID": "W6_ProbabilityR.html#the-uniform-distribution",
    "href": "W6_ProbabilityR.html#the-uniform-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "The Uniform Distribution",
    "text": "The Uniform Distribution\nIn a uniform distribution, each possible outcome has an equal chance of occurring.\n\nIf we have a hat with 12 paper slips with names, each name has an equal chance (\\(p = \\frac{1}{12} \\approx .08\\)) of being drawn:"
  },
  {
    "objectID": "W6_ProbabilityR.html#the-binomial-distribution",
    "href": "W6_ProbabilityR.html#the-binomial-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "The Binomial Distribution",
    "text": "The Binomial Distribution\nThe binomial (“two categories”) distribution is used for discrete data with two possible outcomes (e.g., flipping a coin). It models the number of successes being observed (e.g., heads), given the probability of success (0.5 for fair coins) and the number of observations (flips of a coin, e.g., 10).\n\nHow many heads (successes) should we expect and with what probability?\nWe can simulate 10 coin flips (or dice) each 10.000 times and count the number of heads (out of the 10). We can use this distribution to work out the probability of different outcomes, e.g., getting at least 3 heads (or 6s) out of 10 tosses (dice rolls).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsuccess: whatever you want, also an “artificial” dichotomization like “roll a 6” vs. “roll no 6”\nadd up probabilities &gt;=3 or 1 - P(X &lt;= 2)"
  },
  {
    "objectID": "W6_ProbabilityR.html#the-normal-distribution",
    "href": "W6_ProbabilityR.html#the-normal-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\nThe normal distribution is very common in statistics (i.e., in the real world). It (roughly) reflects the probability of any value occurring for a continuous variable, such as height.\n\nNormal distribution of height\nThe normal distribution is always symmetrical\n=&gt; equal probability of observations above and below the mean.\n=&gt; the mean, median, and mode are all equal!"
  },
  {
    "objectID": "W6_ProbabilityR.html#normal-distribution-2",
    "href": "W6_ProbabilityR.html#normal-distribution-2",
    "title": "06 Probability & Sampling in R",
    "section": "Normal Distribution 2",
    "text": "Normal Distribution 2\nWe can also use simulations to approximate a normal distribution. This simulation shows that increasing the sample size will get closer to a normal distribution:\n\nA simulation of an experiment collecting height data from 5000 participants."
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-uniform-distribution",
    "href": "W6_ProbabilityR.html#using-the-uniform-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Uniform Distribution",
    "text": "Using the Uniform Distribution\nWe can use runif for a uniform distribution of continuous (numerical) values or\nsample for a uniform distribution of discrete (numerical or text) values.\n\nDraw a random decimal number between 0 and 1\nDraw 100 random decimal numbers between 0 and 10 and calculate their mean.\nDraw 50 random integer numbers between 1 and 10 and calculate their mean.\nDraw who may have the first turn during board game night: Anna, Barbara, Christina, or Dana.\nProduce a random order of all the names of Anna, Barbara, Christina, and Dana.\n\n\n\n#1\nrunif(n=1) #default parameters are already set to min=0 and max=1\n\n[1] 0.4226502\n\n#2\nrunif(n=100, max=10) %&gt;% mean()\n\n[1] 4.641486\n\n#3\nsample(1:10, size=50, replace=T) %&gt;% mean()\n\n[1] 5.78\n\n#4\nsample(c(\"Anna\", \"Barbara\", \"Christina\", \"Dana\"), size=1)\n\n[1] \"Christina\"\n\n#5\nsample(c(\"Anna\", \"Barbara\", \"Christina\", \"Dana\")) #by default, sample draws all elements in random order\n\n[1] \"Dana\"      \"Christina\" \"Anna\"      \"Barbara\""
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-binomial-distribution",
    "href": "W6_ProbabilityR.html#using-the-binomial-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Binomial Distribution",
    "text": "Using the Binomial Distribution\n\n\n\n\ndbinom(): the density distribution gives you the probability of exactly \\(x_i\\) successes given the number of trials and the probability of success on a single trial: \\(P(X = x_i)\\) (e.g., what’s the probability of flipping 8/10 heads with a fair coin?)\n\n\n\n\npbinom(): the (cumulative) probability distribution gives you the cumulative probability of getting a maximum of \\(x_i\\) successes: \\(P(X \\le x_i)\\) (e.g., getting 5 or fewer heads out of 10 flips).\nqbinom(): the quantile function gives you the number of success (x-axis) corresponding to a given cumulative probability: \\(X(P = P_i)\\) (e.g., A maximum of how many heads do you have to expect if you want at least an event probability of 25%?). This is the inverse function of pbinom().\n\nNote: Be aware of the difference between success probability \\(p\\), the probability of the density distribution \\(P(X = x_i)\\), and the probability of the cumulative probability distribution \\(P(X \\le x_i)\\)\n\n\n\n\n\n\n\n\n\n\nWhat’s the probability of getting exactly 5 heads on 10 flips?\nWhat’s the probability of getting 0 to 2 heads on 10 flips?\nWhat’s the probability of getting at least 8 heads on 10 flips?"
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-binomial-distribution-2",
    "href": "W6_ProbabilityR.html#using-the-binomial-distribution-2",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Binomial Distribution 2",
    "text": "Using the Binomial Distribution 2\nNow in R:\n\nWhat’s the probability of getting exactly 5 heads on 10 flips?\nWhat’s the probability of getting 0 to 2 heads on 10 flips?\nWhat’s the probability of getting at least 8 heads on 10 flips?\n\n\n\n#1\ndbinom(x = 5, size = 10, prob = 0.5)\n\n[1] 0.2460938\n\n#2 (indirect way)\ndbinom(x = 0:2, size=10, prob=0.5) %&gt;% sum()\n\n[1] 0.0546875\n\n#2 (direct way)\npbinom(q = 2, size = 10, prob = 0.5) #P(X &lt;= q)\n\n[1] 0.0546875\n\n#3 (careful: minus 1)\npbinom(q = 8-1, size = 10, prob = 0.5, lower.tail = F) #P(X &gt; q) = 1 - P(X &lt;= q)\n\n[1] 0.0546875\n\n\n\n\nNote: The binomial distribution is only symmetrical for \\(p = 50\\%\\).\nThat’s why “a maximum of 2 heads” (0, 1, or 2) has the same probability as “at least 8 heads” (8, 9, or 10).\n\n\nx: the number of ‘heads’ of which we want to know the probability.\nsize: the number of trials (flips) we are simulating; in this case, 10 flips.\nprob: the probability of ‘heads’ on one trial. 50% far a fair coin."
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-binomial-distribution-3",
    "href": "W6_ProbabilityR.html#using-the-binomial-distribution-3",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Binomial Distribution 3",
    "text": "Using the Binomial Distribution 3\nNow let’s use the quantile function qbinom()!\nImagine a friend wants to bet you on tossing a coin and bets that it will be tails. You suspect she has a coin that is not fair and it will be more likely that it turns up as tails.\nYour friend agrees that you can toss the coin 10 times to test it before you have to give your bet.\nyou want to find out whether the coin is fair and ask yourself: What is the minimum number of heads that is acceptable if it is fair?\nWe choose a probability so low that it is unlikely to get a result lower than that if the coin was fair. We will use a typical value for statistical significance: 0.05 (or in 5% of cases we will find a lower value by chance if the coin was fair).\n\n\nqbinom(p = .05, size = 10, prob = .5)\n\n[1] 2\n\n\nIn this case, the probability of success is now called prob because p is now used for the probability cut-off we want to set. This is unnecessarily confusing :(\n\n\nIf we run the code, we get a value of 2. This means that 2 heads is the first time that the cumulative probability function reaches at least 5% . Thus, if we get less than two heads out of the ten tosses, we could conclude that the coin is likely biased (there is only a 5% chance that this would happen if the coin was fair). You would probably not bet with your friend!\n\n\nNote: This is a bad way to test the fairness of a coin (it’s just for illustration of qbinom)! Rather demand that you win at tails (if the coin is fair, your friend shouldn’t mind)."
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-normal-distribution",
    "href": "W6_ProbabilityR.html#using-the-normal-distribution",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Normal Distribution",
    "text": "Using the Normal Distribution\nFor every probability distribution, R provides similar functions starting with d, p, or q. For the normal distribution, those are:\n\n\ndnorm(): density function, for calculating the density (not probability!) of a specific value. Only useful for plotting.\npnorm(): cumulative probability or distribution function, for calculating the probability of getting at least (or at most) a specific value.\nqnorm(): quantile function, for calculating the specific value associated with a given cumulative probability.\n\n\n\nFor the next activities, we will use means and SDs of height from the Scottish Health Survey (2008)."
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-normal-distribution-2",
    "href": "W6_ProbabilityR.html#using-the-normal-distribution-2",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Normal Distribution 2",
    "text": "Using the Normal Distribution 2\nCalculate the probability of meeting a Scottish woman who is as tall or taller than the average Scottish man.\nWhich function would you use?\nHint: You want to know how likely it is that you get a value as extreme or extremer than a specific value (the average height of men) within the distribution for women.\nWhat we know:\n\naverage female height = 163.8, SD = 6.931\naverage male height = 176.2, SD = 6.748\nWe want to know “at least as tall as”\n\n\nWe need the pnorm() function. Fill in the values instead of the NULLs.\n\npnorm(q = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\n\n\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = FALSE)\n\n[1] 0.03680228\n\n\n\n\nNote: For continuous distributions, we don’t have to distinguish between “taller than” and “at least as tall”. \\(P(X \\le x_i) = P(X &lt; x_i)\\)! (Because the probability of one specific value like 176.2000000 m is exactly 0)\n\n\nAlso note: The SD of the distribution of males is not relevant for this question.\n\nDon’t do this:\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = F) + \n  dnorm(x = 176.2, mean = 163.8, sd = 6.931)\n\n[1] 0.04841892\n\n\nYou cannot add a probability and a density together! Just pnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = F) is the correct answer!\nWhen we say “What’s the probability of a woman being 1.80 m tall?”, we actually mean: “What’s the probability of a person being between 1.795 and 1.805 m tall?” (since height is usually measured within steps of 1 cm). We can calculate this, e.g. for Scottish women, using: pnorm(q = 180 + c(-.5, .5), mean = 163.8, sd = 6.931) %&gt;% diff() = 0.3%"
  },
  {
    "objectID": "W6_ProbabilityR.html#using-the-normal-distribution-3",
    "href": "W6_ProbabilityR.html#using-the-normal-distribution-3",
    "title": "06 Probability & Sampling in R",
    "section": "Using the Normal Distribution 3",
    "text": "Using the Normal Distribution 3\nFiona is a very tall Scottish woman (181.12 cm) who will only date men who are as tall or taller than her. What is the probability of Fiona finding a taller man?\nWhat we know:\n\naverage female height = 163.8, SD = 6.931\naverage male height = 176.2, SD = 6.748\nWe want to know “tall or taller”\nFiona’s height = 181.12\n\n\n\npnorm(q = 181.12, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n[1] 0.2329687\n\n\n\n\nConclusion: Fiona shrinks her dating pool to roughly a quarter and may thus consider abandoning beauty standards imposed by society. (Same advice for men, of course)\n\n\n\n\nHow tall would a Scottish man have to be in order to be in the tallest 5% of the height distribution for Scottish men?\n\n\n\nqnorm(p = .05, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n[1] 187.2995"
  },
  {
    "objectID": "W6_ProbabilityR.html#simulate-different-distributions",
    "href": "W6_ProbabilityR.html#simulate-different-distributions",
    "title": "06 Probability & Sampling in R",
    "section": "Simulate Different Distributions",
    "text": "Simulate Different Distributions\nIt is possible to draw data from different distributions:\n\n\nnsamples &lt;- 10000\nnhistbins &lt;- 100\n\n# uniform distribution\np1 &lt;- tibble(x = runif(nsamples)) %&gt;% \n  ggplot((aes(x))) + geom_histogram(bins = nhistbins) + \n  labs(title = \"Uniform\")\n\n# binomial distribution\np2 &lt;- tibble(x = rbinom(nsamples, 20, 0.25)) %&gt;% \n  ggplot(aes(x)) + geom_histogram(bins = nhistbins) +\n  labs(title = \"Binomial (p=0.25, 20 trials)\")\n\n# normal distribution\np3 &lt;- tibble(x = rnorm(nsamples)) %&gt;% \n  ggplot(aes(x)) + geom_histogram(bins = nhistbins) +\n  labs(title = \"Normal\")\n\n# Chi-squared distribution\np4 &lt;- tibble(x = rchisq(nsamples, df=1)) %&gt;% \n  ggplot(aes(x)) + geom_histogram(bins = nhistbins) +\n  labs(title = \"Chi-squared\")\n\ncowplot::plot_grid(p1, p2, p3, p4, ncol = 1)"
  },
  {
    "objectID": "W6_ProbabilityR.html#simulate-a-fake-dataset",
    "href": "W6_ProbabilityR.html#simulate-a-fake-dataset",
    "title": "06 Probability & Sampling in R",
    "section": "Simulate a Fake Dataset",
    "text": "Simulate a Fake Dataset\nLet’s simulate data of 120 participants of different heights and genders flipping a coin. To do so, we need to know how to simulate a) heights, b) flip a coin, and c) assign genders.\n\nSimulate heights:\n\nheights &lt;- rnorm(120, mean = 170, sd = 10)\n\n\n\nSimulate coin flips:\n(Instead of drawing from a probability distribution function that starts with an r, e.g. rnorm(), we use sample(), which randomly (uniformly) draws from values you determine. We need to set replace=TRUE)\n\ncoin_flips &lt;- sample(c(\"Head\", \"Tail\"), 120, replace=TRUE)\n\n\n\nWe could of course use similar code to simulate gender or the like.\nBut if we want to predetermine which genders we want to collect data from (i.e. same number in each gender group), we can also use the function rep(). This function will simply repeat an observation for a number of rows:\n\ngenders &lt;- rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40) #%&gt;% sample() #you can run just \"sample\" on a vector to randomize its order\n\n\n\nDetermine participant numbers and combining everything into one dataframe:\n\nsim_data &lt;- tibble(\n  participant_number = 1:120,\n  gender = rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40),\n  height = rnorm(120, mean = 170, sd = 10),\n  coin_flip = sample(c(\"Head\", \"Tail\"), 120, replace=TRUE)\n)\n\n# or if you have run all the code before, you could also use the objects you have already in your Environment:\n# sim_data &lt;- tibble(participant_number = 1:120, genders, heights, coin_flips)\n\n\nBecause the values of heights and coin flips are random, the assignment of"
  },
  {
    "objectID": "W6_ProbabilityR.html#resampling",
    "href": "W6_ProbabilityR.html#resampling",
    "title": "06 Probability & Sampling in R",
    "section": "Resampling",
    "text": "Resampling\nIf we wanted to do a Monte Carlo Simulation, we could use the code from the last slide and put the simulation into a for loop. Inside the for loop, we would also calculate some value of interest (one estimate per subsample, such as the mean)."
  },
  {
    "objectID": "W6_ProbabilityR.html#resampling-2",
    "href": "W6_ProbabilityR.html#resampling-2",
    "title": "06 Probability & Sampling in R",
    "section": "Resampling 2",
    "text": "Resampling 2\nBut for now, let’s look at the Bootstrap. Remember that we usually use real data for bootstrapping and draw samples with replacement of the same size as the original dataset. We can use this to quantify uncertainty, such as with the Standard Error of the Mean (SEM) or Confidence Intervals.\nLet’s say we have a very small sample of “sweets consumed”. We don’t know the underlying distribution. We make up a dataset, but let’s pretend it is our real data:\n\ndata_10 &lt;- tibble(\n  participant = 1:10,\n  sweets = c(5, 5, 5, 7, 3, 3, 4, 6, 8, 4)\n)\n\n\nWe want to know how sample size influences the SEM, so we also have a sample with twice 10x as many observations:\n\ndata_20 &lt;- tibble(\n  participant = 1:100,\n  sweets = rpois(100,4) #random Poisson distribution\n)"
  },
  {
    "objectID": "W6_ProbabilityR.html#resampling-3",
    "href": "W6_ProbabilityR.html#resampling-3",
    "title": "06 Probability & Sampling in R",
    "section": "Resampling 3",
    "text": "Resampling 3\nLet’s resample 1000 times. To get the sampling distributions of the means, we have to save each mean of each iteration:\n\nset.seed(8465123)\niterations &lt;- 1000 \n\n# initialize empty matrices\nmean_bootstrap_10 &lt;- matrix(NA, nrow = iterations, ncol = 1)\nmean_bootstrap_20 &lt;- matrix(NA, nrow = iterations, ncol = 1)\n\nfor (i in 1:iterations) {\n  # draw exactly the same amount of datapoints as in the original dataset, but with replacement\n  bootstrap_data_10 &lt;- sample_n(data_10, 10, replace=TRUE)\n  bootstrap_data_20 &lt;- sample_n(data_20, 20, replace=TRUE)\n  \n  # calculate the mean for each of the subsamples, put it into matrix in subsequent rows\n  mean_bootstrap_10[i,1] &lt;- mean(bootstrap_data_10$sweets)\n  mean_bootstrap_20[i,1] &lt;- mean(bootstrap_data_20$sweets)\n}\n\n# calculate the SEMs\nsd(mean_bootstrap_10)\n\n[1] 0.4948013\n\nsd(mean_bootstrap_20)\n\n[1] 0.4646242\n\n\nWe can conclude that the SEM is smaller with a larger sample size, which means we can be more certain about our estimate! (We already knew this from the \\(\\sqrt{n}\\) in the denominator of the SE formular but it’s nice to see it confirmed.)"
  },
  {
    "objectID": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "href": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "title": "07 Hypothesis Testing",
    "section": "Null Hypothesis Significance Testing",
    "text": "Null Hypothesis Significance Testing\nExample: We have two groups (treatment and control). We also have a hypothesis: The treatment group has lower scores on measure X (e.g., symptoms). We have the data (X for both groups), now what?\n\n\nWe take the hypothesis (treatment = lower X than control) and negate it (Treatment not lower/equal X compared to control). This is our null hypothesis.\nThen we look at the data and determine how likely they would be if the null hypothesis were true.\nI.e., we want to know the conditional probability: \\(P(Data|H_0)\\)\nIf the data are very unlikely we reject the null hypothesis in favor of the alternative hypothesis (our hypothesis).\n(If the data are not very unlikely, we stick with - or fail to reject - the null hypothesis.)\n\n\n\nHow would you compare the two groups? Calculate the likelihood that there is a reduction in X between the groups? No, more complicated! And counterintuitive!"
  },
  {
    "objectID": "W7_Hypothesis.html#the-process-of-nhst",
    "href": "W7_Hypothesis.html#the-process-of-nhst",
    "title": "07 Hypothesis Testing",
    "section": "The Process of NHST",
    "text": "The Process of NHST\nTo be more precise, we can break down the process of null hypothesis testing in six steps:\n\n\nFormulate a hypothesis that embodies our prediction (before seeing the data)\nSpecify null and alternative hypotheses that reflect the hypothesis formulated in step 1\nCollect some data relevant to the hypothesis\nFit a model to the data that represents the alternative hypothesis and compute a test statistic\nCompute the probability of the observed value of that statistic assuming that the null hypothesis is true\nAssess the “statistical significance” of the result\n\n\n\nLet’s go through these steps, using the NHANES dataset and the research question: Is physical activity related to body mass index (BMI)?"
  },
  {
    "objectID": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "href": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "title": "07 Hypothesis Testing",
    "section": "Step 1: Formulate a Hypothesis of Interest",
    "text": "Step 1: Formulate a Hypothesis of Interest\nHypothesis:\n\n“BMI is greater for people who do not engage in physical activity than for those who do.”\n\nask for hypothesis?"
  },
  {
    "objectID": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "href": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "title": "07 Hypothesis Testing",
    "section": "Step 2: Specify the Null and Alternative Hypotheses",
    "text": "Step 2: Specify the Null and Alternative Hypotheses\nThe null hypothesis (\\(H_0\\)) is the baseline against which we test our hypothesis of interest.\nThe alternative hypothesis (\\(H_A\\)) describes what we expect if there is an effect.\nNHST works under the assumption that the \\(H_0\\) is true (unless the evidence shows otherwise).\n\nWe also have to decide whether we want to test a non-directional (\\(A \\neq B\\)) or directional (\\(A&gt;B\\) or \\(A&lt;B\\)) hypothesis.\nWhat do we specify if we hypothesize that “BMI is greater…”?\n\n\n\\(H_0 = BMI_{active} \\ge BMI_{inactive}\\)\n\\(H_A = BMI_{active} &lt; BMI_{inactive}\\)\n\nTest against \\(H_0\\): What would we expect the data to look like if there was no effect?\nNon-directional: no direction! :D Directional: prior knowledge"
  },
  {
    "objectID": "W7_Hypothesis.html#step-3-collect-data",
    "href": "W7_Hypothesis.html#step-3-collect-data",
    "title": "07 Hypothesis Testing",
    "section": "Step 3: Collect Data",
    "text": "Step 3: Collect Data\nFor this example, we sample 250 individuals from the NHANES dataset.\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.1942\n8.9851\n\n\nYes\n119\n26.6386\n5.2499"
  },
  {
    "objectID": "W7_Hypothesis.html#step-4-fit-a-model",
    "href": "W7_Hypothesis.html#step-4-fit-a-model",
    "title": "07 Hypothesis Testing",
    "section": "Step 4: Fit a Model",
    "text": "Step 4: Fit a Model\nWe want to compute a test statistic that helps us decide whether to reject \\(H_0\\) or not.\n\nThe model we fit needs to quantify (= provide the test statistic) the amount of evidence in favor of \\(H_A\\) relative to the variability of the data.\nThe test statistic will have a probability distribution, allowing us to determine how likely our observed value of the statistic is under \\(H_0\\).\n\n\nIn general, we want to relate an effect (e.g., a mean or a difference of means) to the amount of uncertainty in the data (e.g., the SEM).\n\n\nIn the example, we need a test statistic that tests the difference between two means (we have one BMI mean for each group): The t statistic.\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the means of the two group, \\(S_1^2\\) and \\(S_2^2\\) are the estimated variances of the groups, \\(n_1\\) and \\(n_2\\) are the sizes of the two groups.\n\n\n\\(\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\\) is something like the pooled (“averaged”) SEM of both groups.\n\nThe t statistic is appropriate for comparing the means of two groups when the sample sizes are relatively small and the population standard deviation is unknown.\n\\(\\sqrt{\\frac{S_1^2}{n_1}}\\) alone would be the SEM of subsample 1. But we have to add first before we take the square root.\nReason for adding: The variance of a difference between (or sum of) two independent variables is the sum of the variances of each individual variable (\\(Var(A−B)=Var(A)+Var(B)\\))\none can view the the t statistic as a way of quantifying how large the difference between groups is in relation to the sampling variability of the difference between means"
  },
  {
    "objectID": "W7_Hypothesis.html#the-t-distribution",
    "href": "W7_Hypothesis.html#the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "The t Distribution",
    "text": "The t Distribution\nThe t statistic is distributed according to the t distribution, which looks similar to a normal distribution (the more degrees of freedom, the more “normal”).\nDegrees of freedom for the t test: \\(observations - 2\\) = \\(n_1 + n_2 - 2\\) (when the groups are the same size).\nDegrees of freedom: values that can freely vary when estimating parameters. Usually sample size minus values that you already calculated (e.g. means for the test statistic).\n\n\n\n\n\n\nIf the group sizes are unequal: \\(\\mathrm{d.f.} = \\frac{\\left(\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\right)^2}{\\frac{\\left(S_1^2/n_1\\right)^2}{n_1-1} + \\frac{\\left(S_2^2/n_2\\right)^2}{n_2-1}}\\)\nFortunately, R does all these calculations for us :)\n\nDF: we have calculated two means and have thus given up two DFs (these are fixed already)\nWill be smaller if sample sizes unequal (here 241.12 vs 248 for equal)\nDegrees of freedom are the number of independent values that a statistical analysis can estimate. You can also think of it as the number of values that are free to vary as you estimate parameters"
  },
  {
    "objectID": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "href": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "title": "07 Hypothesis Testing",
    "section": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis",
    "text": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis\nWe do not check likelihood of the alternative distribution or likelihood that the null hypothesis is true, but rather:\nHow likely is it, given that we assume \\(H_0\\) is true, to observe a statistic at least as extreme as the one we observed.\n--&gt; We need to know the distribution of the expected statistic, assuming \\(H_0\\) is true. Then we can calculate how (un-)likely it is to find the statistic (or a more extreme value) we found in our data.\n\n\n\n\n\n\n\ncounter-intuitive: We check the nulldistribution not the one of \\(H_A\\)! But we also don’t check how likely it is that \\(H_0\\) is true, but rather the likelihood under the null hypothesis of observing a statistic at least as extreme as the one we observed.\nat least as extreme: Prob of each particular value = 0\ntry to find out how weird statistic found is (or weirder) –&gt; count all weird(er) possibilities"
  },
  {
    "objectID": "W7_Hypothesis.html#a-simple-example",
    "href": "W7_Hypothesis.html#a-simple-example",
    "title": "07 Hypothesis Testing",
    "section": "A Simple Example",
    "text": "A Simple Example\nIs a coin biased if we flip a coin 100x and we get 70 heads?\n\\(H_0: P(heads) \\le 0.5\\) and \\(H_A: P(heads) &gt; 0.5\\)\nTest statistic = number of heads counted.\nHow likely is it that we would observe 70 or more heads if the coin is unbiased (chance of 50% for heads)?\n\nIf we flip a (fair) coin 100 times, we would get the following distribution (100000 replications):\n\n\n\n\n\nIt is very unlikely to get 70 heads if the coin is fair!\n\nfair coin: null distribution"
  },
  {
    "objectID": "W7_Hypothesis.html#p-value",
    "href": "W7_Hypothesis.html#p-value",
    "title": "07 Hypothesis Testing",
    "section": "P-Value",
    "text": "P-Value\nLet’s go back to out BMI example.\nWe first need to calculate the t statistic:\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.1942\n8.9851\n\n\nYes\n119\n26.6386\n5.2499\n\n\n\n\n\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\[t = \\frac{30 - 27}{\\sqrt{\\frac{9^2}{131} + \\frac{5.2^2}{119}}}\\]\n\\[t = 3.86\\]\n\nThe question is: What is the likelihood that we would find a t statistic of this size or more extreme given the number of degrees of freedom and if the true difference between the groups is zero.\n\n\n\n\\(t\\) statistics if we use the unrounded values!"
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-2",
    "href": "W7_Hypothesis.html#p-value-2",
    "title": "07 Hypothesis Testing",
    "section": "P-Value 2",
    "text": "P-Value 2\nWe can use the t distribution to calculate this probability. We just need the degrees of freedom, which are \\(DF = 241.12\\), and we can then use all these values (e.g. in a function in R):\n\n\n[1] 7.282672e-05\n\n\nThis small probability tells us that our observed t value is relatively unlikely if \\(H_0\\) is really true.\n\nThis is the p-Value for a directional hypothesis. In this case, we only looked at the upper tail probability. With a non-directional hypothesis, we would want to account for both tail probabilities, i.e. how likely it is that a \\(t &gt; 3.86\\) OR \\(t &lt; -3.86\\) is found. In this case, we can simply multiply the p-Value found above by 2 (since it is a symmetric distribution):\n\\(p = 0.000145\\)"
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-using-randomization",
    "href": "W7_Hypothesis.html#p-value-using-randomization",
    "title": "07 Hypothesis Testing",
    "section": "P-Value using Randomization",
    "text": "P-Value using Randomization\nWe can also use our simulation skills to determine the null distribution!\n\nWe can randomly rearrange (or permute) data so that no relationship is present, e.g. assigning group membership to the participants randomly. In this case, \\(H_0\\) should thus be true.\nWe would do this a large amount of times (e.g. 10000), calculate the t statistics for each iteration, and draw a histogram to show the distribution."
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization-2",
    "href": "W7_Hypothesis.html#p-values-using-randomization-2",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization 2",
    "text": "P-Values using Randomization 2\n\n# create function to shuffle BMI data\nshuffleBMIstat &lt;- function() {\n  bmiDataShuffled &lt;- \n    NHANES_sample %&gt;%\n    select(BMI, PhysActive) %&gt;%\n    mutate(\n      BMI = sample(BMI) #randomly shuffle BMI values\n    )\n  # compute the difference\n  simResult &lt;- t.test( #t.test function is more convenient than pt function!\n    BMI ~ PhysActive,\n    data = bmiDataShuffled,\n  )\n  return(simResult$statistic)\n}\n# run function 5000 times and save output\nnRuns &lt;- 5000\nmeanDiffSimDf &lt;- tibble(meanDiffSim = replicate(nRuns, shuffleBMIstat()))\n#run t test of actual data\nbmtTTest &lt;- \n  t.test(\n  BMI ~ PhysActive,\n  data = NHANES_sample,\n  alternative = \"greater\"\n)\n#compare actual data with simulation\nbmiPvalRand &lt;- \n  mean(meanDiffSimDf$meanDiffSim &gt;= bmtTTest$statistic)\n\n#plot everything\nplot = meanDiffSimDf %&gt;% \n  ggplot(aes(meanDiffSim)) +\n  geom_histogram(bins = 200) +\n  geom_vline(xintercept = bmtTTest$statistic, color = \"blue\") +\n  xlab(\"T stat: BMI difference between groups\") +\n  geom_histogram(\n    data = meanDiffSimDf %&gt;% \n      filter(meanDiffSim &gt;= bmtTTest$statistic), \n    aes(meanDiffSim), \n    bins = 200, \n    fill = \"gray\"\n  )\nprint(plot)"
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization-3",
    "href": "W7_Hypothesis.html#p-values-using-randomization-3",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization 3",
    "text": "P-Values using Randomization 3\n\nThe blue line is the observed t statistic. We can calculate a p-Value by counting how many of the simulated t-values are at least as extreme as our observed one and dividing it by the number of simulations. The p-value obtained from randomization (0.000000) is kind of similar to the one obtained using the t distribution (0.000075).\n\nUsing simulations to get the null distribution can be helpful if the assumptions (normal distribution in each group) are violated or if we don’t know the theoretical distribution of the test statistic!\n\nexchangeability: We can use permutations if all observsations are distributed in the same way, such that we can shuffle them without changing the overall distribution.\nNot the case if we have dependent observations, e.g. siblings…"
  },
  {
    "objectID": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "href": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "title": "07 Hypothesis Testing",
    "section": "Step 6: Assess the “Statistical Significance” of the Result",
    "text": "Step 6: Assess the “Statistical Significance” of the Result\nIs the p-value determined small enough to reject the null hypothesis (and thus conclude that the alternative hypothesis is true)?\n\nTraditionally, we reject \\(H_0\\) if the p-value is less than 0.05. (Fisher’s approach)\n\n\n(Either there is an effect/\\(H_A\\) is true or there is a small chance (5%) that there is actually no effect but we coincidentally found such a large value –&gt; false positive)\n\n\nNeyman-Pearson approach: In the long run, we will know how often we are wrong:\n\n\\(\\alpha = .05\\) (false positives or Type I error: We reject \\(H_0\\) although it is correct),\n\\(\\beta = .2\\) (false negatives or Type II error: We accept \\(H_0\\) although it is wrong),\nWe will be correct if we reject \\(H_0\\) when it is wrong (there is actually a difference/an effect) or if we do not reject \\(H_0\\) when it is correct (and there is no difference between groups).\n\nIn both cases, a significance level of \\(\\alpha = .05\\) is usually used.\n\nHow much evidence do we require?\n0.05 Fisher never intended it to be fixed\nBefore computers, tables were used, and all tables had .05 in it!\nFisher: Evidence for hypothesis, NP: long-run error rate"
  },
  {
    "objectID": "W7_Hypothesis.html#what-does-a-significant-result-mean",
    "href": "W7_Hypothesis.html#what-does-a-significant-result-mean",
    "title": "07 Hypothesis Testing",
    "section": "What does a significant result mean?",
    "text": "What does a significant result mean?\nThere is a lot of discussion about the usefulness of using \\(\\alpha = .05\\) as well as about the interpretation of a significant result/certain p-value!\n\n\nA p-value of .01 does….\n\nNOT mean that the probability that \\(H_0\\) is true is 1%!\n\nWe tested \\(P(data|H_0)\\) not \\(P(H_0|data)\\)!\n\nNOT mean that the probability that you’re making a wrong decision is 1%!\n\nThis would also be \\(P(H_0|data)\\)! p-values are probabilities of data (under \\(H_0\\)), not probabilities of hypotheses! And we cannot easily use Bayes to turn the condition because we would need additional information like the prior probability of an alternative hypothesis being true.\n\nNOT mean that you would get the same significance 99% of the time if you repeated the study.\n\nThe p-value is a statement about the likelihood of one particular dataset under the null.\n\nNOT mean that you found a practically important effect.\n\nDifference between statistical significance and practical significance! Effect sizes more important. (Statistical significance depends on sample size!)"
  },
  {
    "objectID": "W7_Hypothesis.html#multiple-testing",
    "href": "W7_Hypothesis.html#multiple-testing",
    "title": "07 Hypothesis Testing",
    "section": "Multiple Testing",
    "text": "Multiple Testing\nNowadays, we often have huge datasets in neuroscience, e.g. collecting brain imaging data of thousands of voxels or quantifying the entire genome.\n\nLet’s look at genome-wide associations studies (GWAS). We have more than a million places in where the genome could differ. If we want to know whether schizophrenia was associated with any of these differences, we would do ~1.000.000 tests! If we simply used \\(\\alpha \\le .05\\) as a threshold, we would get a lot of (\\(1000000 * .05 = 500\\)!) false positives, even if no true effect is present at all.\n\n\nIn this case, we have a lot of dependent tests, which form a family of tests. In such a case, we need to control the family-wise error rate, e.g. by fixing it to a total of \\(\\alpha \\le .05\\) (i.e. the probability of making any Type I error in our study is controlled at .05).\n\n\nOne option is to use the Bonferroni correction, in which we divide .05 by the number of tests (e.g. 1.000.000) and use the new value (\\(\\alpha \\le .000005\\)) as threshold for each individual test.\n\n\nThis is extremely conservative and often results in false negative test results.\n\n\nFor an interesting example what can happen when not correcting for multiple comparisons, see this dead fish showing significant brain activity (Link)."
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals",
    "href": "W7_Hypothesis.html#confidence-intervals",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nSingle value statistic (e.g. t-value, mean…) = point estimate\n\nWe know from the sampling error discussion that each point estimate comes with some uncertainty, described by the standard error.\nRemember, the SEM (standard error of the mean) was calculated with the sample standard deviation \\(\\hat{\\sigma}\\) and the square root of the sample size \\(n\\):\n\\[SEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\]\n\\(n\\) is generally under our control (\\(\\hat{\\sigma}\\) is unknown but fixed*), and we can thus decrease our uncertainty by increasing the sample size.\n\n\n\nWe can more directly describe our uncertainty with confidence intervals (CI), which provides a range of values for our parameter estimate that are consistent with our data! The wider the CI, the more uncertain we are about our estimate.\n\n\n* In practice, we can acquire homogeneous samples (like students) or heterogeneous samples (like extreme groups). This will, however, influence our generalizability."
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-2",
    "href": "W7_Hypothesis.html#confidence-intervals-2",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 2",
    "text": "Confidence Intervals 2\nBecause the CI depends on the SEM, which decreases with sample size, the CI also gets narrower with increasing sample size:\n\n\nif we sample the whole population, we know the population parameter and there is no uncertainty at all!\nRange of possible values (estimate) in concordance with the data"
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-3",
    "href": "W7_Hypothesis.html#confidence-intervals-3",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 3",
    "text": "Confidence Intervals 3\nJust like p-values, confidence intervals can be confusing because they are counter-intuitive: A 95% CI for a statistic does NOT mean that we can have 95% confidence that the true parameter falls within this interval!\nIt is, again, the long-run probability: It will contain the true population parameter 95% of the time in the long-run.\nLet’s sample 100 times with \\(n = 250\\) from the NHANES data and calculate CIs. We use the NHANES mean as true score (dashed line) and check how often the CI misses to include it: 5% of the time.\n\n\nbut: new experiment = new estimate (under exact same conditions would work)!"
  },
  {
    "objectID": "W7_Hypothesis.html#calculating-the-ci",
    "href": "W7_Hypothesis.html#calculating-the-ci",
    "title": "07 Hypothesis Testing",
    "section": "Calculating the CI",
    "text": "Calculating the CI\nWe calculate the CI as follows:\n\\(CI = \\text{point estimate} \\pm \\text{critical value} * \\text{standard error}\\)\nThe “critical value” depends on the sampling distribution. Most of the time, we will use the normal distribution.\n\nCI depends on the confidence level (95%, critical value), the sample size and the variability in the data (both SE)"
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Normal Distribution",
    "text": "CI using the Normal Distribution\nThe critical value are the values of the standard normal distribution that capture 95% (in case of a 95% CI) of the distribution, i.e. the 2.5th and 97.5th percentile.\n\nqnorm(p=c(.025,.975))\n\n[1] -1.959964  1.959964\n\n\nThe CI of the mean would thus be:\n\\(CI = \\bar{X} \\pm 1.96*SE\\)\nOur mean weight in the NHANES sample was 79.92 kg and the SE was \\(\\frac{SD_{weight}}{\\sqrt{n}} = 1.35\\) (for a random \\(n=250\\) subsample)*.\n\nThe lower boundary of the CI of the mean would then be \\(CI = 79.92 - 1.96 * 1.35 = 77.28\\) and the upper \\(CI = 79.92 + 1.96 * 1.35 = 82.56\\). We would write this as [77.28, 82.56].\n\n* In practice, both the mean and standard deviation will be subject to sampling error, i.e., CIs will differ both in location and size despite having the same sample size (cf. plot 2 slides ago)"
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the t Distribution",
    "text": "CI using the t Distribution\nIf we don’t know the population standard deviation, which is usually the case, it is more appropriate to use the t distribution.\nIn this case, we use the critical value of the t distribution:\n\nqt(p = c(.025, .975), 250) #t distribution depends on sample size! =&gt; n = 250\n\n[1] -1.969498  1.969498\n\n\nFor the NHANES weight example, the CI would be: \\(79.92 \\pm 1.97 * 1.35 = [77.15, 82.58]\\).\nThe CI for a t distribution is always larger than for a normal distribution. In practice, this difference is negligible at \\(n \\ge 30\\) (1.984 vs. 1.960).\n\nThe t distribution is wider than the normal distribution (especially for smaller samples), which means that the CI will be slightly wider -&gt; extra uncertainty smaller samples.\npopulation parameter hast a fixed value, so it either falls into CI or not. (Doesn’t make sense to talk about probability of it)"
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "href": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Bootstrap",
    "text": "CI using the Bootstrap\nIf we can’t assume normality or don’t know the sampling distribution, we can also use the bootstrap to compute the CI.\n\nReminder: bootstrap = resampling with replacement, using this distribution as the sampling distribution!\n\n\nIf we use an R function for bootstrapping (boot()), we get CI estimates that are fairly close to the ones calculated:\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bs, type = \"perc\")\n\nIntervals : \nLevel     Percentile     \n95%   (78.41, 83.81 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\n\n\nMethod\nCI\n\n\n\n\nnormal distribution\n[77.28, 82.56]\n\n\nt distribution\n[77.15, 82.58]\n\n\nbootstrap\n[78.41, 83.81]\n\n\n\n\n\nNote: CIs from the normal and t distribution are always symmetrical around the mean (here: 79.92), bootstrapped intervals need not be."
  },
  {
    "objectID": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "href": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "title": "07 Hypothesis Testing",
    "section": "Relationship of CIs to Hypothesis Tests",
    "text": "Relationship of CIs to Hypothesis Tests\nIf the CI does not include the value of the null hypothesis (usually 0), then the associated two-sided one sample test would be significant.\n\nIf we want to compare two conditions, it gets trickier.\n\nIf each mean is contained within the CI of the other mean, then there’s definitely no significant difference.\nIf there is no overlap between CIs, then there is certainly a significant difference (two-sidedly).\nIf the CIs overlap (but don’t contain the other mean), it depends on the relative variability of the two variables\n\nIn general, avoid this “eyeball test” and look at the p value!\nNote: Slightly overlapping CIs can still be significant (e.g., one sided hypothesis)"
  },
  {
    "objectID": "W7_Hypothesis.html#effect-sizes",
    "href": "W7_Hypothesis.html#effect-sizes",
    "title": "07 Hypothesis Testing",
    "section": "Effect Sizes",
    "text": "Effect Sizes\nPractical significance!\nWe need a standard way to describe the size of an effect.\nAn effect size is a standardized measurement that compares the size of an effect to e.g. the variability of the statistic. This is also referred to as signal-to-noise ratio.\nThere are many different variants of effect sizes!"
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d",
    "href": "W7_Hypothesis.html#cohens-d",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d",
    "text": "Cohen’s d\nCohen’s d is used to quantify the difference between two means, in terms of their SD:\n\\[d = \\frac{\\bar{X_1} - \\bar{X}_2}{s}\\]\nwhere \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the means of the two groups and \\(s\\) is the pooled SD:\n\\[s = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}}\\]\nwhich is a combination of both groups’ SDs (\\(s_1\\) and \\(s_2\\)) weighted by their sample size (\\(n_1\\) and \\(n_2\\)).\n\nNote that this is very similar to the t statistic, only the denominator differs:\nt = SEM, d = SD of the data\n–&gt; d will not grow with sample size but remain stable!"
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d-2",
    "href": "W7_Hypothesis.html#cohens-d-2",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d 2",
    "text": "Cohen’s d 2\nThere is a commonly used interpretation of Cohen’s d (although it is criticized to use these cutoffs!):\n\n\n\nInterpetation of Cohen’s d\n\n\nd\nInterpretation\n\n\n\n\n0.0 - 0.2\nnegligible\n\n\n0.2 - 0.5\nsmall\n\n\n0.5 - 0.8\nmedium\n\n\n&gt; 0.8\nlarge\n\n\n\n\n\n\nEven with a large effect of \\(d = 1.78\\) (as in the NHANES data set), the distributions still overlap greatly!\n\n\n\n\n\n\nSmall effect but huge total impact: Psychosocial stress due to Covid-19 (deployed to a whole population)"
  },
  {
    "objectID": "W7_Hypothesis.html#pearsons-r",
    "href": "W7_Hypothesis.html#pearsons-r",
    "title": "07 Hypothesis Testing",
    "section": "Pearson’s r",
    "text": "Pearson’s r\nPearson’s r is a correlation coefficient, and thus a measure of the strength of a linear relationship between two continuous variables.\nr can vary from -1 to 1: -1 is a perfect negative relationship, 0 no (linear) relationship, and 1 a perfect positive relationship. Try your skills eye-balling the size of a correlation: https://www.guessthecorrelation.com/\n\n\nmore on correlations later in the semester!"
  },
  {
    "objectID": "W7_Hypothesis.html#odds-ratio",
    "href": "W7_Hypothesis.html#odds-ratio",
    "title": "07 Hypothesis Testing",
    "section": "Odds Ratio",
    "text": "Odds Ratio\nFor binary variables, the odds ratio is a useful effect size.\nOdds describes the relative likelihood of some event happening versus not happening:\n\\[\n\\text{odds of A} = \\frac{P(A)}{P(\\neg{A})}\n\\]\nOdds ratio is simply the ratio of two odds, i.e. \\(\\frac{\\text{odds of A}}{\\text{odds of B}}\\).\n\nExample:\n\n\n\nLung cancer occurrence separately for current smokers and those who have never smoked\n\n\nStatus\nNeverSmoked\nCurrentSmoker\n\n\n\n\nNo Cancer\n2883\n3829\n\n\nCancer\n220\n6784\n\n\n\n\n\n\\[OR = \\frac{\\frac{220}{220+2883}}{\\frac{6784}{6784+3829}} = 23.22 \\]\nThe odds ratio of 23.22 tells us that the odds of lung cancer in smokers are roughly 23x higher than that of non-smokers!"
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power",
    "href": "W7_Hypothesis.html#statistical-power",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\nRemember: Type I and Type II error!\nTolerance for Type I errors set to \\(\\alpha = 0.05\\), which is very low –&gt; we want to avoid this error!\nWhat about Type II errors?\n\nType II = failing to reject \\(H_0\\) although an effect exists (often set at \\(\\beta = 0.20\\), i.e., a statistical power of \\(80\\%\\)).\nBut \\(\\beta\\) also depends on the effect size: The likelihood of finding a large effect is higher than finding a small effect (at constant \\(n\\))!\n\n\nStatistical power is the complement of the Type II error:\nThe likelihood of finding a positive result given that it exits!\n\\[power = 1 - \\beta\\]\n\n\nStatistical power is affected by three factors:\n\nsample size (larger n = more power)\neffect size (larger effect = more power)\nType I error rate (smaller Type I error = less power)\n\n\nType I: false positives\nType II: false negatives"
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power-2",
    "href": "W7_Hypothesis.html#statistical-power-2",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power 2",
    "text": "Statistical Power 2\nHere, we can see how these three factors influence the power (i.e. the proportion of significant results found):\n\nThe black dotted line denotes the standard 80% power that is often aimed at.\n\nEven with \\(n = 96\\), we have only little power to detect a small effect (\\(d = 0.2\\)): Only ~25% of studies would find the true effect. This means doing this study would be futile, we would likely fail to find the true effect.\n\n\nTherefore, we would do a power analysis before we even run the study - to determine the necessary sample size for a well-powered study that would be able to find an effect if the effect is true.\nFurthermore, positive findings from an underpowered study are more likely to be false positive!\n\nMore on that in Chapter 18 of ST21!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test",
    "href": "W8_ModelingRelationships.html#chi²-test",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test",
    "text": "Chi² Test\nWe will first focus on modeling categorical relationships (of variables that are qualitative!).\n\nThese data are usually expressed in terms of counts.\n\n\nExample: Candy colors\nBag of candy: 30 chocolates, 33 licorices, and 37 gumballs.\n\n\nIs the distribution fair (i.e., 1/3rd of the bag = each candy) and the fact that there are only 30 chocolates a random accident?\n\n\nWhat is the likelihood that the count would come out this way (or even more extreme) if the true probability of each candy type is the same?\n\nCounts: For each combination of variables, how many observations do we have?\nIf the machine really sorts on average 1/3 of each in each bag? How much is due to chance?"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-2",
    "href": "W8_ModelingRelationships.html#chi²-test-2",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test 2",
    "text": "Chi² Test 2\nThe Chi² test checks whether observed counts differ from expected values (\\(H_0\\)).\n\\[\n\\chi^2 = \\sum_i\\frac{(observed_i - expected_i)^2}{expected_i}\n\\]\n\nThe null hypothesis in our example is that the proportion of each type of candy is equal (1/3 or ~33.33).\nIf we plug in our values from above, we would calculate \\(\\chi^2\\) like this:\n\\[ \\chi^2 = \\frac{(30 - 33.33)^2}{33.33} + \\frac{(33 - 33.33)^2}{33.33} + \\frac{(37 - 33.33)^2}{33.33} = 0.74 \\]\n\ntake the difference between observed and expected (33.33), square it, divide it by expected 33.33 and add everything up"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-3",
    "href": "W8_ModelingRelationships.html#chi²-test-3",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test 3",
    "text": "Chi² Test 3\nOn its own, the \\(\\chi^2\\) statistic is not interpretable - it depends on its distribution.\nThe shape of the chi-squared distribution depends on the degrees of freedom (much like the t distribution), which is the number of category levels \\(k-1\\).\n\nFor the candy example, we use a chi-squared distribution with DFs = 2 (3 candy categories minus one). If we’d look at the distribution and found \\(\\chi^2 = .74\\) on the x-axis, we would see that it does not fall far into the tail of the distribution but is rather in the middle. If we calculate the p-value, we’d get \\(P(\\chi^2 &gt; .74) = 0.691\\).\nIt is thus not particularly surprising to find this distribution of candies and we would not reject \\(H_0\\) (equal proportions)."
  },
  {
    "objectID": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "href": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "title": "08 Modeling Relationships",
    "section": "Contingency Tables and the Two-Way Test",
    "text": "Contingency Tables and the Two-Way Test\nThe \\(\\chi^2\\) test is also used to test whether two categorical variables are related to each other.\n\nExample: Are Black drivers more likely to be pulled over by police than white drivers?\nWe have two variables: Skin color (black vs white) and being pulled over (true vs. false). We can represent the data in a contingency table (remember: the count() function was helpful to do this in R):\n\n\n\nContingency table for police search data\n\n\nsearched\nBlack\nWhite\nBlack (relative)\nWhite (relative)\n\n\n\n\nFALSE\n36244\n239241\n0.1295298\n0.8550062\n\n\nTRUE\n1219\n3108\n0.0043565\n0.0111075\n\n\n\n\n\n\n\n\n\nIf there is no relationship between skin color and being searched, the frequencies of searches would be proportional to the frequencies of skin color. This would be our expected values. We can determine them using probabilities:\n\n\n\n\nBlack\nWhite\n\n\n\n\n\nNot searched\n\\(P(\\neg S)*P(B)\\)\n\\(P(\\neg S)*P(W)\\)\n\\(P(\\neg S)\\)\n\n\nSearched\n\\(P(S)*P(B)\\)\n\\(P(S)*P(W)\\)\n\\(P(S)\\)\n\n\n\n\\(P(B)\\)\n\\(P(W)\\)\n\\(100\\%\\)\n\n\n\nRemember: You can only multiply two probabilities to get their conjoint probability if they are independent. Here, we assume independence to calculate expected values and then check how much our observed values deviate from independence.\n\nProbabilities: Because we expect the variables to be unrelated, we can calculate the joint probability as the product of the marginal probabilities:\n\\(P(X \\cap Y) = P(X) * P(Y)\\)\nMarginal probabilities are the prob of each event occuring regardless of other events (in the margins of the table!)"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-4",
    "href": "W8_ModelingRelationships.html#chi²-test-4",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test 4",
    "text": "Chi² Test 4\nIf we compute the standardized squared difference between observed and expected values, we can sum them up to get \\(\\chi^2 = 828.3\\)\n\n\n\nSummary of the 2-way contingency table for police search data\n\n\nsearched\ndriver_race\nn\nexpected\nstdSqDiff\n\n\n\n\nFALSE\nBlack\n36244\n36883.67\n11.09\n\n\nTRUE\nBlack\n1219\n579.33\n706.31\n\n\nFALSE\nWhite\n239241\n238601.33\n1.71\n\n\nTRUE\nWhite\n3108\n3747.67\n109.18\n\n\n\n\n\n\n\nWe can then compute the p-value using a chi-squared distribution with \\(DF = (nRows - 1) * (nColumns - 1) = (2-1) * (2-1) = 1\\)\nWe can also calculate a \\(\\chi^2\\) test easily in R:\n\nchisqTestResult &lt;- chisq.test(summaryDf2wayTable, 1, correct = FALSE)\nchisqTestResult\n\n\n    Pearson's Chi-squared test\n\ndata:  summaryDf2wayTable\nX-squared = 828.3, df = 1, p-value &lt; 2.2e-16\n\n\nThe results indicate that the data are highly unlikely if there was no true relationship between skin color and police searches! We would thus reject \\(H_0\\).\n\nDF: computing the expected frequencies requires three values: total number of observations and marg probs each variable. thus only one of the four values can vary freely."
  },
  {
    "objectID": "W8_ModelingRelationships.html#standardized-residuals",
    "href": "W8_ModelingRelationships.html#standardized-residuals",
    "title": "08 Modeling Relationships",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIf we want to know not only whether but also how the data differ from what we would expect under \\(H_0\\), we can examine the residuals of the model.\nThe residuals tell us for each cell how much the observed data deviates from the expected data.\nTo make the residuals better comparable, we will look at the standardized residuals:\n\\[\n\\text{standardized residual}_{ij} = \\frac{observed_{ij} - expected_{ij}}{\\sqrt{expected_{ij}}}\n\\]\nwhere \\(i\\) and \\(j\\) are the rows and columns respectively.\n\nNegative residuals indicate an observed value smaller than expected.\n\n\n\nSummary of standardized residuals for police stop data\n\n\nsearched\ndriver_race\nStandardized residuals\n\n\n\n\nFALSE\nBlack\n-3.330746\n\n\nTRUE\nBlack\n26.576456\n\n\nFALSE\nWhite\n1.309550\n\n\nTRUE\nWhite\n-10.449072\n\n\n\n\n\n\n\n\nraw residuals depend on number of observations!\nBlack individuals are searched way more often than expected –&gt; helps us intepret significant results."
  },
  {
    "objectID": "W8_ModelingRelationships.html#odds-ratios",
    "href": "W8_ModelingRelationships.html#odds-ratios",
    "title": "08 Modeling Relationships",
    "section": "Odds Ratios",
    "text": "Odds Ratios\nAlternatively, we can represent the relative likelihood of different outcomes as odds ratios:\n\\[\nodds_{searched|black} = \\frac{N(searched\\cap black)}{N(\\neg searched \\cap black)} = \\frac{1219}{36244} = 0.034\n\\]\n\\[\nodds_{searched|white} = \\frac{N(searched \\cap white)}{N(\\neg searched \\cap white)} = \\frac{3108}{239241} = 0.013\n\\]\n\\[\nodds\\ ratio = \\frac{odds(searched|black)}{odds(searched|white)} = 2.59\n\\]\nThe odds of being searched are 2.59x higher for Black vs. white drivers!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox",
    "href": "W8_ModelingRelationships.html#simpsons-paradox",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\nThe Simpson’s Paradox is a great example of misleading summaries.\nIf we look at the baseball data below, we see that David Justice has a better batting average in every single year, but Derek Jeter has a better overall batting average:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlayer\n1995\n\n1996\n\n1997\n\nCombined\n\n\n\n\n\nD. Jeter\n12/48\n.250\n183/582\n.314\n190/654\n.291\n385/1284\n.300\n\n\nD. Justice\n104/411\n.253\n45/140\n.321\n163/495\n.329\n312/1046\n.298\n\n\n\nHow can this be?\n\nSimpson’s Paradox: A pattern is present in the combined dataset but may be different in subsets of the data.\n\n\nHappens if another (lurking) variable changes across subsets (e.g., the number of at-bats, i.e., the denominator).\n\nbatting average: hits/at bats\n1995: in general low batting averages, Justice a lot of at-bats =&gt; diminishes total combined value more strongly than for Jeter."
  },
  {
    "objectID": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "href": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "title": "08 Modeling Relationships",
    "section": "Example: Income Inequality and Hate Crimes",
    "text": "Example: Income Inequality and Hate Crimes\nWe want to look at a dataset that was used for an analysis of the relationship between income inequality (Gini index) and the prevalence of hate crimes in the USA.\n\nIt looks like there is a positive relationship between the variables. How can we quantify this relationship?"
  },
  {
    "objectID": "W8_ModelingRelationships.html#covariance-and-correlation",
    "href": "W8_ModelingRelationships.html#covariance-and-correlation",
    "title": "08 Modeling Relationships",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation\nCovariance: How much do two variables co-vary with each other?\nVariance (single variable): \\(s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{N - 1}\\)\nCovariance (two variables): \\(covariance = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{N - 1}\\)\n(Side note: Variance is the covariance of a variable with itself.)\n\n\n\n“Is there a relation between the deviations of two different variables (from their means) across observations?”\n\n\nWill be far from 0 if data points share a relationship. Positive values for same direction, negative values for opposite directions.\n\n\nCovariance varies with overall level of variance in the data, so not that useful to describe relationships in general.\n\n\n\n\nCorrelation coefficient (Pearson correlation): Scales the covariance by the standard deviations of the two variables and thus standardizes it (=&gt; \\(r\\) varies between \\(-1\\) and \\(1\\) =&gt; comparability!)\n\\[\nr = \\frac{covariance}{s_xs_y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(N - 1)s_x s_y}\n\\]\n\nCovariance depends on dataset!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "href": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "title": "08 Modeling Relationships",
    "section": "Hypothesis Testing for Correlations",
    "text": "Hypothesis Testing for Correlations\nThe correlation between income inequality and hate crimes is \\(r = .42\\), which seems to be a reasonably strong (positive) relationship.\n\nWe can test whether such a relationship could occur by chance, even if there is actually no relationship. In this case, our null hypothesis is \\(H_0: r = 0\\).\n\n\nTo test whether there is a significant relationship, we can transform the \\(r\\) statistic into a \\(t\\) statistic:\n\\[\nt_r = \\frac{r\\sqrt{N-2}}{\\sqrt{1-r^2}}\n\\]\nWe can compute this easily in R:\n\n# perform correlation test on hate crime data\ncor.test(\n  hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nt = 3.2182, df = 48, p-value = 0.002314\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1619097 0.6261922\nsample estimates:\n      cor \n0.4212719 \n\n\nThe p-value is quite small, which indicates that it is quite unlikely to find an \\(r\\) value this high or more extreme. We would thus reject \\(H_0: r = 0\\).\nSide note: There are more beautiful / convenient ways to do this in R. We will cover this in the next session.\n\nsubsetting with $!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlations",
    "href": "W8_ModelingRelationships.html#robust-correlations",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlations",
    "text": "Robust Correlations\nIn the plot, we have seen an outlier: The District of Columbia was quite different from the other data points.\n\nThe Pearson’s correlation coefficient \\(r\\) is highly sensitive to outliers, see this hypothetical example:"
  },
  {
    "objectID": "W8_ModelingRelationships.html#correlation-and-causation",
    "href": "W8_ModelingRelationships.html#correlation-and-causation",
    "title": "08 Modeling Relationships",
    "section": "Correlation and Causation",
    "text": "Correlation and Causation\nDoing a well controlled, randomized experiment (RCT) is extremely helpful to gather causal evidence.\nHowever, it is not always possible or ethical to do an experiment!\nWe can still collect (observational) data. However, if we correlate two variables, we can’t conclude that one causes the other: They might be related but there could also be a third variable that causes both (or even more complex causal structures).\n\nIf we have observational data, causal graphs can be helpful for interpreting causality:\n\n\n\n\n\n\n\n\nCircle: observed variables\nrectangle: latent (unobservable) variable\n\nGreen arrow: positive relationship,\nred: negative\nExamGrade and FinishTime seem negatively related if we ignore other variables!\n(“Hand in your exam early to improve your grade!”)\nKnowledge = theoretical mediator\nStudyTime = proxy for knowledge\nIf we control for StudyTime (which approximates individual knowledge), we find out that ExamGrade and FinishTime are (causally) unrelated!\n\n\n\nWe have briefly talked about causation in week 1\nThink of data/questions where it is impossible/unethical!\nabused children and brain development!\n(3rd var: family stress -&gt; less intellectual engagement –&gt; poorer brain dev)\nCorrelation: s.th. is probably causing s.th. else but not clear what causes what!\nDAG:\ngreen: pos, red: net\ncircle: observed, rect: latent (unobservable)\nExamGrade and FinishTime seem neg related if we ignore others\nknowledge = mediates\nStudyTime = proxy for knowledge, if we “control” it/hold it constant/only use people with same amount, we would see that EG and FT are unrelated!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#testing-a-single-mean",
    "href": "W8_ModelingRelationships.html#testing-a-single-mean",
    "title": "08 Modeling Relationships",
    "section": "Testing a Single Mean",
    "text": "Testing a Single Mean\nWe sometimes might want to know whether a single value, the mean of a group, differs from a specific value, e.g. whether the blood pressure in the sample differs from or is bigger than 80.\n\nWe can test this using the \\(t\\)-test, which we have already encountered in the “Hypothesis Testing” session!\n\\[\nt = \\frac{\\hat{X} - \\mu}{SEM}\n\\]\n\\[\nSEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n\\]\n\\(\\hat{X}\\) is the mean of our sample, \\(\\mu\\) the hypothesized population mean (e.g. the value we want to test against, such as 80 for the blood pressure example).\nWe can easily calculate the \\(t\\)-test in R:\n\nt.test(x=NHANES_adult$BPDiaAve, mu=80, alternative='greater')\n\n\n    One Sample t-test\n\ndata:  NHANES_adult$BPDiaAve\nt = -55.23, df = 4599, p-value = 1\nalternative hypothesis: true mean is greater than 80\n95 percent confidence interval:\n 69.1588     Inf\nsample estimates:\nmean of x \n 69.47239 \n\n\n\n(The \\(t\\) statistic thus asks how large the deviation of sample mean from the expected value with respect to the sampling variability of the mean!)\nWe tested the one-sided alternative (&gt;) and the blood pressure in the sample is much lower than 80, so it is far from significance\nWe can’t interpret the \\(p\\)-value as evidence in favor of \\(H_0\\) (i.e. larger \\(p\\)-value! vs non.sign) –&gt; Bayes!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-two-means",
    "href": "W8_ModelingRelationships.html#comparing-two-means",
    "title": "08 Modeling Relationships",
    "section": "Comparing Two Means",
    "text": "Comparing Two Means\nMore often, we want to know whether there is a difference between the means of two groups.\nExample: Do regular marijuana smokers watch more television?\nIn this example, we expect that they watch more TV, which leads us to the following directed hypotheses:\n\\(H_0\\) = marijuana smokers watch less or equally often TV,\n\\(H_A\\) = marijuana smokers watch more TV.\n\nIf the observations are independent (i.e. you really have two unrelated groups), you can use a very similar formula to calculate the \\(t\\) statistic:\n\\[\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nwhereby \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the group means, \\(S_1^2\\) and \\(S_2^2\\) the group variances, and \\(n_1\\) and \\(n_2\\) the group sizes.\nHere are the results from a one-tailed \\(t\\)-test in R:\n\n\n\n    Welch Two Sample t-test\n\ndata:  TVHrsNum by RegularMarij\nt = -1.2147, df = 116.9, p-value = 0.1135\nalternative hypothesis: true difference in means between group No and group Yes is less than 0\n95 percent confidence interval:\n       -Inf 0.09866006\nsample estimates:\n mean in group No mean in group Yes \n          2.02963           2.30000 \n\n\n\nDV: continuous, IV: categories\nn.s. (differs from book), although mean is higher in Yes, not significantly different!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-paired-dependent-observations",
    "href": "W8_ModelingRelationships.html#comparing-paired-dependent-observations",
    "title": "08 Modeling Relationships",
    "section": "Comparing Paired (= Dependent) Observations",
    "text": "Comparing Paired (= Dependent) Observations\nIf we have repeated observations of the same subject (i.e. a within-subject design), we might want to compare the same subject thus on multiple, repeated measurements.\n\nIf we want to test whether blood pressure differs between the first and second measurement session across individuals, we can use a paired \\(t\\)-test.\nA paired \\(t\\)-test is equivalent to a one-sample \\(t\\)-test, only using the difference between the two means as \\(\\hat{X}\\) and e.g. 0 (if we expect no difference for \\(H0\\)) for \\(\\mu\\).\nIn R, we would run a paired-samples \\(t\\)-test like this:\n\nt.test(BPsys ~ timepoint, data = NHANES_sample_tidy, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  BPsys by timepoint\nt = 2.7369, df = 199, p-value = 0.006763\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2850857 1.7549143\nsample estimates:\nmean difference \n           1.02 \n\n\n\nimportant: If we run an independent sample t-test, it would probably be n.s.! (check out book)"
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "href": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "title": "08 Modeling Relationships",
    "section": "Comparing More Than Two Means",
    "text": "Comparing More Than Two Means\nOften, we want to compare more than two means, e.g. different treatment groups or timepoints.\nExample: Different treatments for blood pressure"
  },
  {
    "objectID": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "href": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "title": "08 Modeling Relationships",
    "section": "Analysis of Variance (ANOVA)",
    "text": "Analysis of Variance (ANOVA)\n\\(H_0\\): all means are equal\n\\(H_A\\): not all means are equal (e.g. at least one differs)\n\nWe can partition the variance in the data into different parts:\n\\(SS_{total}\\) = total variance in the data\n\\(SS_{model}\\) = Variance explained by the model*\n\\(SS_{error}\\) = Variance not explained by the model\n\n\nWe can use those to calculate the mean squares for the model and the error:\n\\(MS_{model} =\\frac{SS_{model}}{df_{model}}= \\frac{SS_{model}}{p-1}\\) (\\(p\\) is the number of factor levels)\n\\(MS_{error} = \\frac{SS_{error}}{df_{error}} = \\frac{SS_{error}}{N - p}\\)\n\n\nWe want to test whether the variance accounted for by the model is greater than expected by chance (\\(H_0\\): no difference).\n\n\nquite common analysis! We will just scratch the surface\n\n\n\n\\(SS\\) = Sum of Squares, remember that the variance is the sum of the squared deviation of an observation to the mean\n\\(MS\\) = Mean (Sum of) Squares: How much variance per degree of freedom?\n*more on that in the next session!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-2",
    "href": "W8_ModelingRelationships.html#anova-2",
    "title": "08 Modeling Relationships",
    "section": "ANOVA 2",
    "text": "ANOVA 2\nIn R, we would run an ANOVA like this:\n\ndf &lt;-\n  df %&gt;% \n  mutate(group2=fct_relevel(group,c(\"placebo\",\"drug1\",\"drug2\")))\n# reorder the factor levels so that \"placebo\" is the control condition/intercept!\n  \n \n# test model without separate duymmies\nlmResultAnovaBasic &lt;- lm(sysBP ~ group2, data=df)\nsummary(lmResultAnovaBasic)\n\n\nCall:\nlm(formula = sysBP ~ group2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\ngroup2drug1  -10.237      2.342  -4.371 2.92e-05 ***\ngroup2drug2   -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n# emm.result &lt;- emmeans(lmResultAnovaBasic, \"group\" )"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general",
    "href": "W8_ModelingRelationships.html#chi²-test-general",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General",
    "text": "Chi² Test: General\nWe will first focus on modeling categorical relationships (of variables that are qualitative!).\n\nThese data are usually expressed in terms of counts.\n\n\nExample: Candy colors\nBag of candy: 30 chocolates, 33 licorices, and 37 gumballs.\n\n\nIs the distribution fair (i.e., 1/3rd of the bag = each candy) and the fact that there are only 30 chocolates a random accident?\n\n\nWhat is the likelihood that the count would come out this way (or even more extreme) if the true probability of each candy type is the same?\n\nCounts: For each combination of variables, how many observations do we have?\nIf the machine really sorts on average 1/3 of each in each bag? How much is due to chance?"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "href": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: One Variable",
    "text": "Chi² Test: One Variable\nThe Chi² test checks whether observed counts differ from expected values (\\(H_0\\)).\n\\[\n\\chi^2 = \\sum_i\\frac{(observed_i - expected_i)^2}{expected_i}\n\\]\n\nThe null hypothesis in our example is that the proportion of each type of candy is equal (1/3 or ~33.33).\nIf we plug in our values from above, we would calculate \\(\\chi^2\\) like this:\n\\[ \\chi^2 = \\frac{(30 - 33.33)^2}{33.33} + \\frac{(33 - 33.33)^2}{33.33} + \\frac{(37 - 33.33)^2}{33.33} = 0.74 \\]\n\ntake the difference between observed and expected (33.33), square it, divide it by expected 33.33 and add everything up"
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general-2",
    "href": "W8_ModelingRelationships.html#chi²-test-general-2",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General 2",
    "text": "Chi² Test: General 2\nOn its own, the \\(\\chi^2\\) statistic is not interpretable - it depends on its distribution.\nThe shape of the chi-squared distribution depends on the degrees of freedom (much like the t distribution), which is the number of category levels \\(k-1\\).\n\nFor the candy example, we use a chi-squared distribution with DFs = 2 (3 candy categories minus one). If we’d look at the distribution and found \\(\\chi^2 = .74\\) on the x-axis, we would see that it does not fall far into the tail of the distribution but is rather in the middle. If we calculate the p-value, we’d get \\(P(\\chi^2 &gt; .74) = 0.691\\).\nIt is thus not particularly surprising to find this distribution of candies and we would not reject \\(H_0\\) (equal proportions)."
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-two-variables",
    "href": "W8_ModelingRelationships.html#chi²-test-two-variables",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: Two Variables",
    "text": "Chi² Test: Two Variables\nIf we compute the standardized squared difference between observed and expected values, we can sum them up to get \\(\\chi^2 = 828.3\\)\n\n\n\nContingency table for police search data\n\n\nsearched\ndriver_race\nn\nexpected\nstdSqDiff\n\n\n\n\nFALSE\nBlack\n36244\n36883.67\n11.09\n\n\nTRUE\nBlack\n1219\n579.33\n706.31\n\n\nFALSE\nWhite\n239241\n238601.33\n1.71\n\n\nTRUE\nWhite\n3108\n3747.67\n109.18\n\n\n\n\n\n\n\nWe can then compute the p-value using a chi-squared distribution with \\(DF = (levels_{var1} - 1) * (levels_{var2} - 1) = (2-1) * (2-1) = 1\\)\nWe can also calculate a \\(\\chi^2\\) test easily in R:\n\nchisq.test(summaryDf2wayTable, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  summaryDf2wayTable\nX-squared = 828.3, df = 1, p-value &lt; 2.2e-16\n\n\nThe results indicate that the data are highly unlikely if there was no true relationship between skin color and police searches! We would thus reject \\(H_0\\).\nQuestion: What is the direction of the observed relationship?\n\nDF: computing the expected frequencies requires three values: total number of observations and marg probs each variable. thus only one of the four values can vary freely."
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "href": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox: More intuitive",
    "text": "Simpson’s Paradox: More intuitive\nWhile typing on a keyboard, what is the relationship between speed and accuracy (or typing errors)?\n(positive, negative, or none)\n\n\n\nIf I try to type faster, I will make more errors =&gt; speed-accuracy trade-off (negative association)\nPeople who are better at typing usually are both faster and make fewer mistakes (positive association)\n\n\n\n\nAnswer: It depends\n\nWithin a person, the relationship between speed and accuracy is negative. My own skill is limited, I can either use it for speed or accuracy.\nBetween persons, the relationship is positive due to inter-individual differences in overall typing skill.\n\n\nUsually, when leveling up, people don’t put all their skill points in only speed or accuracy."
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlatoin-2",
    "href": "W8_ModelingRelationships.html#robust-correlatoin-2",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlatoin 2",
    "text": "Robust Correlatoin 2\nWe can use a different correlation coefficient, though, which is less sensitive to outliers: Spearman correlation.\nIt is based on ranking (i.e., ordering) the data and using the ranks (instead of the original data) for the correlation.\n\ncor.test(hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index,\n  method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nS = 20146, p-value = 0.8221\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n0.03261836 \n\n\nThe correlation has now dropped from \\(.42\\) to \\(.03\\) and is no longer significant. The influence of the one outlier has been greatly diminished.\nOf course, a ranked correlation can also obscure true effects that critically depend on the scale of the data. When in doubt, try both and discuss reasons for differences.\n\nWithout outlier: perfectly negative correlation, with outlier: highly positive!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "href": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "title": "08 Modeling Relationships",
    "section": "Testing a Single Mean (One sample t-Test)",
    "text": "Testing a Single Mean (One sample t-Test)\nWe sometimes might want to know whether a single value, the mean of a group, differs from a specific value, e.g. whether the blood pressure in the sample differs from or is bigger than 80.\n\nWe can test this using the \\(t\\)-test, which we have already encountered in the “Hypothesis Testing” session!\n\\[\nt = \\frac{\\hat{X} - \\mu}{SEM}\n\\]\n\\[\nSEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n\\]\n\\(\\hat{X}\\) is the mean of our sample, \\(\\mu\\) the hypothesized population mean (e.g. the value we want to test against, such as 80 for the blood pressure example).\nWe can easily calculate the \\(t\\)-test in R:\n\nt.test(x=NHANES_adult$BPDiaAve, mu=80, alternative='greater')\n\n\n    One Sample t-test\n\ndata:  NHANES_adult$BPDiaAve\nt = -55.23, df = 4599, p-value = 1\nalternative hypothesis: true mean is greater than 80\n95 percent confidence interval:\n 69.1588     Inf\nsample estimates:\nmean of x \n 69.47239 \n\n\n\n(The \\(t\\) statistic thus asks how large the deviation of sample mean from the expected value with respect to the sampling variability of the mean!)\nWe tested the one-sided alternative (&gt;) and the blood pressure in the sample is much lower than 80, so it is far from significance\nWe can’t interpret the \\(p\\)-value as evidence in favor of \\(H_0\\) (i.e. larger \\(p\\)-value! vs non.sign) –&gt; Bayes!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-two-means-two-sample-t-test",
    "href": "W8_ModelingRelationships.html#comparing-two-means-two-sample-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Two Means (Two sample t-Test)",
    "text": "Comparing Two Means (Two sample t-Test)\nMore often, we want to know whether there is a difference between the means of two groups.\nExample: Do regular marijuana smokers watch more television?\nIn this example, we expect that they watch more TV, which leads us to the following directional hypotheses:\n\\(H_0\\) = marijuana smokers watch less or equally often TV,\n\\(H_A\\) = marijuana smokers watch more TV.\n\nIf the observations are independent (i.e. you really have two unrelated groups), you can use a very similar formula to calculate the \\(t\\) statistic:\n\\[\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nwhereby \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the group means, \\(S_1^2\\) and \\(S_2^2\\) the group variances, and \\(n_1\\) and \\(n_2\\) the group sizes.\nHere are the results from a one-tailed \\(t\\)-test in R:\n\n\n\n    Welch Two Sample t-test\n\ndata:  TVHrsNum by RegularMarij\nt = -1.2147, df = 116.9, p-value = 0.1135\nalternative hypothesis: true difference in means between group No and group Yes is less than 0\n95 percent confidence interval:\n       -Inf 0.09866006\nsample estimates:\n mean in group No mean in group Yes \n          2.02963           2.30000 \n\n\n\nDV: continuous, IV: categories\nn.s. (differs from book), although mean is higher in Yes, not significantly different!"
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-t-test",
    "href": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Dependent Observations (Paired t-test)",
    "text": "Comparing Dependent Observations (Paired t-test)\nIf we have repeated observations of the same subject (i.e., a within-subject design), we might want to compare the same subject thus on multiple, repeated measurements.\n\nIf we want to test whether blood pressure differs between the first and second measurement session across individuals, we can use a paired \\(t\\)-test.\nIn R, we would run a paired-samples \\(t\\)-test like this:\n\nt.test(BPsys ~ timepoint, data = NHANES_sample_tidy, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  BPsys by timepoint\nt = 2.7369, df = 199, p-value = 0.006763\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2850857 1.7549143\nsample estimates:\nmean difference \n           1.02 \n\n\nSide note: A paired \\(t\\)-test is equivalent to a one-sample \\(t\\)-test, when using the paired differences as \\(\\hat{X}\\) and testing them against a value of 0 (if we expect no difference for \\(H_0\\)) for \\(\\mu\\).\n\nimportant: If we run an independent sample t-test, it would probably be n.s.! (check out book)"
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-3",
    "href": "W8_ModelingRelationships.html#anova-3",
    "title": "08 Modeling Relationships",
    "section": "ANOVA 3",
    "text": "ANOVA 3\n\n\n\nCall:\nlm(formula = sysBP ~ group2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\ngroup2drug1  -10.237      2.342  -4.371 2.92e-05 ***\ngroup2drug2   -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n\nWe can see a \\(t\\)-test for every drug. This is because the factor group2 is automatically dummy coded by R: We always compare one drug against the intercept, which is the mean of the placebo group!\nThe \\(t\\)-test shows us that drug1 differs significantly from placebo but not drug2.\nThe \\(F\\)-statistic (also called omnibus test) actually tests our overall hypothesis of no difference between conditions."
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-side-notes",
    "href": "W8_ModelingRelationships.html#anova-side-notes",
    "title": "08 Modeling Relationships",
    "section": "ANOVA side notes",
    "text": "ANOVA side notes\nIn R, there are different functions that you can use to run an ANOVA besides lm(), which have different advantages and disadvantages (functions like ezANOVA() from the ez packages or functions from the afex package might be helpful).\nJust like with the \\(t\\)-test, there’s also a distinction between between-subjects and within-subjects (i.e., repeated measures ANOVA). The previous example contained just between-subjects measures, i.e. different groups without repeated measures. We will talk about other options later, but see the packages mentioned above as well for functional parameters called, e.g., within.\n\nDummy coded (explicitly):\n\n\n\nCall:\nlm(formula = sysBP ~ d1 + d2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\nd1           -10.237      2.342  -4.371 2.92e-05 ***\nd2            -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n\n\\(t\\)-tests: dummy coded = 0 vs. 1\n- control for multiple comparisons! (later)\n- if we wanted to compare the two drugs, we’d have to dummy code/relevel differently or use follow-up comparisons like with emmeans()\n\\(F\\): Is our model better than a simple model that just includes the intercept? In this case placebo…"
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlation-2",
    "href": "W8_ModelingRelationships.html#robust-correlation-2",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlation 2",
    "text": "Robust Correlation 2\nWe can use a different correlation coefficient, though, which is less sensitive to outliers: Spearman correlation.\nIt is based on ranking (i.e., ordering) the data and using the ranks (instead of the original data) for the correlation.\n\ncor.test(hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index,\n  method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nS = 20146, p-value = 0.8221\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n0.03261836 \n\n\nThe correlation has now dropped from \\(.42\\) to \\(.03\\) and is no longer significant. The influence of the one outlier has been greatly diminished.\nOf course, a ranked correlation can also obscure true effects that critically depend on the scale of the data. When in doubt, try both and discuss reasons for differences.\n\nWithout outlier: perfectly negative correlation, with outlier: highly positive!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#your-first-analysis",
    "href": "W9_FirstAnalysisR.html#your-first-analysis",
    "title": "09 Statistical Analyses in R",
    "section": "Your First Analysis",
    "text": "Your First Analysis\nToday, we will practice a lot of different analysis, most of which you will encounter a lot: The Chi³-test, the t-test, ANOVAs and correlation.\n\nPlease set up your RStudio as usual:\n\nOpen RStudio and set the working directory to the course folder\nOpen a new R Markdown document, delete the content, and save it with a suitable name\nInstall and load packages you’ll need: car, effectsize, tidyverse\nOR download the prepared W6_Analysis.Rmd file!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#activity-1",
    "href": "W9_FirstAnalysisR.html#activity-1",
    "title": "09 Statistical Analyses in R",
    "section": "Activity 1",
    "text": "Activity 1\nWhich test would you choose if you wanted to test whether a variable is differently distributed between groups?\nLet’s say we have tested 20 mice and want to know whether they pressed the blue, green, or red lever more often than by chance. This is how often the mice pressed each lever: Blue = 5, Green = 4, Red = 11\n\nWe would run a (one-sample) Chi²-test!\nRemember that in a Chi²-test, we would compare observed to expected counts:\n\\[\n\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\n\\]"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#chi²-test-2",
    "href": "W9_FirstAnalysisR.html#chi²-test-2",
    "title": "09 Statistical Analyses in R",
    "section": "Chi²-Test 2",
    "text": "Chi²-Test 2\nWe can also run a Chi²-test for two variables, such as if we want to know whether the lever presses differ per group.\nLet’s say we have a treatment and a control group and we record the different lever presses:\n\n\n\nGroup\nBlue\nGreen\nRed\nTotals\n\n\n\n\nTreatment\n3\n12\n5\n20\n\n\nControl\n5\n4\n11\n20\n\n\nTotals\n8\n16\n16\n40\n\n\n\nRemember: We use the assumption of independence to calculate the expected values.\n\n\nlever_presses2 = tibble(group=\"treatment\", blue=3, green=12, red=5) %&gt;% \n  bind_rows(tibble(group=\"control\", blue=5, green=4, red=11)) #clearest way to manually input data\n#for long data, you create the frequency table identically to previous slide but with: count(group, levers)\n\nchisq.test(lever_presses2 %&gt;% column_to_rownames(\"group\")) %&gt;% apa::chisq_apa()\n\nchi^2(2) = 6.75, p = .034"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of Chi²-Tests",
    "text": "Assumptions of Chi²-Tests\n\n\nRandom sample\nCategorical variables, i.e., counts within (combinations of) groups\nExpected cell count: &gt;5 counts per cell\nIndependence: Each observation is independent of the others, e.g. there are no repeated measurements/paired data (within-subjects data are correlated!)\n\n\n\nIn the case of the last analysis, we got a warning because the expected cell sizes were too small. In this case, it is better to use Fisher’s exact test:\n\nfisher.test(lever_presses2 %&gt;% column_to_rownames(\"group\"))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  lever_presses2 %&gt;% column_to_rownames(\"group\")\np-value = 0.04168\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#activity-2",
    "href": "W9_FirstAnalysisR.html#activity-2",
    "title": "09 Statistical Analyses in R",
    "section": "Activity 2",
    "text": "Activity 2\nNow imagine you want to compare reaction times of the lever presses of the two groups of mice. You expect that those in the treatment group respond faster than those in the control group. Which statistical test would you use?\n\nHint: We now have two independent groups and a continuous dependent variable (reaction times).\n\n\nAn (independent samples) t-test!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test",
    "href": "W9_FirstAnalysisR.html#t-test",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test",
    "text": "t-Test\nWe can use the formula notation to run the t-test. This notation usually looks like this:\ndependent variable ~ independent variable.\nReplace the NULLs:\n\nt.test(NULL ~ NULL,\n       data = NULL,\n       alternative = NULL,\n       paired = NULL) \n\n\n\nt.test(reaction_times ~ group,\n       data = sim_data_t,\n       alternative = \"greater\", #depends on ALPHABETICAL order of groups in data!\n       paired = FALSE) #in the future, we only specify this IF the data are paired\n\n\n    Welch Two Sample t-test\n\ndata:  reaction_times by group\nt = 1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means between group control and group treatment is greater than 0\n95 percent confidence interval:\n 10.02639      Inf\nsample estimates:\n  mean in group control mean in group treatment \n               468.0592                400.3289 \n\n\n\n\nAs you can see in the output, R automatically chose to run Welch’s t-test, which does not assume variance homogeneity in contrast to Student’s t-test. For the latter, you can add the function parameter var.equal = TRUE\n\nWhen changing the name “treatment” to “a”, the results change:\n\nt.test(reaction_times ~ group,\n       data = sim_data_t %&gt;% mutate(group = ifelse(group==\"treatment\", \"a\", group)),\n       alternative = \"greater\", #depends on order of groups in data! 1st group &gt; 2nd group\n       paired = FALSE, var.equal=T) %&gt;% apa::t_apa()\n\nt(38) = -1.98, p = .973, d = -0.63"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests",
    "text": "Assumptions of t-Tests\nBefore we run a t-test, we also want to check the assumptions for violations:\n\n\nThe dependent variable is continuous (otherwise: chi²-test)\nThe data are independent (otherwise: paired sample t-test)\nThe variance between the groups is homogeneous (only for Student’s t-test, R uses Welch’s test by default)\nThe residuals are normally distributed for each group (otherwise: wilcox.test)\n\n\n\nOftentimes, the last assumption is misquoted as: “The dependent variable needs to be normally distributed”.\nIn fact, only its sampling distribution needs to be (blue vs. grey distribution in the lecture on sampling [direct link]), which will always be the case for big enough samples due to the central limit theorem."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-2",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-2",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests 2",
    "text": "Assumptions of t-Tests 2\nTest for normality of residuals (for both groups): If points fall along the line nicely, assumption is met.\n\n\ntreatment &lt;- sim_data_t %&gt;%\n  filter(group == \"treatment\") %&gt;%\n  mutate(group_resid = \n           reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#base R QQ plot\nqqnorm(treatment)\nqqline(treatment)\n\n\n\n\n\n\n\n\ncontrol &lt;- sim_data_t %&gt;%\n  filter(group == \"control\") %&gt;%\n  mutate(group_resid = reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#car's version highlighting (and returning) problematic values\ncar::qqPlot(control)\n\n\n\n\n\n[1] 18  4"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#paired-samples-or-within-subjects-t-test",
    "href": "W9_FirstAnalysisR.html#paired-samples-or-within-subjects-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Paired Samples (or Within-Subjects) t-Test",
    "text": "Paired Samples (or Within-Subjects) t-Test\nSometimes you have dependent data: These data are somehow correlated, e.g. they belong to the same subject (that you measured repeatedly).\n\nIn this case, you would use a paired-samples t-test.\n\n\nLet’s run such a t-test with real data. We’ll use the Mehr Song and Spelke 2016 Experiment 1.csv file (note that this is not a good file name!).\nIn this dataset, the authors examined whether infants exposed to certain songs would recognize strangers singing these lullabies as part of their social group. Parents sang certain lullabies to their infants for 1-2 weeks. During the experiment, the infants looked at videos of two strangers: First the strangers were just smiling (baseline phase), then they would sing either the familiar or an unfamiliar lullaby. Finally, the infants again saw the videos of the strangers smiling (test phase). Eye-tracking (duration looked at each stranger) was measured.\n\n\nLoad the file into your Environment. Run the code and explain what happens:\n\ngaze &lt;- read_csv(\"Mehr Song and Spelke 2016 Experiment 1.csv\") %&gt;%\n  filter(exp1 == 1) %&gt;%\n  select(id,\n         Baseline_Proportion_Gaze_to_Singer,\n         Test_Proportion_Gaze_to_Singer) %&gt;%\n  rename(baseline = Baseline_Proportion_Gaze_to_Singer,\n         test = Test_Proportion_Gaze_to_Singer)"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test-2",
    "href": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test-2",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of the Paired-Samples t-Test 2",
    "text": "Assumptions of the Paired-Samples t-Test 2\n\nThe data are continuous.\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\n\nA paired-samples t-test actually tests whether the difference between two measurements is significantly different from 0 (= no difference/effect).\nIn our example data, this means that the test values are subtracted from the baseline values, and this difference is used as data.\nTo test the assumption that residuals are normally distributed, we thus calculate the residuals as follow:\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\n\n\n\n[1] 22 29\n\nshapiro.test(gaze_residual$group_resid)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#descriptives-visualization",
    "href": "W9_FirstAnalysisR.html#descriptives-visualization",
    "title": "09 Statistical Analyses in R",
    "section": "Descriptives & Visualization",
    "text": "Descriptives & Visualization\nFor the visualization, we need the data in long format (this is identical for between-subject groups):\n\n\ngaze_tidy &lt;- gaze %&gt;%\n  pivot_longer(names_to = \"phase\", \n               values_to = \"looking_time\", \n               cols = c(baseline, test))\n\n# boxplot\ngaze_tidy %&gt;% \n  ggplot(aes(x=phase, y=looking_time)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nWe can also calculate the means and SDs per phase:\n\n\ngaze_tidy %&gt;% \n  summarise(mean_looking = mean(looking_time),\n            sd_looking = sd(looking_time),\n            n = n(),\n            .by = phase)\n\n\n# A tibble: 2 × 4\n  phase    mean_looking sd_looking     n\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 baseline        0.521      0.177    32\n2 test            0.593      0.179    32"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "href": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "title": "09 Statistical Analyses in R",
    "section": "Paired Samples t-Test in R",
    "text": "Paired Samples t-Test in R\nAny ideas how you would specify the paired samples t-test in R?\n\n\nt.test(NULL ~ NULL,\n       paired = NULL,\n       data = NULL,\n       alternative = NULL)\n\n\n\n\nt.test(looking_time ~ phase, #this assumes that data are ordered by subject!\n       paired = TRUE,\n       data = gaze_tidy,\n       alternative = \"two.sided\")\n\n\n    Paired t-test\n\ndata:  looking_time by phase\nt = -2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.13349698 -0.01129217\nsample estimates:\nmean difference \n    -0.07239458"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "href": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Effect Size for the t-Test",
    "text": "Effect Size for the t-Test\nYou can (and should!) of course calculate and report effect sizes for your test statistics to get an impression of how practically relevant the effect is.\nFor the t-tests, you would calculate Cohen’s d (using the function from the effectsize package):\n\neffectsize::cohens_d(looking_time ~ phase, paired=T, data=gaze_tidy)\n\nCohen's d |         95% CI\n--------------------------\n-0.43     | [-0.79, -0.06]\n\n\n\n\nOr just use the apa package and you get everything in one go:\n\nwith(gaze, #the with function allows to call columns as if they were variables (but pipe function doesn't work with it)\n     t.test(baseline, test, paired = TRUE)) %&gt;% \n  apa::t_apa(es_ci=T)\n\nt(31) = -2.42, p = .022, d = -0.43 [-0.79; -0.06]"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#write-up-of-the-t-test",
    "href": "W9_FirstAnalysisR.html#write-up-of-the-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Write Up of the t-Test",
    "text": "Write Up of the t-Test\nWhat do you think you should report in your results section?\n\n\nthe means and SDs per condition (or the mean difference and the SD of the difference between conditions)\nthe test statistic t, incl. degrees of freedom\nthe p-value\nthe effect size\n\n\n\n\nAt test stage (M = .59, SD = .18), infants showed a significantly longer preferential looking time to the singer of the familiar melody than they had shown the same singer at baseline (M = .52, SD = .18), t(31) = 2.42, p = .022, d = .41."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlation",
    "href": "W9_FirstAnalysisR.html#correlation",
    "title": "09 Statistical Analyses in R",
    "section": "Correlation",
    "text": "Correlation\nIf we have two continuous variables, we can of course also look at their relationship using correlation. In the data you just used, we have two continuous variables, the repeated measures of gaze.\nWith these data, we might be interested in whether there is a relationship between the two measures of gaze, i.e. whether those children who looked at the stranger more at baseline would also be the ones who looked at the stranger more often at the follow-up test.\n\n# cor(x = variable1, y = variable2)\n\nct &lt;- cor.test(x = NULL, \n         y = NULL, \n         method = \"pearson\", \n         alternative = \"two.sided\")\nct\n\n\n\ncor(x = gaze$baseline, y = gaze$test)\n\n[1] 0.5458966\n\nct &lt;- cor.test(x = gaze$baseline, \n         y = gaze$test, \n         method = \"pearson\", \n         alternative = \"two.sided\")\nct\n\n\n    Pearson's product-moment correlation\n\ndata:  gaze$baseline and gaze$test\nt = 3.5686, df = 30, p-value = 0.00123\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2435655 0.7515352\nsample estimates:\n      cor \n0.5458966 \n\n\n\n\nWrite-Up:\n\nThere appeared to be a positive relationship between gaze at strangers at baseline (M = .52, SD = .18) and at the follow-up test (M = .59, SD = .18), in line with the alternative hypothesis. A Pearson correlation found a significant, large positive correlation between the two variables (r = .55, t(30) = 3.57, p = .001) and the null hypothesis is therefore rejected.\n\n\n\nYou can also use report() to get an automatic suggestion for how to report the results (works with a lot of different models!).\n\nlibrary(report)\nreport(ct)\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between gaze$baseline and gaze$test is\npositive, statistically significant, and very large (r = 0.55, 95% CI [0.24,\n0.75], t(30) = 3.57, p = 0.001)\n\n\n\nWe mainly use this dataset so that you don’t have to load another one, but in practice you would either run a t-test or a correlation, not necessarily both!\nThe t-tests answers whether there is a change across all participants between the two time points, the correlation answers the question whether those who score high at one time point would also score high at the next (regardless of overall level)."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-2---notes",
    "href": "W9_FirstAnalysisR.html#correlations-2---notes",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations 2 - Notes",
    "text": "Correlations 2 - Notes\nThere are also some assumptions that need to be checked:\n\nIs the data continuous (interval, ratio, or ordinal)?\nIs there a data point for each participant on both variables?\nIs the data normally distributed in both variables?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity?\n\nPlease see the text book for how to test these assumptions.\n\nYou should - as always - report the descriptive statistics (summary statistics such as mean and SD).\n\n\nYou can also report and visualize multiple correlations at once, using a scatterplot matrix or heatmaps. Check out e.g. the corrplot package!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#activity-3",
    "href": "W9_FirstAnalysisR.html#activity-3",
    "title": "09 Statistical Analyses in R",
    "section": "Activity 3",
    "text": "Activity 3\nWhat if we have more than two groups and/or more than one variable? For example, what if we have one variable treatment (with the factor levels treatment 1, treatment 2, and control) and possibly another variable called timepoint (baseline, post-test)?\nWhich statistical test could we use?\n\nWe would possibly run an ANOVA!\nIf we have only one factor (e.g. treatment with three factor levels), we would do an one-way ANOVA.\nIf we have more than one factor but only between-subjects variables, we would run an ANOVA.\nIf we have at least one within-subjects factor, we would run a repeated measures (or mixed) ANOVA.\nWe will cover ANOVAs even more next week in the context of the linear model.\n\nwe will today only look at one-way anovas! Next week we will cover the case when we have more than one IV/predictor!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova",
    "href": "W9_FirstAnalysisR.html#one-way-anova",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nFor this activity, we will use data from a study about memory of traumatic events (see the textbook for details). In short, the authors of the paper were interested to find out whether:\n\nreconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions.\n\n\n\nDownload the data James Holmes_Expt 2_DATA.csv. This time, put it in a subfolder of your project called “Data”.\nAdd a column to the dataframe called subject that equals the row_number(), which will act as a participant ID.\nrename(): Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\nSelect only the columns subject, Condition and intrusions.\nChange the variable Condition from numeric to a factor using as.factor()\n\n\n\n\nlibrary(tidyverse)\n\ndat &lt;- read_csv(\"Data/James Holmes_Expt 2_DATA.csv\") %&gt;% \n  rownames_to_column(\"subject\") %&gt;% #mutate(subject = 1:n()) %&gt;% \n  rename(intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary) %&gt;% \n  select(subject, Condition, intrusions) %&gt;% \n  mutate(Condition = as.factor(Condition))\n\n\nwe will today only look at one-way anovas! Next week we will cover the case when we have more than one IV/predictor!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-2",
    "href": "W9_FirstAnalysisR.html#one-way-anova-2",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA 2",
    "text": "One-Way ANOVA 2\nCreate summary/descriptive statistics and visualize the data.\nAs summary statistics, we want the mean, SD, and SE.\n\nse = function(x, na.rm = FALSE) { sd(x, na.rm) / sqrt(if(!na.rm) length(x) else sum(!is.na(x))) }\n\nsum_dat &lt;- dat %&gt;%\n  summarise(mean = mean(intrusions),\n            sd = sd(intrusions),\n            se = se(intrusions),\n            .by = Condition)\nprint(sum_dat)\n\n# A tibble: 4 × 4\n  Condition  mean    sd    se\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1          5.11  4.23 0.996\n2 2          1.89  1.75 0.411\n3 3          3.89  2.89 0.681\n4 4          4.83  3.33 0.785\n\n\nNote: The names of the factor levels are missing. If we wanted to plot the data, we should have added them in the previous step. For brevity, we will not do it this time.\n\n\ndon’t use a bar chart!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-3",
    "href": "W9_FirstAnalysisR.html#one-way-anova-3",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA 3",
    "text": "One-Way ANOVA 3\n\nRun the ANOVA using lm() and formula notation.\n\n\nmod1 &lt;- lm(intrusions ~ Condition, data = dat)\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: intrusions\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nCondition  3 114.82  38.273  3.7948 0.01409 *\nResiduals 68 685.83  10.086                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nUsing afex::aov_ez:\n\n\nlibrary(afex)\nmod &lt;- aov_ez(id = \"subject\", # the column containing the subject IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # can output an effect size! we want partial eta-squared\n              type = 3, # there are both reasons for 2 and 3 (not covered here)\n              include_aov = TRUE, # needed for some calculations with emmeans but takes longer\n              data = dat)\nanova(mod)\n\nAnova Table (Type 3 tests)\n\nResponse: intrusions\n          num Df den Df    MSE      F     ges  Pr(&gt;F)  \nCondition      3     68 10.086 3.7948 0.14341 0.01409 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "href": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "title": "09 Statistical Analyses in R",
    "section": "Checking the Assumptions",
    "text": "Checking the Assumptions\n\nlibrary(performance)\nlibrary(patchwork)\n\ncheck_model(mod1) # doesn't work for ezANOVA output!\n\n\n\n# \"manually\" check normality of residuals \n\nqqPlot(mod$aov$residuals)\n\n\n\n\n[1]  3 57\n\nshapiro.test(mod$aov$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod$aov$residuals\nW = 0.87739, p-value = 4.252e-06\n\n# check homogeneity of variance\ntest_levene(mod)\n\nWarning: Variances differ between groups (Levene's Test, p = 0.039).\n\n\nBoth assumptions are not met!\nBut ANOVAS are quite robust to (minor) deviations…\n(if the assumptions are violated more, you could…\n- run a non-parametric test (Kruskall-Wallis for between-subjects designs of Friedman for repeated measures)\n- transform the data (see Field et al., 2009)\n- use bootstrapping (see Field et al., 2009)"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#post-hoc-tests",
    "href": "W9_FirstAnalysisR.html#post-hoc-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Post-Hoc Tests",
    "text": "Post-Hoc Tests\nSo now we know that there are differences between the Conditions, but we don’t know yet which groups differ from each other. We could thus calculate pairwise comparisons or post-hoc t-tests to compare each condition to the others by by filtering the data (so that only two conditions remain) and running t-tests.\nA more convenient way is to use the emmeans() function from the package with the same name. We can also adjust the tests for multiple comparisons directly.\nWe could also define specific contrasts to test a priori (i.e., based on hypotheses). But we will skip this here.\n\nlibrary(emmeans)\nmod %&gt;% emmeans(pairwise ~ Condition, adjust = \"bonferroni\") # also works with mod1!\n\n$emmeans\n Condition emmean    SE df lower.CL upper.CL\n 1           5.11 0.749 68    3.617     6.60\n 2           1.89 0.749 68    0.395     3.38\n 3           3.89 0.749 68    2.395     5.38\n 4           4.83 0.749 68    3.340     6.33\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0199\n Condition1 - Condition3    1.222 1.06 68   1.155  1.0000\n Condition1 - Condition4    0.278 1.06 68   0.262  1.0000\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.3787\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0420\n Condition3 - Condition4   -0.944 1.06 68  -0.892  1.0000\n\nP value adjustment: bonferroni method for 6 tests \n\n\n\nShould we adjust for multiple comparisons? It depends. There are good reasons for either."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#power-effect-sizes",
    "href": "W9_FirstAnalysisR.html#power-effect-sizes",
    "title": "09 Statistical Analyses in R",
    "section": "Power & Effect Sizes",
    "text": "Power & Effect Sizes\nYou should calculate the power before conducting the study, using an estimated effect size based on e.g. prior research:\n\nlibrary(pwr)\n\npwr.anova.test(k = 4, f = .4, sig.level = .05, power = .8)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\n\nYou can calculate effect sizes for each pairwise comparison (the overall effect size for the model is given if you use the aov_ez() function above. It is the ges in the output and represents an effect size called partial eta²).\n\nlibrary(lsr)\n\nd_1_2 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat, Condition %in% c(1,2)) %&gt;% \n                   droplevels())\n\nd_1_3 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat, Condition %in% c(1,3)) %&gt;%\n                   droplevels()) \n\n# and so forth...\n\nd_1_2\n\n[1] 0.9964172\n\nd_1_3\n\n[1] 0.3376282"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#write-up",
    "href": "W9_FirstAnalysisR.html#write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Write Up",
    "text": "Write Up\nOnce again, the apa package helps us here - if we used afex::aov_ez instead of lm 😅:\n\nmod %&gt;% apa::anova_apa()\n\n       Effect                                              \n1 (Intercept) F(1, 68) = 110.29, p &lt; .001, petasq = .62 ***\n2   Condition F(3, 68) =   3.79, p = .014, petasq = .14 *  \n\n\n\n\nmod %&gt;% emmeans(\"Condition\") %&gt;% pairs(adjust=\"none\") #follow up t-tests without adjustment\n\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0033\n Condition1 - Condition3    1.222 1.06 68   1.155  0.2523\n Condition1 - Condition4    0.278 1.06 68   0.262  0.7938\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.0631\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0070\n Condition3 - Condition4   -0.944 1.06 68  -0.892  0.3755\n\n\nLooking at contrasts including condition 1 (control group): Only condition 2 different.\nLet’s get the associated effect size of this specific contrast:\n\n\n\nlibrary(lsr)\ncohensD(intrusions ~ Condition, \n        data = filter(dat, Condition %in% c(1,2)) %&gt;% droplevels())\n\n[1] 0.9964172\n\n\n\n\n\nThere was a significant difference between groups in overall intrusion frequency in daily life, \\(F(3, 68) = 3.79, p = 0.014, \\eta_p^2 = .14\\). Pairwise comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, \\(t(68) = 3.04, p &lt; 0.01, d = 1.00\\), experienced significantly fewer intrusive memories…"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#set-up",
    "href": "W9_FirstAnalysisR.html#set-up",
    "title": "09 Statistical Analyses in R",
    "section": "Set Up",
    "text": "Set Up\n\nOpen RStudio and load your Biostats R project. Create a new script called DataAnalysis1.R.\nInstall and load new packages you’ll need: car, effectsize, and apa."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "href": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "title": "09 Statistical Analyses in R",
    "section": "One Sample Chi²-Test",
    "text": "One Sample Chi²-Test\n\nlibrary(tidyverse) \n\n# Input data into R\nlever_presses &lt;- tibble(levers=c(rep(\"blue\", 5), rep(\"green\", 4), rep(\"red\", 11))) %&gt;% #data in usual format\n  count(levers) #convert to a frequency table\n\n# run Chi² test\nchi2_lever &lt;- chisq.test(lever_presses %&gt;% pivot_wider(names_from=\"levers\", values_from=\"n\")) #wide format needed\n#chi2_lever &lt;- chisq.test(tibble(blue=5, green=4, red=11)) #enter data directly as summary table\n\nchi2_lever %&gt;% apa::chisq_apa() #output results\n\nchi^2(2) = 4.30, p = .116\n\n# add expected count and residuals to data\nlever_presses %&gt;% mutate(expected = chi2_lever$expected, \n                         residuals = chi2_lever$residuals)\n\n# A tibble: 3 × 4\n  levers     n expected residuals\n  &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 blue       5     6.67    -0.645\n2 green      4     6.67    -1.03 \n3 red       11     6.67     1.68 \n\n\n\nIs sample size not important for significance here? \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] More observations =&gt; easier to see greater absolute difference between observed and expected values =&gt; gets squared and therefore “outcompetes” denominator (what about expected reductions in sampling error?)"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-setup",
    "href": "W9_FirstAnalysisR.html#t-test-setup",
    "title": "09 Statistical Analyses in R",
    "section": "t-test setup",
    "text": "t-test setup\nTo run a t-Test, let’s first simulate data. What happens here?\n\nset.seed(31415)\nsim_data_t &lt;- tibble(\n  group = rep(c(\"treatment\", \"control\"), each=20),\n  reaction_times = c(rnorm(20, 400, 100), rnorm(20, 450, 100)))"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-alternative-function-calls",
    "href": "W9_FirstAnalysisR.html#t-test-alternative-function-calls",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: alternative function calls",
    "text": "t-Test: alternative function calls\nYou can also supply two vectors of numerical values for the groups:\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\") #more intuitive now because you can filter for treatment first\n\n\n    Welch Two Sample t-test\n\ndata:  sim_data_t %&gt;% filter(group == \"treatment\") %&gt;% pull(reaction_times) and sim_data_t %&gt;% filter(group == \"control\") %&gt;% pull(reaction_times)\nt = -1.3232, df = 37.735, p-value = 0.09686\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 8.368736\nsample estimates:\nmean of x mean of y \n 408.5894  439.0917 \n\n\n\nMore beautiful output with apa package (only for Student’s t-tests):\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\", \n       var.equal = T) %&gt;% \n  apa::t_apa(es_ci=T) #optional: confidence interval around effect size\n\nt(38) = -1.32, p = .097, d = -0.42 [-1.04; 0.21]"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-alternatives",
    "href": "W9_FirstAnalysisR.html#t-test-alternatives",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: alternatives",
    "text": "t-Test: alternatives\nYou can also supply two vectors of numerical values for the groups:\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\") #more intuitive now because you can filter for treatment first\n\n\n    Welch Two Sample t-test\n\ndata:  sim_data_t %&gt;% filter(group == \"treatment\") %&gt;% pull(reaction_times) and sim_data_t %&gt;% filter(group == \"control\") %&gt;% pull(reaction_times)\nt = -1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n      -Inf -10.02639\nsample estimates:\nmean of x mean of y \n 400.3289  468.0592 \n\n\n\nMore useful output with apa package (only for Student’s t-tests):\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\", \n       var.equal = T) %&gt;% \n  apa::t_apa(es_ci=T) #optional: confidence interval around effect size\n\nt(38) = -1.98, p = .027, d = -0.63 [-1.26; 0.01]\n\n\n\n\nFor paired t-tests, you can also work with the wide format of data (advantage: missing values become explicit):\n\nsim_data_t_wide = sim_data_t %&gt;% mutate(subject=rep.int(1:(n()/2), 2)) %&gt;% \n  pivot_wider(names_from=\"group\", values_from=\"reaction_times\")\nt.test(x = sim_data_t_wide %&gt;% pull(treatment),\n       y = sim_data_t_wide %&gt;% pull(control),\n       alternative = \"less\", \n       paired = T) %&gt;% \n  apa::t_apa(es_ci=T) #optional: confidence interval around effect size\n\nt(19) = -1.98, p = .031, d = -0.44 [-0.90; 0.02]"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-3",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-3",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests 3",
    "text": "Assumptions of t-Tests 3\nAlternatively, we can also run a Shapiro-Wilk test to test for deviations from normality:\n\nshapiro.test(x = treatment)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treatment\nW = 0.91403, p-value = 0.0761\n\nshapiro.test(x = control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.96812, p-value = 0.7147\n\n\nIf the test is non-significant, then we can conclude that normality of residuals is not violated.\n\n\nTransform your data to try and normalise the distribution. Not usually recommended these days but some still use it.\nUse a non-parametric test. The non-parametric equivalent of the independent t-test is the Mann-Whitney and the equivalent of the paired-samples t-test is the Wilcoxon signed-ranks test. Though more modern permutation tests are better.\nDo nothing. Delacre, Lakens & Leys, 2017 argue that with a large enough sample (&gt;30), the Welch test is robust to deviations from assumptions. With very large samples normality is even less of an issue, so design studies with large samples."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#optional-assumptions-of-the-paired-samples-t-test-2",
    "href": "W9_FirstAnalysisR.html#optional-assumptions-of-the-paired-samples-t-test-2",
    "title": "09 Statistical Analyses in R",
    "section": "Optional: Assumptions of the Paired-Samples t-Test 2",
    "text": "Optional: Assumptions of the Paired-Samples t-Test 2\n\nThe data are continuous.\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\n\nA paired-samples t-test actually tests whether the difference between two measurements is significantly different from 0 (= no difference/effect).\nIn our example data, this means that the test values are subtracted from the baseline values, and this difference is used as data.\nTo test the assumption that residuals are normally distributed, we thus calculate the residuals as follow:\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\n\n\n\n[1] 22 29\n\nshapiro.test(gaze_residual$group_resid)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#optional-paired-samples-t-test",
    "href": "W9_FirstAnalysisR.html#optional-paired-samples-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Optional: Paired Samples t-Test",
    "text": "Optional: Paired Samples t-Test\nSometimes you have dependent data: These data are somehow correlated, e.g. they belong to the same subject (that you measured repeatedly across a within-subject manipulation).\n\nIn this case, you would use a paired-samples t-test.\n\n\nLet’s run such a t-test with real data. We’ll use the Mehr Song and Spelke 2016 Experiment 1.csv file (note that this is not a good file name!).\nIn this dataset, the authors examined whether infants exposed to certain songs would recognize strangers singing these lullabies as part of their social group. Parents sang certain lullabies to their infants for 1-2 weeks. During the experiment, the infants looked at videos of two strangers: First the strangers were just smiling (baseline phase), then they would sing either the familiar or an unfamiliar lullaby. Finally, the infants again saw the videos of the strangers smiling (test phase). Eye-tracking (duration looked at each stranger) was measured.\n\n\nLoad the file into your Environment. Run the code and explain what happens:\n\ngaze &lt;- read_csv(\"Mehr Song and Spelke 2016 Experiment 1.csv\") %&gt;%\n  filter(exp1 == 1) %&gt;%\n  select(id,\n         Baseline_Proportion_Gaze_to_Singer,\n         Test_Proportion_Gaze_to_Singer) %&gt;%\n  rename(baseline = Baseline_Proportion_Gaze_to_Singer,\n         test = Test_Proportion_Gaze_to_Singer)"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "href": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of the Paired-Samples t-Test",
    "text": "Assumptions of the Paired-Samples t-Test\n\nThe data are continuous.\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\n\nA paired-samples t-test actually tests whether the difference between two measurements is significantly different from 0 (= no difference/effect).\nIn our example data, this means that the test values are subtracted from the baseline values, and this difference is used as data.\nTo test the assumption that residuals are normally distributed, we thus calculate the residuals as follow:\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\n\n\n\n[1] 22 29\n\nshapiro.test(gaze_residual$group_resid)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#summary-optional-activity",
    "href": "W9_FirstAnalysisR.html#summary-optional-activity",
    "title": "09 Statistical Analyses in R",
    "section": "Summary: Optional Activity",
    "text": "Summary: Optional Activity\n\n\nMost things are similar between independent and dependent sample t-tests\nMake sure to include paired=T for repeated measures to get correct results\nRecommendation: Use apa::t_apa() with es.ci=T to get (most of) the information you need\nIt is often a good idea to also report means and standard deviations per group (summarise with .by argument)\nPlotting: Unfortunately, (between subjects) confidence intervals are not diagnostic for the significance of dependent samples. Instead, we need the confidence interval around the paired differences (i.e., the within subject changes). Since this is not easy to do and there is little consensus yet, I will just raise awareness here."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-2",
    "href": "W9_FirstAnalysisR.html#correlations-2",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations 2",
    "text": "Correlations 2\nWith these data, we might be interested in whether there is a relationship between the two measures of gaze, i.e., whether those children who looked at the stranger more at baseline would also be the ones who looked at the stranger more often at the follow-up test (here: indicating stability of preferences).\n\nSimilar to the paired t-Test, the continuous variables are also “paired” within subjects. Thus, we can a similar syntax that is easier for a wide format of data (gaze instead of gaze_tidy):\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", \n         alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  gaze %&gt;% pull(baseline) and gaze %&gt;% pull(test)\nt = 3.5686, df = 30, p-value = 0.00123\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2435655 0.7515352\nsample estimates:\n      cor \n0.5458966 \n\n\nNote: We don’t have to indicate paired=T because correlations only work for paired values."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-write-up",
    "href": "W9_FirstAnalysisR.html#correlations-write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Write Up",
    "text": "Correlations: Write Up\nOnce again, the apa package offers help to summarize the results:\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", \n         alternative = \"two.sided\") %&gt;% \n  apa::cor_apa(r_ci=T)\n\nr(30) = .55 [.24; .75], p = .001\n\n\n\nYou can even use report() to get an automatic suggestion of how to report the results (works with a lot of different models!).\n\nlibrary(report)\nwith(gaze, cor.test(x = baseline, \n                    y = test, \n                    method = \"pearson\", \n                    alternative = \"two.sided\")) %&gt;% \n  report()\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between baseline and test is positive,\nstatistically significant, and very large (r = 0.55, 95% CI [0.24, 0.75], t(30)\n= 3.57, p = 0.001)\n\n\n\nWe mainly use this dataset so that you don’t have to load another one, but in practice you would either run a t-test or a correlation, not necessarily both!\nThe t-tests answers whether there is a change across all participants between the two time points, the correlation answers the question whether those who score high at one time point would also score high at the next (regardless of overall level)."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlation-test",
    "href": "W9_FirstAnalysisR.html#correlation-test",
    "title": "09 Statistical Analyses in R",
    "section": "Correlation Test",
    "text": "Correlation Test\nWith these data, we might be interested in whether there is a relationship between the two measures of gaze, i.e., whether those children who looked at the stranger more at baseline would also be the ones who looked at the stranger more often at the follow-up test (here: indicating stability of preferences).\n\nSimilar to the paired t-Test, the continuous variables are also “paired” within subjects. Thus, we can a similar syntax that is easier for a wide format of data (gaze instead of gaze_tidy):\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", \n         alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  gaze %&gt;% pull(baseline) and gaze %&gt;% pull(test)\nt = 3.5686, df = 30, p-value = 0.00123\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2435655 0.7515352\nsample estimates:\n      cor \n0.5458966 \n\n\nNote: We don’t have to indicate paired=T because correlations only work for paired values."
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-notes",
    "href": "W9_FirstAnalysisR.html#correlations-notes",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Notes",
    "text": "Correlations: Notes\nThere are also some assumptions that need to be checked:\n\nAre the data continuous? (for ordinal values: Spearman’s rho)\nIs there a data point for each participant on both variables? (paired values)\nAre the residuals normally distributed?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity? (Variance of residuals should be constant across x-axis)\nNote: This is very hard to judge by eye and is not the same as the confidence band around the regression line to show constant width. In fact, the latter will always be larger near the ends of the regression line due to how it is computed.\n\nPlease see the text book for how to test these assumptions.\n\nYou should - as always - report the descriptive statistics (summary statistics such as mean and SD).\n\n\nYou can also report and visualize multiple correlations at once, using a scatterplot matrix or heatmaps. Check out e.g. the corrplot package!"
  },
  {
    "objectID": "W9_FirstAnalysisR.html#effect-sizes-power",
    "href": "W9_FirstAnalysisR.html#effect-sizes-power",
    "title": "09 Statistical Analyses in R",
    "section": "Effect Sizes & Power",
    "text": "Effect Sizes & Power\nThe most common effect size estimate for an ANOVA is partial eta squared \\(\\eta_p^2\\) (as we calculated with afex::aov_ez before). We get one per factor and it summarizes all pairwise effects within it.\nWe could also calculate Cohen’s d for each pairwise comparison within the factor but this is tedious and gets confusing quickly (1 factor with 5 levels = 10 effects; 3 factors with 5 levels each = 30 effects). It’s still sad that emmeans doesn’t output it as one additional column.\n\n\n\nEffect sizes are important to calculate the statistical power of your study before conducting it. Use an estimated effect size based on prior research:\n\nlibrary(pwr)\npwr.anova.test(k = 4, f = .4, sig.level = .05, power = .8) #we leave out the n parameter to let it be calculated\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group"
  },
  {
    "objectID": "W10_GLM.html#definitions",
    "href": "W10_GLM.html#definitions",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Definitions",
    "text": "Definitions\nDependent variable (DV): The outcome variable that the model aims to explain (\\(Y\\)).\nIndependent variable (IV): The variable(s) that we use to explain the DV (\\(X\\)).\nLinear model: The model for the DV is composed of a linear combination of IVs (that are multiplied by different weights!)\n\nThe weights are the parameters \\(\\beta\\) and determine the relative contribution of each IV. (This is what the model estimates! The weights thus give us the important information we’re usually interested in: How strong are IV and DV related.)\nThere may also be several DVs (“multivariate statistics”), but usually that’s not the case except for specific biopsychological methods (e.g., fMRI). Thus, we will focus on those cases with one DV!"
  },
  {
    "objectID": "W10_GLM.html#example",
    "href": "W10_GLM.html#example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Example",
    "text": "Example\n\n\nLet’s use some simulated data:\n\n\n\n\n\n\nWe can calculate the correlation between the two variables:\n\n\n\n    Pearson's product-moment correlation\n\ndata:  df$grade and df$studyTime\nt = 2.0134, df = 6, p-value = 0.09073\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1261283  0.9255245\nsample estimates:\n      cor \n0.6349813 \n\n\nr(6) = .63 [-.13; .93], p = .091\n\n\nThe correlation is quite high (.63), but the CI is also pretty wide.\n\n\n\nFundamental activities of statistics:\n\nDescribe: How strong is the relationship between grade and study time?\nDecide: Is there a statistically significant relationship between grade and study time?\nPredict: Given a particular amount of study time, what grade do we expect?\n\n\nrelationship study time and grade"
  },
  {
    "objectID": "W10_GLM.html#linear-regression",
    "href": "W10_GLM.html#linear-regression",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nUse the GLM to…\n\n\ndescribe the relation between two variables (similar to correlation)\npredict DV for new values of IV (new observations)\nadd multiple IVs!\n\n\n\n\n\nSimple GLM (here: equivalent to linear regression):\n\\[\ny = \\beta_0+ x * \\beta_x + \\epsilon\n\\]\n\\(\\beta_0\\) = intercept: the overall offset of the line when \\(x=0\\) (this cannot always be interpreted)\n\\(\\beta_x\\) = slope: how much do we expect \\(y\\) to change with each change in \\(x\\)?\n\\(y\\) = DV\n\\(x\\) = IV or predictor\n\\(\\epsilon\\) = error term* or resudials: whatever variance is left once the model is fit (Think of the model as the blue line and the residuals are the vertical deviations of the data points from the line)\n(If we refer to predicted \\(y\\)-values, after we have estimated the model, we can drop the error term: \\(\\hat{y} = \\hat{\\beta_0} + x * \\hat{\\beta_x}\\).)"
  },
  {
    "objectID": "W10_GLM.html#the-relation-between-correlation-and-regression",
    "href": "W10_GLM.html#the-relation-between-correlation-and-regression",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "The Relation Between Correlation and Regression",
    "text": "The Relation Between Correlation and Regression\nThere is a close relation and we can convert \\(r\\) to \\(\\hat{\\beta_x}\\).\n\\(\\hat{r} = \\frac{covariance_{xy}}{s_x * s_y}\\)\n\\(\\hat{\\beta_x} = \\frac{covariance_{xy}}{s_x*s_x}\\)\n\\(covariance_{xy} = \\hat{r} * s_x * s_y\\)\n\\(\\hat{\\beta_x} = \\frac{\\hat{r} * s_x * s_y}{s_x * s_x} = r * \\frac{s_y}{s_x}\\)\n--&gt; Regression slope = correlation multiplied by ratio of SDs (if SDs are equal, \\(r\\) = \\(\\hat{\\beta}\\) )\n\nEstimation of GLM:\nlinear algebra (R will do that for us!) –&gt; Appendix book"
  },
  {
    "objectID": "W10_GLM.html#standard-errors-for-regression-models",
    "href": "W10_GLM.html#standard-errors-for-regression-models",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Standard Errors for Regression Models",
    "text": "Standard Errors for Regression Models\nWe usually want to make inferences about the regression parameter estimates. For this we need an estimate of their variability.\nWe first need an estimate of how much variability is not explained by the model: the residual variance (or error variance):\nCompute residuals:\n\\[\nresidual = y - \\hat{y} = y - (x*\\hat{\\beta_x} + \\hat{\\beta_0})\n\\]\nCompute Sum of Squared Errors (remember from ANOVA?):\n\\[\nSS_{error} = \\sum_{i=1}^n{(y_i - \\hat{y_i})^2} = \\sum_{i=1}^n{residuals^2}\n\\]\nCompute Mean Squared Error:\n\\[\nMS_{error} = \\frac{SS_{error}}{df} = \\frac{\\sum_{i=1}^n{(y_i - \\hat{y_i})^2} }{N - p}\n\\]\nwhere the \\(df\\) are the number of observations \\(N\\) - the number of estimated parameter \\(p\\) (in this case 2: \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_x}\\)).\nFinally, we can calculate the standard error for the full model:\n\\[\nSE_{model} = \\sqrt{MS_{error}}\n\\]\nWe can also calculate the SE for specific regression parameter estimates by rescaling the \\(SE_{model}\\):\n\\[\nSE_{\\hat{\\beta_x}} = \\frac{SE_{model}}{\\sqrt{\\sum{(x_i - \\bar{x})^2}}}\n\\]\n\nrescaling SE: by square root of the SS of the X variable"
  },
  {
    "objectID": "W10_GLM.html#statistical-tests-for-regression-parameters",
    "href": "W10_GLM.html#statistical-tests-for-regression-parameters",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Statistical Tests for Regression Parameters",
    "text": "Statistical Tests for Regression Parameters\nWith the parameter estimates and their standard errors, we can compute \\(t\\)-statistics, which represent the likelihood of the observed estimate vs. the expected value under \\(H_0\\) (usually 0, no effect).\n\\[\n\\begin{array}{c}\nt_{N - p} = \\frac{\\hat{\\beta} - \\beta_{expected}}{SE_{\\hat{\\beta}}}\\\\\nt_{N - p} = \\frac{\\hat{\\beta} - 0}{SE_{\\hat{\\beta}}}\\\\\nt_{N - p} = \\frac{\\hat{\\beta} }{SE_{\\hat{\\beta}}}\n\\end{array}\n\\]"
  },
  {
    "objectID": "W10_GLM.html#quantifying-goodness-of-fit-of-the-model",
    "href": "W10_GLM.html#quantifying-goodness-of-fit-of-the-model",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Quantifying Goodness of Fit of the Model",
    "text": "Quantifying Goodness of Fit of the Model\nOften, it is useful to check how good the (total) model we estimated fits the data.\n\nWe can do that easily by asking how much of the variability in the data is accounted for by the model?\n\n\nIf we only have one IV (\\(x\\)), then we can simply square the correlation coefficient:\n\\[\nR^2 = r^2\n\\]\nIn study time example, \\(R^2\\) = 0.63² = 0.4 –&gt; we accounted for 40% of the overall variance in grades!\n\n\nMore generally, we can calculate \\(R^2\\) with the Sum of Squared Variances:\n\\[\nR^2 = \\frac{SS_{model}}{SS_{total}} = 1-\\frac{SS_{error}}{SS_{total}}\n\\]\n\n\nWith a sample of sufficient size, it is possible to get highly significant values that still explain very little of the total variance (i.e., little practical significance despite statistical significance)\n\n\\(R^2\\) is the name of the Goodness of Fit stat!\nA small R² tells us that even though a model might be significant, it may only explain a small amount of information in the DV"
  },
  {
    "objectID": "W10_GLM.html#fitting-more-complex-models",
    "href": "W10_GLM.html#fitting-more-complex-models",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Fitting More Complex Models",
    "text": "Fitting More Complex Models\nOften we want to know the effects of multiple variables (IVs) on some outcome.\nExample:\nSome students have taken a very similar class before, so there might not only be the effect of studyTime on grades, but also of having taken a priorClass.\n\n\n\nWe can built a model that takes both into account by simply adding the “weight” and the IV (priorClass) to the model:\n\\(\\hat{y} = \\hat{\\beta_1}*studyTime + \\hat{\\beta_2}*priorClass + \\hat{\\beta_0}\\)\n\n\nTo model priorClass, i.e. whether each individual has taken a previous class or not, we use dummy coding (0=no, 1=yes).\nThis means, for those who have not taken a class, the whole part of the equation (\\(\\hat{\\beta_2} * priorClass\\)) will be zero - we will add it for the others.\n\\(\\hat{\\beta_2}\\) is thus the difference in means between the two groups!\n\\(\\hat{\\beta_1}\\) is the regression slope of studyTime across data points/regardless of whether someone has taken a class before.\n\n\n\nIf we plot the data, we can see that both IVs seem to have an effect on grades:\n\n\n\n\n\n\n\n\nHow can we tell from the plot that both IVs might have an effect?"
  },
  {
    "objectID": "W10_GLM.html#interactions-between-variables",
    "href": "W10_GLM.html#interactions-between-variables",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interactions Between Variables",
    "text": "Interactions Between Variables\nWe previously assumed that the effect of studyTime on grade was the same for both groups - but sometimes we expect that this regression slope differs per group!\nE.g., due to prior knowledge from another class, it may be easier to profit from studying the new materials (i.e., steeper slope). Or it may be harder due to diminishing marginal returns (i.e., flatter slope).\n\n\nThis is what we call an interaction: The effect of one variable depends on the value of another variable.\nThus, priorClass can have a main effect on grade (i.e., independent of studyTime): “I already know more, so I don’t need to study”.\nBut it can also interact with studyTime: “Due to my prior knowledge, I can study more efficiently.”"
  },
  {
    "objectID": "W10_GLM.html#interactions-2",
    "href": "W10_GLM.html#interactions-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interactions 2",
    "text": "Interactions 2\nWhat if we find research suggesting that anxious people react differently to caffeine than non-anxious people?\nLet’s include anxiety in the model:\n\n\n\n# compute linear regression adding anxiety to model\nlmResultCafAnx &lt;- lm(speaking ~ caffeine + anxiety, data = df)\nsummary(lmResultCafAnx)\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.968  -9.743   1.351  10.530  25.361 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)       -12.5812     9.1967  -1.368    0.189\ncaffeine            0.1313     0.1446   0.908    0.377\nanxietynotAnxious  14.2328     8.2324   1.729    0.102\n\nResidual standard error: 18.21 on 17 degrees of freedom\nMultiple R-squared:  0.2041,    Adjusted R-squared:  0.1105 \nF-statistic:  2.18 on 2 and 17 DF,  p-value: 0.1436\n\n\n\n\n\n\n\n\n\n\n\nIt looks like the effect of caffeine is indeed different for the two anxiety groups: Increasing for non-anxious people and decreasing for anxious ones.\nHowever, the model is not significant!\n\n\nThis is due to the fact that we only look at additive effects (main effects) with this model. Overall, neither caffeine nor anxiety predicts grades.\nIn other words: The model tries to fit the same slope for both groups, which is a flat line.\n\nexplain additive effects: flat line for average caffeine effect, no difference for means of anxiety groups"
  },
  {
    "objectID": "W10_GLM.html#interactions-3",
    "href": "W10_GLM.html#interactions-3",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interactions 3",
    "text": "Interactions 3\nTo allow for different slopes for each group (i.e. for the effect of caffeine to vary between the anxiety groups), we have to model the interaction as well.\nThe interaction is simply the product of the two variables:\n\n\n\n# compute linear regression including caffeine X anxiety interaction\nlmResultInteraction &lt;- lm(\n  speaking ~ caffeine + anxiety + caffeine:anxiety,\n  # speaking ~ caffeine * anxiety,  # same!\n  data = df\n)\nsummary(lmResultInteraction)\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety + caffeine:anxiety, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.385  -7.103  -0.444   6.171  13.458 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 17.43085    5.43012   3.210 0.005461 ** \ncaffeine                    -0.47416    0.09664  -4.906 0.000158 ***\nanxietynotAnxious          -43.44873    7.79141  -5.576 4.17e-05 ***\ncaffeine:anxietynotAnxious   1.08395    0.12931   8.382 3.01e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.085 on 16 degrees of freedom\nMultiple R-squared:  0.8524,    Adjusted R-squared:  0.8247 \nF-statistic:  30.8 on 3 and 16 DF,  p-value: 7.014e-07\n\n\n\n\n\n\n\n\n\n\n\nWe now see that there are significant main effects for both caffeine and anxiety, as well as the significant interaction between both variables. (We have to be careful of interpreting the main effects when an interaction is also significant!)\n\n\nThe interpretation of the coefficients when interactions are included is not as straight forward!\n\n\nIf you want to report the “typical” ANOVA table with main effects and the general interaction:\n\nanova(lmResultInteraction)\n\nAnalysis of Variance Table\n\nResponse: speaking\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncaffeine          1  454.8   454.8  6.9578 0.017911 *  \nanxiety           1  991.5   991.5 15.1678 0.001288 ** \ncaffeine:anxiety  1 4593.4  4593.4 70.2662 3.01e-07 ***\nResiduals        16 1045.9    65.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ninterpretation coefficients:\nintercept: intercept of anxious group!\nintercept not anxious: difference intercept anxiousnotanxious\nslope anxious: only for the anxious group!\nslope not anxious: diff in slopes\nno main effects!!!"
  },
  {
    "objectID": "W10_GLM.html#model-comparison",
    "href": "W10_GLM.html#model-comparison",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Model Comparison",
    "text": "Model Comparison\nSometimes, we want to compare two (nested!) models to see which one fits the data better.\nWe can do so by using the anova()* function in R:\n\nanova(lmResultCafAnx, lmResultInteraction)\n\nAnalysis of Variance Table\n\nModel 1: speaking ~ caffeine + anxiety\nModel 2: speaking ~ caffeine + anxiety + caffeine:anxiety\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)    \n1     17 5639.3                                 \n2     16 1045.9  1    4593.4 70.266 3.01e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis shows that Model 2, incl. the interaction, is to be preferred.\n\nNote: We can only meaningfully use this method with so-called nested models, which means that the simpler (reduced) model only contains variables also included in the more complex (full) model.\n\n\nWald compares the ratio of squared errors to an F-distribution (sound familiar from ANOVA?), while likelihood ratio compares the ratio of likelihoods to a χ2 distribution\n\n\n\n*Yes, it is kind of an ANOVA as well, in that (a ratio of) squared errors is compared to an \\(F\\)-distribution…"
  },
  {
    "objectID": "W10_GLM.html#criticizing-our-model-and-checking-assumptions",
    "href": "W10_GLM.html#criticizing-our-model-and-checking-assumptions",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Criticizing Our Model and Checking Assumptions",
    "text": "Criticizing Our Model and Checking Assumptions\n“Garbage in, garbage out” - we have to make sure our model is properly specified!\n\nProperly specified = having included the appropriate IVs.\n\n\nThe model also needs to satisfy the assumptions of the statistical method (= GLM).\nOne important assumption of the GLM is that the residuals are normally distributed.\nThis assumption can be violated by a not properly specified model or because the data are inappropriate for the statistical model.\n\n\nWe can use a Q-Q plot, which represents the quantiles of two distributions/variables (e.g., the data and a normal distribution of the same data) against each other.\nIf the data points diverge substantially from the line (especially in the extremes), we can conclude that the residuals are not normally distributed."
  },
  {
    "objectID": "W10_GLM.html#model-diagnostics-2",
    "href": "W10_GLM.html#model-diagnostics-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Model Diagnostics 2",
    "text": "Model Diagnostics 2\nTo check the assumptions, we can easily run a function for model diagnostics (incl. Q-Q plots) in R. The function, check_model(), is included in the performance package by the easystats team (who make great packages for everything related to statistical modeling!)\n\n# install.packages(\"easystats)\nlibrary(performance)\n\ncheck_model(lmResultInteraction)\n\n\n\nWe’re not going into detail about all these diagnostics (and hard to see!), but it is always a good idea to run diagnostics/check assumptions for your models!"
  },
  {
    "objectID": "W10_GLM.html#what-does-predict-really-mean",
    "href": "W10_GLM.html#what-does-predict-really-mean",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "What Does “Predict” Really Mean?",
    "text": "What Does “Predict” Really Mean?\nWe neither mean “predicting before seeing the data/in the future” nor mean to imply causality!\n\nIt simply refers to fitting a model to the data: We estimate (or predict) values for the DV (\\(\\hat{y}\\)) and the IVs are often referred to as predictors.\n\nRelated to: predicting future values"
  },
  {
    "objectID": "W10_GLM.html#multivariate-data-an-example",
    "href": "W10_GLM.html#multivariate-data-an-example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Multivariate Data: An Example",
    "text": "Multivariate Data: An Example\nHow do different aspects of psychological function (self-control etc.) relate to one another?\n10h battery of cognitive tests and surveys, N = 522, 9 measures of interest!\nMeasures:\n\nResponse inhibition: ability to quickly stop an action (measured with the stop-signal task, measure is called stop-signal reaction time (SSRT) - we have 4 different versions of this measure).\nImpulsivity: tendency to make decisions on impulse, without regard of potential consequences (UPPS-P survey, assesses 5 facets of impulsivity)."
  },
  {
    "objectID": "W10_GLM.html#visualizing-multivariate-data",
    "href": "W10_GLM.html#visualizing-multivariate-data",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Visualizing Multivariate Data",
    "text": "Visualizing Multivariate Data\nHard (impossible?) for us to visualize more than three dimensions/variables.\n\nScatterplot of matrices for the nine variables in the self-control dataset. The diagonal elements in the matrix show the histogram for each of the individual variables. The lower left panels show scatterplots of the relationship between each pair of variables, and the upper right panel shows the correlation coefficient for each pair of variables.\nWhat do you see?\neach row/col –&gt; single variable\ndiagonal: dist each var\nlower triangle: scatterplot each pair, regression line –&gt; relationship\nupper: correlation coefficient"
  },
  {
    "objectID": "W10_GLM.html#heatmap",
    "href": "W10_GLM.html#heatmap",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Heatmap",
    "text": "Heatmap\nVisualize correlations:\n\nHeatmap of the correlation matrix for the nine self-control variables. The brighter yellow areas in the top left and bottom right highlight the higher correlations within the two subsets of variables.We can see clear clusters: SSRT and UPPS have greater intercorrelations than correlations with the other measure."
  },
  {
    "objectID": "W10_GLM.html#heatmap-2",
    "href": "W10_GLM.html#heatmap-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Heatmap 2",
    "text": "Heatmap 2\nHeatmaps are especially helpful if we have a large number of variables, such as in neuroimaging! Below you can see the functional connectivity of &gt;300 brain regions:\n\nHeatmap of correlation coefficients of brain activity between 316 regions of the left hemisphere of a single individual. Yellow: strong positive correlations, blue: strong negative correlations\nlarge blocks of pos corr: major connected networks in the brain"
  },
  {
    "objectID": "W10_GLM.html#clustering",
    "href": "W10_GLM.html#clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Clustering",
    "text": "Clustering\nClustering: Identifying groups of related observations or variables within a dataset, based on the similarity of the values of the observations.\n\nSimilarity: Distance between values.\nEuclidean Distance: Length of the line that connects two data points:\n\n\n\n\n\n\\[\nd(x,y) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\n\\]\n\n\nEuclidean Distance is sensitive to variability in both variables –&gt; scale data before! (e.g., z-transformation using R’s scale function)\n\nClustering: finding set of groups that have the lowest distance between their members.\nEuclidean Dist: Pythagorean theorem\n–&gt; can be extended to more than two dimensions!\nScale: calculate z-score, standardizing\nExample: Relation between height and weight =&gt; it shouldn’t make a difference if we rescale the data from m to cm or from kg to pounds."
  },
  {
    "objectID": "W10_GLM.html#k-means-clustering",
    "href": "W10_GLM.html#k-means-clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "K-Means Clustering",
    "text": "K-Means Clustering\nK-means clustering: Identifies a set of cluster centers & then assigns each data point to the cluster whose center is the closest (Euclidean Distance!).\n\n\nDecide on value for K, the number of clusters to be found (e.g. based on previous knowledge/expectations).\nCome up with k locations for the centers - or centroids - of the clusters (e.g. choose data points at random to start with).\nCompute Euclidean distance of each data point to each centroid.\nAssign each point to a cluster, based on closest distance to centroid.\nRecompute centroid by averaging the location of all points assigned to that cluster.\nRepeat steps 1-5 until a stable solution is found (iterative process)."
  },
  {
    "objectID": "W10_GLM.html#example-latitudelongitude-data",
    "href": "W10_GLM.html#example-latitudelongitude-data",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Example: Latitude/Longitude Data",
    "text": "Example: Latitude/Longitude Data\n\n\nHere we can see the starting points (black squares) and end points (big colored dots) for each cluster, as well as the final cluster assignment of each data point (color):\n\n\n\n\n\n\nWe can see that there is a reasonable overlap between clusters and continents.\nWe can further investigate this overlap with the confusion matrix, which compares membership of each cluster with the actual continents for each country:\n\n\n      \nlabels AF AS EU NA OC SA\n     1  5  1 36  0  0  0\n     2  3 24  0  0  0  0\n     3  0  0  0  0  0  7\n     4  0  0  0 15  0  4\n     5  0 10  0  0  6  0\n     6 35  0  0  0  0  0\n\n\nNote: usually we don’t know the ground truth (i.e. which continent) in unsupervised learning!\n=&gt; confusion matrix cannot be estimated\nNote 2: Every time we run the iterative process, we will get a different result if we use random starting points. Make sure the result is robust, e.g. by running the Clustering algorithm several times.)\n\n\n\n\nCluster 1 contains all European countries, as well as countries from northern Africa and Asia.\n\n\n\nCluster 2 contains contains Asian countries as well as several African countries.\nCluster 3 contains countries from the southern part of South America.\nCluster 4 contains all of the North American countries as well as northern South American countries.\nCluster 5 contains Oceania as well as several Asian countries\nCluster 6 contains all of the remaining African countries."
  },
  {
    "objectID": "W10_GLM.html#hierarchical-clustering",
    "href": "W10_GLM.html#hierarchical-clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering\nHierarchical Clustering: Also uses distances to determine clusters but also visualizes relationships in dendrograms.\n\n\nThe most common procedure is agglomerative clustering:\n\n\nEvery data point is treated as its own cluster.\nTwo clusters with the least distance (e.g. average linkage) between them are combined.\nRepeat 1 & 2 until only one cluster is left.\nVisualize, decide on a cutoff for the amount of reasonable clusters.\n\n\n\n\n\n\n\n\nColored lines: different cutoffs.\n\n\n\nThere seems to be a high degree of similarity within each variable set (SSRT and UPPS) compared to between sets.\n=&gt; The first split separates UPPS vs. SSRT perfectly.\nWithin UPPS, sensation seeking stands out as the most different to the rest.\n\naverage linkage: average of all distances between each data point in each of two clusters.\nCan read diagram from left to right: One supercluster that is split up more and more. Or right to left: Individual points that get joint together into bigger and bigger clusters.\ncolored lines: different cutoff values"
  },
  {
    "objectID": "W10_GLM.html#dimensionality-reduction",
    "href": "W10_GLM.html#dimensionality-reduction",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nWe often measure different variables that are highly similar to each other, e.g. because they are supposed to measure the same construct.\nAlthough we might measure a particular number of variables (= dimensionality of data set), there may be fewer independent sources of underlying information!\nDimensionality reduction: Reduce the number of variables by creating composite variables that reflect the underlying information."
  },
  {
    "objectID": "W10_GLM.html#principal-component-analysis-pca",
    "href": "W10_GLM.html#principal-component-analysis-pca",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Principal Component Analysis (PCA)",
    "text": "Principal Component Analysis (PCA)\nAim: Find a lower-dimensional (linear) description of a set of variables (that still accounts for the maximum possible information/variance in the dataset).\nVariance: Combination of signal + noise –&gt; find strongest common signal between variables!\n\n1st Component: explains most variance between variables, 2nd component: maximum of remaining variance - but uncorrelated with 1st…\n\n\n\n\n\n\n\n\n\n\nGreen arrow: 1st component, follows direction of max. variance\nRed arrow: 2nd component, perpendicular to 1st =&gt; uncorrelated!\nWe can run a PCA on more than two variables!\n\n\n\nobtain as many components as there are variables (assuming that there are more observations than there are variables)\nin practice: find a small number of components that can explain a large portion of the variance.\n1st component: similar to regression line, but minimizes perpendicular distance points to line (not vertical!)"
  },
  {
    "objectID": "W10_GLM.html#pca-2",
    "href": "W10_GLM.html#pca-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "PCA 2",
    "text": "PCA 2\nIf we calculate a PCA on the impulsivity data, we see that there are two components (in the scree plot) that account for quite some variance.\nWe can also look at the variable loadings, which show which variable “goes into” which component to better specify what that component represents. Here we can see that one components represents (=captures variance related to) the SSRT variables, the other the UPPS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScree plot: Sometimes used to make decisions on number of components (eigenvalues plotted)\nloadings: sign is arbitrary"
  },
  {
    "objectID": "W10_GLM.html#factor-analysis",
    "href": "W10_GLM.html#factor-analysis",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Factor Analysis",
    "text": "Factor Analysis\nPCA is useful for reducing a dataset.\nThe components are per definition uncorrelated –&gt; sometimes this is a limitation.\nPCA also doesn’t account for measurement error –&gt; possibly difficult to interpret loadings.\n\nExploratory Factor Analysis: can also be used for dimensionality reduction.\nIdea: Each observed variable is created through a combination of contributions from a latent variable + measurement error. (latent: can’t be directly observed!)\n\n\nHow do different measures relate to underlying factor (that gives rise to these measures)?"
  },
  {
    "objectID": "W10_GLM.html#fa-2",
    "href": "W10_GLM.html#fa-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "FA 2",
    "text": "FA 2\n\n\n\n\n\n\n\n\n\n\n\nFactor analysis with Call: fa(r = observed_df, nfactors = 3)\n\nTest of the hypothesis that 3 factors are sufficient.\nThe degrees of freedom for the model is 7  and the objective function was  0.04 \nThe number of observations was  200  with Chi Square =  7.96  with prob &lt;  0.34 \n\nThe root mean square of the residuals (RMSA) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nTucker Lewis Index of factoring reliability =  0.993\nRMSEA index =  0.026  and the 10 % confidence intervals are  0 0.094\nBIC =  -29.13\n\n\n\n\n\n\n\nRMSEA (root mean square error of approximation): Measure of model fit, should be &lt; .08.\nUse (lowest) SABIC (sample-size adjusted Bayesian information criterion) to compare models with different number of factors.\n\nWe can “hand over” 3 factors\nRMSEA quantifies how far predicted covariances (between data) are from actual covariances"
  },
  {
    "objectID": "W10_GLM.html#glm-results",
    "href": "W10_GLM.html#glm-results",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "GLM results",
    "text": "GLM results\nUsually, we would just let R do the calculations:\n\nsummary(lmResult)\n\n\nCall:\nlm(formula = grade ~ studyTime, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.656  -2.719   0.125   4.703   7.469 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   76.156      5.161  14.756 6.09e-06 ***\nstudyTime      4.313      2.142   2.013   0.0907 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.386 on 6 degrees of freedom\nMultiple R-squared:  0.4032,    Adjusted R-squared:  0.3037 \nF-statistic: 4.054 on 1 and 6 DF,  p-value: 0.09073\n\n\nThe intercept is significantly different from zero (which is usually not very relevant: with 0 study time, you don’t get 0%) and the effect of studyTime is not (or only “marginally”) significant. So for every hour that we study more, the effect on the grade is descriptively rather small (~4%) but possibly not present at all (because it is not statistically significant).\n\n\\(t\\) ratio of \\(\\beta\\) to its \\(SE\\)!\nintercept: expected grade without studying at all"
  },
  {
    "objectID": "W10_GLM.html#interaction-example",
    "href": "W10_GLM.html#interaction-example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example",
    "text": "Interaction Example\nExample: What is the effect of caffeine on public speaking?\n\n\n\n\n\n# perform linear regression with caffeine as independent variable\nlmResultCaffeine &lt;- lm(speaking ~ caffeine, data = df)\nsummary(lmResultCaffeine)\n\n\nCall:\nlm(formula = speaking ~ caffeine, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.096 -16.024   5.014  16.453  26.979 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -7.4132     9.1653  -0.809    0.429\ncaffeine      0.1676     0.1508   1.111    0.281\n\nResidual standard error: 19.19 on 18 degrees of freedom\nMultiple R-squared:  0.06419,   Adjusted R-squared:  0.0122 \nF-statistic: 1.235 on 1 and 18 DF,  p-value: 0.2811\n\n\n\n\n\n\n\n\n\n\n\nThere doesn’t seem to be a “direct” (bivariate) effect:"
  },
  {
    "objectID": "W10_GLM.html#interaction-example-two-main-effects",
    "href": "W10_GLM.html#interaction-example-two-main-effects",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example: Two main effects",
    "text": "Interaction Example: Two main effects\nWhat if we have the hypothesis that anxiety also affects public speaking?\n\n\n\n\n\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.968  -9.743   1.351  10.530  25.361 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)       -12.5812     9.1967  -1.368    0.189\ncaffeine            0.1313     0.1446   0.908    0.377\nanxietynotAnxious  14.2328     8.2324   1.729    0.102\n\nResidual standard error: 18.21 on 17 degrees of freedom\nMultiple R-squared:  0.2041,    Adjusted R-squared:  0.1105 \nF-statistic:  2.18 on 2 and 17 DF,  p-value: 0.1436\n\n\n\n\n\n\n\n\n\n\n\nThe new model is still not significant. This is due to the fact that we only look at additive effects (main effects). But neither caffeine nor anxiety alone/independently predict public speaking performance.\n\n\nFrom the plot, however, it looks like the effect of caffeine is indeed different for the two anxiety groups: Increasing for non-anxious people and decreasing for anxious ones.\nIn other words: We need to have a model that allows to fit different regression slopes to both groups.\n\nexplain additive effects: look at average caffeine effect, then add mean for anxiety groups (but: both not significant here!)\nproblem of independent main effects: also if you bring together two findings from two different papers =&gt; no information about interaction of predictors"
  },
  {
    "objectID": "W10_GLM.html#interaction-example-full-model",
    "href": "W10_GLM.html#interaction-example-full-model",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example: Full model",
    "text": "Interaction Example: Full model\nTo allow for different slopes for each group (i.e. for the effect of caffeine to vary between the anxiety groups), we have to model the interaction as well.\n\n\n\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety + caffeine:anxiety, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.385  -7.103  -0.444   6.171  13.458 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 17.43085    5.43012   3.210 0.005461 ** \ncaffeine                    -0.47416    0.09664  -4.906 0.000158 ***\nanxietynotAnxious          -43.44873    7.79141  -5.576 4.17e-05 ***\ncaffeine:anxietynotAnxious   1.08395    0.12931   8.382 3.01e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.085 on 16 degrees of freedom\nMultiple R-squared:  0.8524,    Adjusted R-squared:  0.8247 \nF-statistic:  30.8 on 3 and 16 DF,  p-value: 7.014e-07\n\n\n\n\n\n\n\n\n\n\n\nThe model is now significant! There is an interaction between caffeine and anxiety. Interestingly, the main effects are also significant now even though they were not in the previous models (because the residual variance has been reduced drastically from 18 to 8 by the highly significant interaction).\nNote: speaking ~ caffeine * anxiety is shorthand for speaking ~ caffeine + anxiety + caffeine:anxiety"
  },
  {
    "objectID": "W10_GLM.html#convert-glm-to-anova",
    "href": "W10_GLM.html#convert-glm-to-anova",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Convert GLM to ANOVA",
    "text": "Convert GLM to ANOVA\nThe interpretation of the coefficients of a GLM when interactions are included is not as straight forward compared to an ANOVA!\n\nIf you want to report the “typical” ANOVA table with main effects and the general interaction:\n\nanova(lmResultInteraction)\n\nAnalysis of Variance Table\n\nResponse: speaking\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncaffeine          1  454.8   454.8  6.9578 0.017911 *  \nanxiety           1  991.5   991.5 15.1678 0.001288 ** \ncaffeine:anxiety  1 4593.4  4593.4 70.2662 3.01e-07 ***\nResiduals        16 1045.9    65.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nNote: The p-values are different between the GLM and the ANOVA outputs because effects including factors are coded slightly differently (dummy vs. effect coding):\nDummy coding uses the first level as a default and compares the remaining levels to it (\\(0\\) vs. \\(1\\)).\nEffect coding takes the overall mean as an abstract comparison (\\(-.5\\) vs. \\(+.5\\)).\nThis difference is resembled in the output tables as anxietynotAnxious (GLM) vs. anxiety (ANOVA).\n\ninterpretation coefficients:\nintercept: intercept of anxious group!\nintercept not anxious: difference intercept anxious vs. notanxious\nslope anxious: only for the anxious group!\nslope not anxious: diff in slopes\nno main effects!!!"
  },
  {
    "objectID": "W10_GLM.html#model-diagnostics",
    "href": "W10_GLM.html#model-diagnostics",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nTo check the assumptions, we can easily run a function for model diagnostics (incl. Q-Q plots) in R. The function, check_model(), is included in the performance package by the easystats team (who make great packages for everything related to statistical modeling!)\n\n# install.packages(\"easystats\")\nlibrary(performance)\n\ncheck_model(lmResultInteraction)\n\n\n\nWe’re not going into detail about all these diagnostics (and hard to see!), but it is always a good idea to run diagnostics/check assumptions for your models!"
  },
  {
    "objectID": "W10_GLM.html#remark-predicting-in-a-statistical-context",
    "href": "W10_GLM.html#remark-predicting-in-a-statistical-context",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Remark: “Predicting” in a Statistical Context",
    "text": "Remark: “Predicting” in a Statistical Context\nWe neither mean “predicting before seeing the data/in the future” nor mean to imply causality!\n\nIt simply refers to fitting a model to the data: We estimate (or predict) values for the DV (\\(\\hat{y}\\)) and the IVs are often referred to as predictors.\n\nRelated to: predicting future values"
  },
  {
    "objectID": "W10_GLM.html#factor-analysis-fa",
    "href": "W10_GLM.html#factor-analysis-fa",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Factor Analysis (FA)",
    "text": "Factor Analysis (FA)\nPCA is useful for reducing the dimensionality of a dataset.\nThe components are per definition uncorrelated –&gt; sometimes this is a limitation.\nPCA also doesn’t account for measurement error –&gt; possibly difficult to interpret loadings.\n\nExploratory Factor Analysis: can also be used for dimensionality reduction.\nIdea: Each observed variable is created through a combination of contributions from a latent variable + measurement error. (latent: can’t be directly observed!)\n\n\nHow do different measures relate to underlying factor (that gives rise to these measures)?"
  },
  {
    "objectID": "docs/W1_intro.html",
    "href": "docs/W1_intro.html",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Who am I?\n. . .\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?\n\n\n\nSurvey (Zoom) + Moodmeter (pick a stamp - top of screen, select annotate…)\nToo many people to have an introduction round!\nI know that you probably don’t know each other yet, there will be some break-out sessions where you can get to know each other a bit (and talk about stats!) ;)\nStats Anxiety: It will be packed, but it will be ok (You can always reach me with questions!)!\n\n\n\n\n\nThese slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\n\n\n\n. . .\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n. . .\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is an option via Zoom\n\n\n. . .\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked in WueCampus):\n\nStatistical Thinking for the 21st Century: https://statsthinking21.github.io/statsthinking21-core-site/index.html\nFor the R part: Fundamentals of Quantitative Analysis: https://psyteachr.github.io/quant-fun-v2/\n\n\n\n\nOnline: Participation, videos, chat…\nOr R Session on Tuesday and video before? Some can’t make it on Wednesdays… (chat or speak out)\nAttendance: If 2x per week sync: max. 3 missed classes, if 1x per week: max. 2 missed classes (unless I know your reasons for missing Wednesdays!) –&gt; if you missed more, I can’t admit you for the exam/report\nThe input and hands-on sessions will be highly based on these two textbooks. You don’t need to read the textbooks, but it will of course help if you either read the chapter before or after the sessions: Repetition is always helpful!\n\n\n\n\n\n\nFrom basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset (exam with pass or fail grading)\n\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy –&gt; so that you can go through the slides afterwards again (but textbook might also be helpful)\n\n\n\n\n. . .\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n. . .\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)\n\nThe first four weeks will be basics, the next 4 will be analyses."
  },
  {
    "objectID": "docs/W1_intro.html#hello",
    "href": "docs/W1_intro.html#hello",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Who am I?\n. . .\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?\n\n\n\nSurvey (Zoom) + Moodmeter (pick a stamp - top of screen, select annotate…)\nToo many people to have an introduction round!\nI know that you probably don’t know each other yet, there will be some break-out sessions where you can get to know each other a bit (and talk about stats!) ;)\nStats Anxiety: It will be packed, but it will be ok (You can always reach me with questions!)!"
  },
  {
    "objectID": "docs/W1_intro.html#using-the-slides",
    "href": "docs/W1_intro.html#using-the-slides",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "These slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\""
  },
  {
    "objectID": "docs/W1_intro.html#organizational-issues",
    "href": "docs/W1_intro.html#organizational-issues",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": ". . .\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n. . .\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is an option via Zoom\n\n\n. . .\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked in WueCampus):\n\nStatistical Thinking for the 21st Century: https://statsthinking21.github.io/statsthinking21-core-site/index.html\nFor the R part: Fundamentals of Quantitative Analysis: https://psyteachr.github.io/quant-fun-v2/\n\n\n\n\nOnline: Participation, videos, chat…\nOr R Session on Tuesday and video before? Some can’t make it on Wednesdays… (chat or speak out)\nAttendance: If 2x per week sync: max. 3 missed classes, if 1x per week: max. 2 missed classes (unless I know your reasons for missing Wednesdays!) –&gt; if you missed more, I can’t admit you for the exam/report\nThe input and hands-on sessions will be highly based on these two textbooks. You don’t need to read the textbooks, but it will of course help if you either read the chapter before or after the sessions: Repetition is always helpful!"
  },
  {
    "objectID": "docs/W1_intro.html#contents",
    "href": "docs/W1_intro.html#contents",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "From basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset (exam with pass or fail grading)\n\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy –&gt; so that you can go through the slides afterwards again (but textbook might also be helpful)"
  },
  {
    "objectID": "docs/W1_intro.html#project",
    "href": "docs/W1_intro.html#project",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": ". . .\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n. . .\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long."
  },
  {
    "objectID": "docs/W1_intro.html#calender",
    "href": "docs/W1_intro.html#calender",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Date\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)\n\nThe first four weeks will be basics, the next 4 will be analyses."
  },
  {
    "objectID": "docs/W1_intro.html#why-is-it-important-that-you-know-statistics",
    "href": "docs/W1_intro.html#why-is-it-important-that-you-know-statistics",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is it important that YOU know statistics?",
    "text": "Why is it important that YOU know statistics?\n\n\nYou’re doing a research master!\n\nResearch = Reading & understanding papers (esp. the analyses)\nDesigning your own experiments, analyze data, interpret results\n\nWe live in an increasingly data-centric world\n\nKnowing how to wrangle and analyze data is a valuable skill\n\nFacts & data literacy matter more than ever!\n\nFake News, “Lying with stats”, Reproducibility Crisis\nBeing able to call bullshit (https://www.callingbullshit.org/)\n\n“I only believe in statistics that I doctored myself” ― Winston S. Churchill\n\nHowever: “It is easy to lie with statistics, but easier to lie without them” ― Frederick Mosteller\n\n\n\n\nbreak-out session, 3 min.\n–&gt; Afterwards: write in chat or speak, what did you come up with?\npossibly show empirical cycle or the like to indicate that stats are necessary at almost every step"
  },
  {
    "objectID": "docs/W1_intro.html#what-is-statistical-thinking",
    "href": "docs/W1_intro.html#what-is-statistical-thinking",
    "title": "01a Introduction to Biostatistics",
    "section": "What is Statistical Thinking?",
    "text": "What is Statistical Thinking?\n\n\n“a systematic way of thinking about how we describe the world and use data [to] make decisions and predictions, all in the context of the inherent uncertainty that exists in the real world.” (Poldrack, Preface of ST21)\n“Statistical thinking is a way of understanding a complex world by describing it in relatively simple terms that nonetheless capture essential aspects of its structure or function, and that also provide us some idea of how uncertain we are about that knowledge.” (Poldrack, Chapter 1)\n\n\n\nbreak down complexity, include uncertainty"
  },
  {
    "objectID": "docs/W1_intro.html#why-is-statistical-thinking-important",
    "href": "docs/W1_intro.html#why-is-statistical-thinking-important",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is Statistical Thinking Important?",
    "text": "Why is Statistical Thinking Important?\n\n\ndata literacy vs. intuition/heuristics/anecdotal evidence\n\nPublic discourse about Covid-19, migration, etc. (e.g., “50% of people in intensive care are vaccinated”)\n\n\n\n. . .\n\n\n\nBase Rate Fallacy\n\n\n\nWrite in chat! (after first bullet point!)\nexample availability heuristic from book (or any other example where intuition is wrong, i.e. vaccinations/covid…)\n--&gt; test in class? Ask for opinion/intuition, show data"
  },
  {
    "objectID": "docs/W1_intro.html#what-can-statistics-do-for-us",
    "href": "docs/W1_intro.html#what-can-statistics-do-for-us",
    "title": "01a Introduction to Biostatistics",
    "section": "What can Statistics Do For Us?",
    "text": "What can Statistics Do For Us?\n\nDescribe patterns by summarizing/breaking down data (“descriptive statistics”)\nDecide whether one thing is better than another, given the uncertainty (“inferential statistics”)\nPredict how other people would “behave” (generalize to new observations)\n\n\ndescribe: not useful to look at every single data point/person, but we need s.th. like tendencies/trends…"
  },
  {
    "objectID": "docs/W1_intro.html#the-big-ideas",
    "href": "docs/W1_intro.html#the-big-ideas",
    "title": "01a Introduction to Biostatistics",
    "section": "The Big Ideas",
    "text": "The Big Ideas\n\n\nLearning from data: Update our beliefs\nAggregation: How to summarize the data to draw meaningful conclusions?\nUncertainty: Probabilistic evidence\nSampling from the population: Which people etc. do we select?\n\n\n\nask for every point what I could mean w/ it?\nLfD: gather new knowledge\nAgg: Can’t look at all ind data points, need to find trends etc. (should not go to far! throwing out data)\nuncert: stats = tools for making decisions under uncert, we can never prove anything but provide evidence, there is no 100% certainty for an outcome (cancer)\nsampling: how do we represent the population? What is the population? how much data do we need? More is better, but payoff decreases…"
  },
  {
    "objectID": "docs/W1_intro.html#causality",
    "href": "docs/W1_intro.html#causality",
    "title": "01a Introduction to Biostatistics",
    "section": "Causality",
    "text": "Causality\nCorrelation does not imply causation… but is a hint!\n. . .\nExample: Smoking = less risk for Parkinson’s disease? (Godwin-Austen et al., 1982; Chen et al., 2010)\n. . .\n--&gt; confounding factors?\n. . .\ne.g., individual dopaminergic activity =&gt; addiction & motor function\n. . .\nRandomized Controlled Trials (RCT) as the solution?\n\ngive example! Eat more fat = living longer? Confounders (richer people, healthier diets, less stress, better health care…)\nRCT: exp control and manipulation, removes confounds if done well\nAt least some more causal evidence!\nQUESTIONS so far?"
  },
  {
    "objectID": "docs/W1_intro.html#what-are-data",
    "href": "docs/W1_intro.html#what-are-data",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data?",
    "text": "What are Data?\n\nWhat do you think are data?\n\n\n\nqualitative vs. quantitative\n\nqualitative?\n\nopen questions, descriptions… can potentially be coded into categories\n\nquantitative?\n\nnumeric, can be averaged etc.\n\n\n\n\n\nChat –&gt; after showing slide! Come up with examples for “Data”\nCollect: Do you have ideas? What are data you encounter in your lives/work etc? What are differences between these data?"
  },
  {
    "objectID": "docs/W1_intro.html#what-are-data-2",
    "href": "docs/W1_intro.html#what-are-data-2",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data? (2)",
    "text": "What are Data? (2)\n\n\nData types\n\ncharacter/string: text (qualitative)\nfactors/categories\ntypes of numbers (quantitative)\n\nbinary: 0 or 1, TRUE or FALSE (logical)\nintegers: whole numbers\nreal numbers: decimals/fractions\n\n\ndiscrete vs. continuous\n\ndiscrete: finite set of particular values (0 or 1, scale from 1 to 10)\ncontinuous: real numbers that fall into particular range (e.g., brain activity, visual analoge scale)\n\nWhat data type is eye color?\n\n\n\ndiscrete vs. continuous: question for examples or quiz\nFurther classify data examples mentioned in chat"
  },
  {
    "objectID": "docs/W1_intro.html#what-is-a-data-set",
    "href": "docs/W1_intro.html#what-is-a-data-set",
    "title": "01a Introduction to Biostatistics",
    "section": "What is a Data Set?",
    "text": "What is a Data Set?\n\na collection of data\nusually organized into rows and columns (like an excel spreadsheet)\n\nrows: participants/animals/cells…\ncolumns: variables!\n\neach variable contains one type of measurement\n\ntable cells = unique observations of variables per participant etc.\n\n\n\n\n\nNHANES dataset\n\n\n\npossibly go through columns and ask for data types?"
  },
  {
    "objectID": "docs/W1_intro.html#what-makes-a-good-measurement",
    "href": "docs/W1_intro.html#what-makes-a-good-measurement",
    "title": "01a Introduction to Biostatistics",
    "section": "What Makes a Good Measurement?",
    "text": "What Makes a Good Measurement?\n\n\n\nWhat is being measured?\n\nconstructs vs. proxies: need to be well-defined! (Difficult)\nmeasurement error\n\nrandom: e.g., variation in reaction times of same participant across trials\nsystematic: e.g., miscalibrated eye-tracking device\n\n\nDo we have a “gold standard” to compare the measurement to?\n\n\n\nBreak-Out session: Brainstorm what makes a good vs. bad measurement!\nGroup work/brainstorm:\n\nWhat are problems?\nWhich kind of errors/when is data NOT good\nhow can we minimize error?"
  },
  {
    "objectID": "docs/W1_intro.html#reliability",
    "href": "docs/W1_intro.html#reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Reliability",
    "text": "Reliability\nCorrelation of a measurement with “itself”\n\n\nInternal reliability (consistency)\nTest-retest reliability (stability)\nInter-rater reliability (agreement)\n\n\n. . .\nCorrelation with other variables can’t be higher than reliability (cf., Wilmer et al., 2012, Table 1)!"
  },
  {
    "objectID": "docs/W1_intro.html#validity",
    "href": "docs/W1_intro.html#validity",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity",
    "text": "Validity\nAre we measuring the construct we’re interested in?\n\n\nFace validity: Does it intuitively make sense? First reality check!\nConstruct validity\n\nconvergent validity: Related to similar measures that should measure the same construct\ndivergent validity: Is it unrelated to other measures?\n\nPredictive validity: Is it predictive of other outcomes? (e.g., intelligence & job success)\n\n\n. . .\n\n\n\nReliability & Validity"
  },
  {
    "objectID": "docs/W1_intro.html#summarizing-data",
    "href": "docs/W1_intro.html#summarizing-data",
    "title": "01a Introduction to Biostatistics",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\n\nThrowing away (some of the) information!\n\nextract the quintessence of the data (important for forming models)\nmake predictions\n\nCounts, frequencies, percentages, averages"
  },
  {
    "objectID": "W11_GLMinR.html",
    "href": "W11_GLMinR.html",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "",
    "text": "code.sourceCode {\n  font-size: 1.4em;\n}\n\ndiv.cell-output-stdout {\n  font-size: 1.4em;\n}\n\n\n\nlibrary(pwr)\nlibrary(rcompanion)\nlibrary(lsr)\nlibrary(car)\n\nLade nötiges Paket: carData\n\nlibrary(broom)\nlibrary(afex)\n\nLade nötiges Paket: lme4\n\n\nLade nötiges Paket: Matrix\n\n\n************\nWelcome to afex. For support visit: http://afex.singmann.science/\n\n\n- Functions for ANOVAs: aov_car(), aov_ez(), and aov_4()\n- Methods for calculating p-values with mixed(): 'S', 'KR', 'LRT', and 'PB'\n- 'afex_aov' and 'mixed' objects can be passed to emmeans() for follow-up tests\n- Get and set global package options with: afex_options()\n- Set sum-to-zero contrasts globally: set_sum_contrasts()\n- For example analyses see: browseVignettes(\"afex\")\n************\n\n\n\nAttache Paket: 'afex'\n\n\nDas folgende Objekt ist maskiert 'package:lme4':\n\n    lmer\n\nlibrary(emmeans)\nlibrary(see)\nlibrary(performance)\nlibrary(report)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ dplyr::recode() masks car::recode()\n✖ purrr::some()   masks car::some()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nstart recording"
  },
  {
    "objectID": "W11_GLMinR.html#setup",
    "href": "W11_GLMinR.html#setup",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Setup",
    "text": "Setup\nWe will use the data by Zhang et al. (2014): Zhang et al. 2014 Study 3.csv\nThe study design was a 2x2 design:\n\ntime (time1, time2) - within-subjects IV\nevent (ordinary vs. extraordinary) - between-subjects IV\nDV: interest"
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling",
    "href": "W11_GLMinR.html#data-wrangling",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nTasks:\n\nRead in the data file\n\nSelect the three columns we need\n\nAdd on a column of subject IDs based on the row_number()\n\nTidy the data/bring it in long format\n\nRecode the values of Condition from numeric to text labels\n\nRecode the values of time to be easier to read/write\n\nChange the data type of Condition and time to be factors!\n\nReplace the “NULLs” to achieve all this step by step…\n\nzhang_data2 &lt;- read_csv(\"Zhang et al. 2014 Study 3.csv\") %&gt;% \n  select(NULL, NULL, NULL) %&gt;% \n  mutate(subject = NULL) %&gt;% \n  NULL(names_to = \"time\", values_to = \"interest\", cols =  c(\"T1_Predicted_Interest_Composite\",\"T2_Actual_Interest_Composite\")) %&gt;%\n  mutate(time = recode(time, NULL = NULL, NULL = NULL), # should be condition!\n         Condition = recode(NULL, \"T1_Predicted_Interest_Composite\" = \"time1_interest\", \"T2_Actual_Interest_Composite\" = \"time2_interest\"),\n         NULL = as.factor(NULL),\n         time = NULL(time))\n\n. . .\n\nzhang_data2 &lt;- read_csv(\"Data/Zhang et al. 2014 Study 3.csv\") %&gt;%\n  select(Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite) %&gt;%\n  mutate(subject = row_number()) %&gt;%\n  pivot_longer(names_to = \"time\",values_to = \"interest\", cols = c(\"T1_Predicted_Interest_Composite\",\"T2_Actual_Interest_Composite\")) %&gt;%\n  mutate(Condition = dplyr::recode(Condition, \"1\" = \"Ordinary\", \"2\" = \"Extraordinary\"))%&gt;%\n  mutate(time = dplyr::recode(time, \"T1_Predicted_Interest_Composite\" = \"time1_interest\", \"T2_Actual_Interest_Composite\" = \"time2_interest\")) %&gt;%\n  mutate(Condition = as.factor(Condition)) %&gt;% \n  mutate (time = as.factor(time))\n\nRows: 130 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (35): Condition, T1_Extraordinariness, T2_Extraordinariness, T1_Predicte...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nDo it together"
  },
  {
    "objectID": "W11_GLMinR.html#descriptive-statistics",
    "href": "W11_GLMinR.html#descriptive-statistics",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nCalculate descriptive statistics (mean and SD) for interest for each Condition for each time (hint: you will need to group_by() two variables) and store it in an object named sum_dat_factorial. These are known as the cells means.\n. . .\n\nsum_dat_factorial &lt;- zhang_data2 %&gt;% \n  group_by(Condition, time) %&gt;% \n  summarise(mean_interest = mean(interest, na.rm=TRUE),\n            sd_interest = sd(interest, na.rm=TRUE))\n\n`summarise()` has grouped output by 'Condition'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "W11_GLMinR.html#visualize-the-data",
    "href": "W11_GLMinR.html#visualize-the-data",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Visualize the data",
    "text": "Visualize the data\n\nViolin-Boxplot\nWrite the code that produces violin-boxplots for the scores in each group. time should be on the x-axis and Condition should be in different colors. The CV, interest, is on the y-axis. Such a plot is called “grouped” (e.g. grouped boxplot).\nHint 1: you will need to add in the second IV in the first call to ggplot as a fill argument (aes(x,y,fill)).  \nHint 2: you will need to add position = position_dodge(.9) to geom_boxplot to get the plots to align.  \n. . .\n\nggplot(zhang_data2, \n       aes(x = time , y = interest, fill = Condition))+\n  geom_violin(trim = FALSE, \n              alpha = .4) +\n  geom_boxplot(position = position_dodge(.9), \n               width = .2, \n               alpha = .6) +\n  scale_x_discrete(labels = c(\"Time 1\", \"Time 2\")) +\n  scale_fill_viridis_d(option = \"E\") +\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.9)) +\n  theme_minimal()"
  },
  {
    "objectID": "W11_GLMinR.html#interaction-line-plot",
    "href": "W11_GLMinR.html#interaction-line-plot",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Interaction (line) plot",
    "text": "Interaction (line) plot\nIn this analysis, we also want to look at the interaction between time and Condition. To see whether an interaction might be present (e.g. the lines are not parallel!), it is helpful to make a line plot, again with time on the x-axis, Condition as separate lines, and (mean) interest on the y-axis. We want to draw the summarized data, that’s why we use sum_dat_factorial.\nHere’s the code:\n\nggplot(sum_dat_factorial, aes(x = time, y = mean_interest, group = Condition, shape = Condition)) +\n  geom_point(size = 3) +\n  geom_line(aes(linetype = Condition))+\n  scale_x_discrete(labels = c(\"Time 1\", \"Time 2\"))+\n  theme_classic()\n\n\n\n\nThere seems to be an interaction! The lines are not parallel, which means in this case that the increase in interest between time 1 and time 2 is greater in the “ordinary” condition!\nBut is this effect significant?"
  },
  {
    "objectID": "W11_GLMinR.html#mixed-anova",
    "href": "W11_GLMinR.html#mixed-anova",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Mixed ANOVA",
    "text": "Mixed ANOVA\nWe now want to run a mixed ANOVA. Mixed because it is a mix of within- and between-subjects independent variables.\n\nComplete the below code to run the factorial ANOVA. Remember that you will need to specify both IVs and that one of them is between-subjects and one of them is within-subjects. Look up the help documentation for aov_ez to find out how to do this.\nSave the ANOVA model to an object called mod_factorial\nPull out the anova table, you can either do this with mod_factorial$anova_table or anova(mod_factorial) both have the same result. Save this to an object named factorial_output. You can use tidy() to save the output as a data frame, which might be useful.\n\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n               data = NULL, \n               between = \"NULL\", \n               within = \"NULL\",\n               dv = \"NULL\", \n               type = 3,\n               es = \"NULL\") \n\nfactorial_output &lt;- NULL %&gt;% tidy()\n\n. . .\n\nmod_factorial &lt;- aov_ez(id = \"subject\",\n               data = zhang_data2, \n               between = \"Condition\", \n               within = \"time\",\n               dv = \"interest\", \n               type = 3,\n               es = \"pes\") \n\nContrasts set to contr.sum for the following variables: Condition\n\nfactorial_output &lt;- anova(mod_factorial) %&gt;% tidy()\n\nWarning in tidy.anova(.): The following column names in ANOVA output were not\nrecognized or transformed: num.Df, den.Df, MSE, ges\n\n# OR\n\nfactorial_output &lt;- mod_factorial$anova_table %&gt;% tidy()\n\nWarning in tidy.anova(.): The following column names in ANOVA output were not\nrecognized or transformed: num.Df, den.Df, MSE, ges\n\nfactorial_output\n\n# A tibble: 3 × 7\n  term           num.Df den.Df   MSE statistic     ges    p.value\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 Condition           1    128 2.05      0.463 0.00278 0.498     \n2 time                1    128 0.607    25.9   0.0441  0.00000126\n3 Condition:time      1    128 0.607     4.44  0.00786 0.0370    \n\n\n. . .\nConclusion:\nThe main effect of time and the interaction between time and Condition are significant. Judged by visual inspection of the plot, interest inreases over time points, especially for the “ordinary” group…"
  },
  {
    "objectID": "W11_GLMinR.html#assumption-checking",
    "href": "W11_GLMinR.html#assumption-checking",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Assumption checking",
    "text": "Assumption checking\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is continuous (interval or ratio data )\nThe observations should be independent\nThe residuals should be normally distributed\nThere should be homogeneity of variance between the groups\n\nTo test assumption 3, extract the residuals from the model (mod_factorial$residuals), create a qq-plot and conduct a Shapiro-Wilk test.\nFor the final assumption, we can again use test_levene() to test homogeneity of variance.\n. . .\n\n# normality testing\nqqPlot(mod_factorial$lm$residuals)\n\n\n\n\n[1] 203  73\n\nshapiro.test(mod_factorial$lm$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod_factorial$lm$residuals\nW = 0.98325, p-value = 0.003785\n\n# levene's test\ntest_levene(mod_factorial)\n\nWarning: Functionality has moved to the 'performance' package.\nCalling 'performance::check_homogeneity()'.\n\n\nOK: There is not clear evidence for different variances across groups (Levene's Test, p = 0.893)."
  },
  {
    "objectID": "W11_GLMinR.html#write-up",
    "href": "W11_GLMinR.html#write-up",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Write up",
    "text": "Write up\nWhat do we need to report?\n. . .\n\nSummary statistics (means, SDs) per cell\nF(df1, df2) = F-value, p = p-value, effect size per effect\nPossibly pairwise contrasts\nInterpretation"
  },
  {
    "objectID": "W11_GLMinR.html#setup-1",
    "href": "W11_GLMinR.html#setup-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Setup",
    "text": "Setup\nWe will use the data from this paper: Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis. Psychological Science, 28, 204–215\nIn the paper, the authors investigated whether there is a “just right” amount of screen time that is associated with higher well-being.\nIn this huge dataset (N=120000), we have the following variables that we will use for analysis:\n\na continuous DV, well-being (Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70, so it’s not really continuous but… oh well…),\na continuous predictor/IV: screen time,\na categorical predictor/IV: gender."
  },
  {
    "objectID": "W11_GLMinR.html#tasks",
    "href": "W11_GLMinR.html#tasks",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Tasks:",
    "text": "Tasks:\n\nDownload wellbeing.csv, participant_info.csv and screen_time.csv and save them in your Chapter folder. Make sure that you do not change the file names at all.\nLoad the CSV datasets into variables called pinfo, wellbeing and screen using read_csv().\nTake a look at the data and make sure you understand what you see. The wellbeing tibble has information from the WEMWBS questionnaire; screen has information about screen time use on weekends (variables ending with we) and weekdays (variables ending with wk) for four types of activities: using a computer (variables starting with Comph; Q10 on the survey), playing video games (variables starting with Comp; Q9 on the survey), using a smartphone (variables starting with Smart; Q11 on the survey) and watching TV (variables starting with Watch; Q8 on the survey).\n\n\n# echo: true\npinfo &lt;- read_csv(\"Data/participant_info.csv\")\n\nRows: 120115 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Serial, male, minority, deprived\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nwellbeing &lt;- read.csv(\"Data/wellbeing.csv\")\nscreen &lt;- read.csv(\"Data/screen_time.csv\")\n\n# View(screen)"
  },
  {
    "objectID": "W11_GLMinR.html#preprocessing",
    "href": "W11_GLMinR.html#preprocessing",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Preprocessing",
    "text": "Preprocessing\nCalculate the WEMWBS scores by taking the sum of all the items:\n\nWrite the code to create a new table called wemwbs, with two variables: Serial (the participant ID), and tot_wellbeing, the total WEMWBS score.\nyou might have to “pivot” the data from wide to long format.\nyou probably have to use a group_by() to calculate the well-being (WEMWBS) score per person.\nverify for yourself that the scores all fall in the 14-70 range. Przybylski and Weinstein reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"score\", -Serial) %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score))\n\n# you could also mutate(tot_wellbeing = WBOptimf + ...) %&gt;% select(Serial, tot_wellbeing)\n\n# sanity check values\n\nwemwbs %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n# A tibble: 1 × 4\n   mean    sd   min   max\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1  47.5  9.55    14    70"
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization",
    "href": "W11_GLMinR.html#data-visualization",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data visualization",
    "text": "Data visualization\nWe now want to visualize the relationship between screen time (for the four different technologies) and well-being.\nRun the code below and write comments in the code that explain what each line of code is doing:\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"hours\", -Serial) %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = dplyr::recode(variable,\n               \"Watch\" = \"Watching TV\",\n               \"Comp\" = \"Playing Video Games\",\n               \"Comph\" = \"Using Computers\",\n               \"Smart\" = \"Using Smartphone\"),\n     day = dplyr::recode(day,\n              \"wk\" = \"Weekday\",\n              \"we\" = \"Weekend\"))\n\ndat_means &lt;- inner_join(wemwbs, screen2, \"Serial\") %&gt;%\n  group_by(variable, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\n`summarise()` has grouped output by 'variable', 'day'. You can override using\nthe `.groups` argument.\n\nggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~variable, nrow = 2)\n\n\n\n\nAlso describe what you see in the figures/plots that you get when running the code.\n. . .\nThere seems to be a peak around 1h/day for max. wellbeing for all sorts of screen time.\n\nWalk through code together!"
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling-1",
    "href": "W11_GLMinR.html#data-wrangling-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data wrangling",
    "text": "Data wrangling\nWe need to do a few things to get a dataset that we can use for analysis:\n\nCreate a new table, smarttot, that has the mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays.\n\n\nYou will need to filter the dataset to only include smartphone use and not other technologies.\n\nYou will also need to group the results by the participant ID (i.e., serial).\n\nThe final data-set should have two variables: Serial (the participant) and tothours. In this step, you will need to summarise the data.\n\nYou will need to use the dataset screen2 to do this.\n\n. . .\n\nsmarttot &lt;- screen2 %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tothours = mean(hours))\n\n. . .\n\nNext, create a new tibble called smart_wb that only includes (filters) participants from smarttot who used a smartphone for more than one hour per day each week, and then combine (join) this table with the information in wemwbs and pinfo.\n\n. . .\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\")"
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling-2",
    "href": "W11_GLMinR.html#data-wrangling-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling 2",
    "text": "Data Wrangling 2\n\nWhen you do regression analysis, it is helpful to mean center your continuous (independent) variables. You mean center a predictor X simply by subtracting the mean (X_centered = X - mean(X)). This has two useful consequences:\n\n\nthe model intercept reflects the prediction for Y at the mean value of the predictor variable, rather than at the zero value of the unscaled variable;\nif there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects). (Don’t worry if you don’t understand what this means yet!)\n\nIf you mean-center categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0). This is also handy and is called effects coding. (Not true if unequal groups! Use if_else())\nTasks:\n\nUse mutate to add two new variables to smart_wb: tothours_c, calculated as a mean-centered version of the tothours predictor; and male_c, recoded as -.5 for female and .5 for male.\nTo create male_c you will need to use if_else(male == 1, .5, -.5) You can read this code as “if the variable male equals 1, recode it as .5, if not, recode it as -.5”.\nFinally, recode male and male_c as factors, so that R knows not to treat them as a real numbers.\n\n. . .\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(thours_c = tothours - mean(tothours),\n         male_c = ifelse(male == 1, .5, -.5),\n         male_c = as.factor(male_c),\n         male = as.factor(male))"
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization-2",
    "href": "W11_GLMinR.html#data-visualization-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data visualization 2",
    "text": "Data visualization 2\nTry to recreate the following plot:\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(tothours, male) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(NULL, aes(NULL, NULL, color = NULL)) +\n  geom_NULL() +  # which geom to use for the points?\n  geom_NULL(method = \"lm\") + # which geom for the lines?\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\")\n\n. . .\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(tothours, male) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(smart_wb_gen, aes(tothours, mean_wellbeing, color = male)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\")"
  },
  {
    "objectID": "W11_GLMinR.html#analysis",
    "href": "W11_GLMinR.html#analysis",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Analysis",
    "text": "Analysis\nTry to specify the following regression model in R:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\\(Yi\\) is the well-being score for participant i;\n\\(X1i\\) is the mean-centered smartphone use variable for participant i;\n\\(X2i\\) is gender (-.5 = female, .5 = male);\n\\(X3i\\) is the interaction between smartphone use and gender (=\\(X1i×X2i\\))\n\n\nmod &lt;- lm(NULL ~ NULL, data = smart_wb)\n\nmod_summary &lt;- summary(mod)\n\n. . .\n\nmod &lt;- lm(tot_wellbeing ~ thours_c + male_c + thours_c:male_c, data = smart_wb)\n# mod &lt;- lm(tot_wellbeing ~ hours_c * male_c, data = smart_wb)\n\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\nCall:\nlm(formula = tot_wellbeing ~ thours_c + male_c + thours_c:male_c, \n    data = smart_wb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        44.86740    0.04478 1001.87   &lt;2e-16 ***\nthours_c           -0.77121    0.02340  -32.96   &lt;2e-16 ***\nmale_c0.5           5.13968    0.07113   72.25   &lt;2e-16 ***\nthours_c:male_c0.5  0.45205    0.03693   12.24   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,   Adjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: &lt; 2.2e-16\n\n\nBy which variable in the output is the interaction between smartphone use and gender shown? Is it significant?\nHow would you interpret the results?"
  },
  {
    "objectID": "W11_GLMinR.html#assumption-checking-1",
    "href": "W11_GLMinR.html#assumption-checking-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Assumption checking",
    "text": "Assumption checking\nHere are the assumptions for multiple regression:\n\nThe outcome/DV is continuous (interval/ratio level data)\nThe predictor variable is interval/ratio or categorical\nAll values of the outcome variable are independent (i.e., each score should come from a different participant)\nThe predictors have non-zero variance\nThe relationship between outcome and predictor is linear\nThe residuals should be normally distributed\nThere should be homoscedasticity (homogeneity of variance, but for the residuals)\nMulticollinearity: predictor variables should not be too highly correlated\n\nFrom the work we’ve done so far we know that assumptions 1 - 4 are met and we can use the functions from the performance package again to check the rest (this will take a while because the dataset is so huge):\n\nassumptions &lt;- check_model(mod, check = c(\"vif\", \"qq\", \"normality\", \"linearity\", \"homogeneity\"))\n\nassumptions\n\n\n\n# qqPlot(mod$residuals)\n\n(Note: the line in the homogeneity plot is missing due to the large amount of data. Check out the textbook for a solution as well as for further information on what these measures mean.)"
  },
  {
    "objectID": "W11_GLMinR.html#further-analysis-of-interaction",
    "href": "W11_GLMinR.html#further-analysis-of-interaction",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Further Analysis of Interaction",
    "text": "Further Analysis of Interaction\nWe can use emmeans package to further investigate the direction of the interaction. This is especially handy if we have more than two factor levels and can’t read out the direction of the effect from the model summary.\nSpecifically, we’re using the emtrends() function, because we have a continuous variable and want to know the (simple) slope/trend of this variable within each of the factor levels of the categorical variable:\n\nsimple_slopes_interaction &lt;- emtrends(mod, ~male_c|thours_c, var=\"thours_c\")\nsimple_slopes_interaction\n\nthours_c = -3.41e-16:\n male_c thours_c.trend     SE    df lower.CL upper.CL\n -0.5           -0.771 0.0234 71029   -0.817   -0.725\n 0.5            -0.319 0.0286 71029   -0.375   -0.263\n\nConfidence level used: 0.95 \n\ntest(simple_slopes_interaction)  # with the test() function, you can get the p-value to test whether the slope within each group is sign. different from 0!\n\nthours_c = -3.41e-16:\n male_c thours_c.trend     SE    df t.ratio p.value\n -0.5           -0.771 0.0234 71029 -32.956  &lt;.0001\n 0.5            -0.319 0.0286 71029 -11.170  &lt;.0001"
  },
  {
    "objectID": "W11_GLMinR.html#power-effect-size-and-write-up",
    "href": "W11_GLMinR.html#power-effect-size-and-write-up",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Power, effect size and write up",
    "text": "Power, effect size and write up\nUse this code to calculate power and effect size:\n\npwr.f2.test(u = 3, v = 71029, f2 = NULL, sig.level = .05, power = .99)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\n\nIs the study adequately powered?\nFor the write up, you can use this text block, including inline code (wrapped by r ) to directly use the output of R in your text. If you then knit your document, it will insert the values:\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(3, 7.1029^{4}) = 2450.89, p &lt; .001, Adjusted R2 = 0.09, f2 = .63), accounting for 9% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = -0.77, p &lt; .001, as was gender (β = 5.14, p &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = 0.45, p &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys.\n\nIn this example, you can also see what you need to report.\nYou can also use the report() function from the report package to get a suggestion for what to report from your results (it would still need some editing!):\n\nreport(mod)\n\nWe fitted a linear model (estimated using OLS) to predict tot_wellbeing with\nthours_c and male_c (formula: tot_wellbeing ~ thours_c + male_c +\nthours_c:male_c). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.09, F(3, 71029) = 2450.89, p &lt; .001, adj. R2 =\n0.09). The model's intercept, corresponding to thours_c = 0 and male_c = -0.5,\nis at 44.87 (95% CI [44.78, 44.96], t(71029) = 1001.87, p &lt; .001). Within this\nmodel:\n\n  - The effect of thours c is statistically significant and negative (beta =\n-0.77, 95% CI [-0.82, -0.73], t(71029) = -32.96, p &lt; .001; Std. beta = -0.15,\n95% CI [-0.16, -0.15])\n  - The effect of male c [0.5] is statistically significant and positive (beta =\n5.14, 95% CI [5.00, 5.28], t(71029) = 72.25, p &lt; .001; Std. beta = 0.54, 95% CI\n[0.52, 0.55])\n  - The effect of thours c × male c [0.5] is statistically significant and\npositive (beta = 0.45, 95% CI [0.38, 0.52], t(71029) = 12.24, p &lt; .001; Std.\nbeta = 0.09, 95% CI [0.08, 0.11])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "W12_LMM.html",
    "href": "W12_LMM.html",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "code.sourceCode {\n  font-size: 1.4em;\n}\n\n\nThis week will be based on parts of a different textbook: Learning Statistical Models Through Simulation in R.\n. . .\nWe will cover Linear Mixed-Effects Models, which are a generalization of linear models, but they allow us to include random effects, e.g. for subjects. This is especially helpful if we have within-subject variables. LMMs are a lot more flexible than (repeated-measures) ANOVAs.\n\nlibrary(performance)\nlibrary(effectsize)\nlibrary(emmeans)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nWe will use a package called lme4 for the statistical models. The package includes a dataset called sleepstudy, which we will be using. You don’t have to load the data separately, just load the package and you have access to the data:\n\nlibrary(lme4)\n\nLade nötiges Paket: Matrix\n\n\n\nAttache Paket: 'Matrix'\n\n\nDie folgenden Objekte sind maskiert von 'package:tidyr':\n\n    expand, pack, unpack\n\nhead(sleepstudy)\n\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n5 356.8519    4     308\n6 414.6901    5     308\n\n# for information about the dataset, check out:\n# ?sleepstudy\n\nDescription:\n\n     The average reaction time per day (in milliseconds) for subjects\n     in a sleep deprivation study.\n\n     Days 0-1 were adaptation and training (T1/T2), day 2 was baseline\n     (B); sleep deprivation started after day 2.\n\nFormat:\n\n     A data frame with 180 observations on the following 3 variables.\n\n     ‘Reaction’ Average reaction time (ms)\n\n     ‘Days’ Number of days of sleep deprivation\n\n     ‘Subject’ Subject number on which the observation was made.\n\n\n\nMultilevel data are nested data, which means that the are clustered:\n\n\nFor example, repeated measures of the same subjects will result in data that are more strongly correlated within subjects than between.\nBut LMMs can also account for other kinds of nesting/clustering, such as patients who share therapists or mice from the same cage/experimenter.\n\n\n. . .\nData is usually multilevel for one of the three reasons below (multiple reasons could simultaneously apply):\n\nyou have a within-subject factor, and/or\nyou have pseudoreplications (several trials/measurements), and/or\nyou have multiple stimulus items.\n\n. . .\n\n\n\n\n\nLevels of a Multilevel Model\n\n\n\n\n\n\n3-level LMM\n\n\n\n\n. . .\nThese kind of data are extremely common in neuroscientific research!\n. . .\nUnfortunately, LMMs are hardly every covered in statistics classes. Instead, these data are often analyzed using t-tests or ANOVAs, but sometimes these models are not sufficient (e.g. because they only allow for categorical predictors, but time in our example data is continuous…).\n. . .\nMoreover, LMMs have less of a problem with missing data.\n\nWe can often use t-tests or ANOVAs, but we might have to calculate the means per condition or the like before we run the analysis. This means throwing away a lot of information!\n\n\n\n\nIn the dataset, we have measurements of 18 participants across 10 days of sleep deprivation. Each day, the participants performed a “psychomotor vigilance test” where they had to monitor a display and press a button as quickly as possible as soon as a stimulus appeared.\nThe dependent measure (DV) is response times (RT).\nLet’s take a look at the data, with a separate plot per participant:\n\nsleep &lt;- sleepstudy\n\nggplot(sleep, aes(x = Days, y = Reaction)) +\n  geom_point() +\n  scale_x_continuous(breaks = 0:9) +\n  facet_wrap(~Subject)\n\n\n\n\nIt looks like RT is increasing with each additional day of sleep deprivation, starting from day 2 and increasing until day 10.\n\n\n\nWe have some more information about the model that is helpful:\n\nThe first two days were adaptation and training, the third day was a baseline measurement (8h time in bed)\nOn the 4th day (until the 10th, so for 7 days), the sleep deprivation began:\n\nThere were four groups: 9h, 7h, 5h, 3h time in bed\n\n\n. . .\nWe thus have to remove the first two days, as they might bias our results.\nTask:\n\nRemove (filter) observations where Days is 0 or 1.\nMake a new variable, days_deprived, where day 2 is recoded as 0, day 3 as 1 etc.\nStore the data in a dataframe called sleep2.\n\n. . .\n\nsleep2 &lt;- sleepstudy %&gt;%\n  filter(Days &gt;= 2) %&gt;%\n  mutate(days_deprived = Days - 2)\n\nhead(sleep2)\n\n  Reaction Days Subject days_deprived\n1 250.8006    2     308             0\n2 321.4398    3     308             1\n3 356.8519    4     308             2\n4 414.6901    5     308             3\n5 382.2038    6     308             4\n6 290.1486    7     308             5\n\n\n\n\n\nHow might we model the relationship between days_deprived and Reaction?\n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n\n\n\n\n. . .\nIt looks like we could fit an (increasing) line to each participant’s data.\nRemember the general formula for fitting lines:\n\\(Y = \\beta_0 + \\beta_1 X\\)\nwhere \\(\\beta_0\\) is the y-intercept and \\(\\beta_1\\) is the slope, which we both estimate from the data.\n. . .\nIf we fit such a line for every participant, the lines will differ in their intercept (mean RT at baseline, people differ in RTs!) and slope (the change in RT with each additional day of sleep deprivation).\nShould we fit the same line for every participant? Or individual lines? Or something in between?\nThese three approaches are also called complete pooling, no pooling, and partial pooling.\n\n\n\nWith complete pooling, we would estimate the same intercept and slope for every participant (“one size fits all”). This approach ignores that certain data points belong to certain individuals and just fits a line across all data points.\nWe could fit such a model simply with lm(), which means we ignore the repeated measures within person and pretend that all observations are independent:\n\ncp_model &lt;- lm(Reaction ~ days_deprived, sleep2)\n\nsummary(cp_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived, data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-112.284  -26.732    2.143   27.734  140.453 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    267.967      7.737  34.633  &lt; 2e-16 ***\ndays_deprived   11.435      1.850   6.183 6.32e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 50.85 on 142 degrees of freedom\nMultiple R-squared:  0.2121,    Adjusted R-squared:  0.2066 \nF-statistic: 38.23 on 1 and 142 DF,  p-value: 6.316e-09\n\n\n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_abline(intercept = coef(cp_model)[1],\n              slope = coef(cp_model)[2],\n              color = 'blue') +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n\n\n\n\n\nFits the data badly!\nthe predicted mean response time on Day 0 is about 268 milliseconds, with an increase of about 11 milliseconds per day of deprivation, on average. We can’t trust the standard errors for our regression coefficients, however, because we are assuming that all of the observations are independent (technically, that the residuals are). However, we can be pretty sure this is a bad assumption.\n\n\n\n\nAnother approach would be to fit separate lines for each participant.\nThis approach implies that the estimates for one participant are completely uninformed by the estimates for the other participants - we could fit 18 separate models.\nWe could also include Subject as a predictor, or a so-called fixed effect.\nFor this approach, we have to make sure Subject is a factor (because the subject ID is meaningless, 310 is not 1 better than 309 etc.).\n\nstr(sleep2)\n\n'data.frame':   144 obs. of  4 variables:\n $ Reaction     : num  251 321 357 415 382 ...\n $ Days         : num  2 3 4 5 6 7 8 9 2 3 ...\n $ Subject      : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 2 2 ...\n $ days_deprived: num  0 1 2 3 4 5 6 7 0 1 ...\n\n# fit the model\n\nnp_model &lt;- lm(Reaction ~ days_deprived + Subject + days_deprived:Subject, data = sleep2)\n\nsummary(np_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived + Subject + days_deprived:Subject, \n    data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-106.521   -8.541    1.143    8.889  128.545 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              288.2175    16.4772  17.492  &lt; 2e-16 ***\ndays_deprived             21.6905     3.9388   5.507 2.49e-07 ***\nSubject309               -87.9262    23.3023  -3.773 0.000264 ***\nSubject310               -62.2856    23.3023  -2.673 0.008685 ** \nSubject330               -14.9533    23.3023  -0.642 0.522422    \nSubject331                 9.9658    23.3023   0.428 0.669740    \nSubject332                27.8157    23.3023   1.194 0.235215    \nSubject333                -2.7581    23.3023  -0.118 0.906000    \nSubject334               -50.2051    23.3023  -2.155 0.033422 *  \nSubject335               -25.3429    23.3023  -1.088 0.279207    \nSubject337                24.6143    23.3023   1.056 0.293187    \nSubject349               -59.2183    23.3023  -2.541 0.012464 *  \nSubject350               -40.2023    23.3023  -1.725 0.087343 .  \nSubject351               -24.2467    23.3023  -1.041 0.300419    \nSubject352                43.0655    23.3023   1.848 0.067321 .  \nSubject369               -21.5040    23.3023  -0.923 0.358154    \nSubject370               -53.3072    23.3023  -2.288 0.024107 *  \nSubject371               -30.4896    23.3023  -1.308 0.193504    \nSubject372                 2.4772    23.3023   0.106 0.915535    \ndays_deprived:Subject309 -17.3334     5.5703  -3.112 0.002380 ** \ndays_deprived:Subject310 -17.7915     5.5703  -3.194 0.001839 ** \ndays_deprived:Subject330 -13.6849     5.5703  -2.457 0.015613 *  \ndays_deprived:Subject331 -16.8231     5.5703  -3.020 0.003154 ** \ndays_deprived:Subject332 -19.2947     5.5703  -3.464 0.000765 ***\ndays_deprived:Subject333 -10.8151     5.5703  -1.942 0.054796 .  \ndays_deprived:Subject334  -3.5745     5.5703  -0.642 0.522423    \ndays_deprived:Subject335 -25.8995     5.5703  -4.650 9.47e-06 ***\ndays_deprived:Subject337   0.7518     5.5703   0.135 0.892895    \ndays_deprived:Subject349  -5.2644     5.5703  -0.945 0.346731    \ndays_deprived:Subject350   1.6007     5.5703   0.287 0.774382    \ndays_deprived:Subject351 -13.1681     5.5703  -2.364 0.019867 *  \ndays_deprived:Subject352 -14.4019     5.5703  -2.585 0.011057 *  \ndays_deprived:Subject369  -7.8948     5.5703  -1.417 0.159273    \ndays_deprived:Subject370  -1.0495     5.5703  -0.188 0.850912    \ndays_deprived:Subject371  -9.3443     5.5703  -1.678 0.096334 .  \ndays_deprived:Subject372 -10.6041     5.5703  -1.904 0.059613 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.53 on 108 degrees of freedom\nMultiple R-squared:  0.849, Adjusted R-squared:  0.8001 \nF-statistic: 17.35 on 35 and 108 DF,  p-value: &lt; 2.2e-16\n\n\n\nalso uses lm()\nintercept and slope = 308, other values are deviations from 308\nThis model does not give us an overall intercept and slope! (Can average of course…) -&gt; suboptimal if we want to generalize to new participants!\n\n\nall_intercepts &lt;- c(coef(np_model)[\"(Intercept)\"],\n                    coef(np_model)[3:19] + coef(np_model)[\"(Intercept)\"])\n\nall_slopes  &lt;- c(coef(np_model)[\"days_deprived\"],\n                 coef(np_model)[20:36] + coef(np_model)[\"days_deprived\"])\n\nids &lt;- sleep2 %&gt;% pull(Subject) %&gt;% levels() %&gt;% factor()\n\n# make a tibble with the data extracted above\nnp_coef &lt;- tibble(Subject = ids,\n                  intercept = all_intercepts,\n                  slope = all_slopes)\n\nnp_coef\n\n# A tibble: 18 × 3\n   Subject intercept slope\n   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 308          288. 21.7 \n 2 309          200.  4.36\n 3 310          226.  3.90\n 4 330          273.  8.01\n 5 331          298.  4.87\n 6 332          316.  2.40\n 7 333          285. 10.9 \n 8 334          238. 18.1 \n 9 335          263. -4.21\n10 337          313. 22.4 \n11 349          229. 16.4 \n12 350          248. 23.3 \n13 351          264.  8.52\n14 352          331.  7.29\n15 369          267. 13.8 \n16 370          235. 20.6 \n17 371          258. 12.3 \n18 372          291. 11.1 \n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_abline(data = np_coef,\n              mapping = aes(intercept = intercept,\n                            slope = slope),\n              color = 'blue') +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n\n\n\n\n\n\n\nNeither the complete or no-pooling approach is satisfactory.\nIt would be desirable to improve our estimates for individual participants by taking advantage of what we know about the other participants.\n. . .\nThis is called partial pooling: We treat a factor (e.g. subject) as random instead of as fixed.\nA random factor is a factor whose levels are considered to represent a proper subset of all the levels in the population (remember sampling!).\n. . .\nIn partial pooling used in LMMs, estimates at each factor level (i.e. subject) become informed by the information at other levels.\nThe model estimates values for the population, and pulls the estimates for individual subjects toward those values, a statistical phenomenon known as shrinkage.\n. . .\nWe thus estimate a model like this:\n\\(Y_{sd} = \\gamma_{0} + S_{0s} + \\left(\\gamma_{1} + S_{1s}\\right) X_{sd} + e_{sd}\\)\nwhere \\(\\gamma_{0}\\) is the “overall”/population intercept and \\(\\gamma_{1}\\) is the population slope. These are the fixed effects which are usually of interest and they are estimated from the data.\n\\(S_{0s}\\) are the random intercepts per participant and \\(S_{1s}\\) the random slopes for \\(X_{sd}\\) per participant. These values vary over subjects and are the offsets from the fixed effects (i.e. how much do individuals differ from the overall intercept/slope? Some subjects will have slower RTs, for some the effect of sleep deprivation will be stronger…).\n(See textbook for further mathematical formula descriptions and details!)\n\nWill help us distinguish signal from error for each participant\nimprove generalization to the population\nespecially important if we have missing data\n---\nRF: result of sampling, want to generalize beyond those levels\n---\nFE: assume that they reflect true pop para, don’t vary from sample to sample\n\n\n\n\n\n\n\nDifferent Pooling Models\n\n\n\n\n\nShrinkage\n\n\n\nthe further away (the more “unnormal), the more changed/drawn towards overall estimates/penalized.\nThe fewer observations in a cluster, the more information borrowed from others, greater pull (373 and 374)\nAvoids overfitting by taming extreme estimates!\n\n\n\n\nTo fit a LMM, we can use the function lmer() from the lme4 package (you could also use functions from the afex package, which might be more user friendly).\nThe notation is very similar to that of fitting lm() models, we only need to add the random effects:\n\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\n\n. . .\nHere we can see that we only have one predictor/IV/fixed effect: days_deprived.\nRandom effects are denoted in the parentheses (). On the right side of the |, you write down what uniquely identifies the clustering variable, e.g. Subjects. On the left side of the |, you put the effects that you want to vary over the levels of the clustering variable. The right side thus denotes the random intercept, the left side the random slope.\n. . .\nThere are a number of ways to specify random effects. The most common you will see are:\n\n\n\n\n\n\n\nModel\nSyntax\n\n\n\n\nRandom intercepts only\nReaction ~ days_deprived + (1 | Subject)\n\n\nRandom intercepts and slopes\nReaction ~ days_deprived + (1 + days_deprived | Subject)\n(or the one above, which is identical)\n\n\n\nRandom-intercepts-only models are appropriate if you have within-subjects factors without pseudo-replications (i.e. one measurement per subject/level). If you have more than one observation per subject per cell, you need random slopes.\n\nalways good to include random slopes, but sometimes the model does not converge –&gt; only random intercepts\nrmANOVA ~ random intercept model\nYou can add other random effects!\n\n\n\n\nLet’s look at the model output:\n\nsummary(pp_mod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error t value\n(Intercept)    267.967      8.266  32.418\ndays_deprived   11.435      1.845   6.197\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062\n\n\nThe section called Fixed effects is similar to what you have seen so far for lm() models. This is also the section that will likely be of main interest to you.\nYou can see that the estimated mean reaction time for participants at Day 0 was about 268 milliseconds, with each day of sleep deprivation adding an additional 11 milliseconds to the response time, on average.\n. . .\nYou might also notice that you don’t see p-values in the output. There is a huge discussion on how to best estimate the degrees of freedom for these models… If you don’t want to go into the details, one option is to use the lmerTest package to obtain p-values:\n\nlibrary(lmerTest)\n\n\nAttache Paket: 'lmerTest'\n\n\nDas folgende Objekt ist maskiert 'package:lme4':\n\n    lmer\n\n\nDas folgende Objekt ist maskiert 'package:stats':\n\n    step\n\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\nsummary(pp_mod)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)    267.967      8.266  17.000  32.418  &lt; 2e-16 ***\ndays_deprived   11.435      1.845  16.999   6.197 9.75e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062\n\n\n\n\n\nThe random effects part of the output provides you with the variance-covariance matrix of the random effects and the residual variance.\nThe residual variance is the variance of the residuals, i.e. the error variance which is not explained by the model.\nThe variance-covariance matrix above gives us the variance of each random effect component as well as the correlation between random intercept and slope. Often, you would not need to interpret these effects in too much detail (unless you’re interested in floor/ceiling effect visible in a big correlation), but you should make sure the variance is not 0 or 1.\n\n\n\nOften, we have a set of stimuli that we use for all subjects, e.g. pictures. Each specific stimulus might have its own effects, some might be more efficient in eliciting the measured response than others. In such a case, the stimuli would also explain some of the variance and would be a random factor.\n. . .\nData would be clustered not only within subject but also within stimulus (more similar)\nStimuli would also be assumed to be drawn randomly from a population of possible stimuli and we want to be able to generalize beyond the ones used.\n\nwhy “crossed”? Every participant provides an observation (or several) for every stimulus…\n\n. . .\nWith lmer(), it is quite easy to add other random effects, such as crossed random effects:\n\ny ~ x + (1 + x | subject_id) + (1 + x | stimulus_id)\n\n\n\n\nIt often happens that you get an error message: Either your model does not converge (R tries but can’t find good estimates) or you have a singular fit (the random factors have variances close to 0 or correlate perfectly, -1 or 1, with each other).\nIn both cases, it makes sense to simplify your random effect structure:\n\nConstrain all covariance parameters to zero. This is accomplished using the double-bar || syntax, e.g., changing (a * b | subject) to (a * b || subject). If you still run into estimation problems, then:\nInspect the parameter estimates from the non-converging or singular model. Are any of the slope variables zero or near to zero? Remove these and re-fit the model, repeating this step until the convergence warnings / singular fit messages go away.\n\n\nthis might not make sense right now, but you can look at it once you run into these problems\n\n\n\n\nLet’s fit a model with simulated data, which you can find in the file dat_sim2.csv.\n\ndat_sim2 &lt;- read_csv(\"Data/dat_sim2.csv\")\n\nRows: 5000 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (4): subj_id, item_id, cond, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(dat_sim2)\n\n# A tibble: 6 × 5\n  subj_id item_id  cond gender     Y\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1       1       1  -0.5 male   1078.\n2       1       2   0.5 male    957.\n3       1       3  -0.5 male    698.\n4       1       4   0.5 male    464.\n5       1       5  -0.5 male    497.\n6       1       6   0.5 male    787.\n\n\nIn the file, you can see 100 participants (subj_id) and 50 observations per participants, one for each stimulus (item_id).\nYou can also see two predictors: cond and gender.\nAs you can see, cond is a within-subject, across-item variable (a categorical factor!), which means that some of the stimuli belong to one category, the others to a second category (e.g. positive and negative images). gender is a between-subjects variable (also a categorical factor!): Participants either identify as female or male but that doesn’t change.\nFinally, there is a dependent/outcome variable called Y, this could be reaction times.\n. . .\nIf we’re interested in the effects of cond and gender (including their interaction) on Y, how would you specify the model? Which would be the fixed effects, which would be random effects?\n. . .\n\n# make sure gender is a factor!\ndat_sim2$gender &lt;- as.factor(dat_sim2$gender)\nlevels(dat_sim2$gender)\n\n[1] \"female\" \"male\"  \n\nmod_sim &lt;- lmer(Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id), dat_sim2, REML = FALSE)\n\nsummary(mod_sim)\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n                Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)      790.541     19.157 134.091  41.267  &lt; 2e-16 ***\ncond              76.085     26.894  56.207   2.829  0.00646 ** \ngendermale         5.503     20.261  99.624   0.272  0.78651    \ncond:gendermale    3.134     12.361  99.160   0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond   gndrml\ncond         0.062              \ngendermale  -0.529 -0.059       \ncond:gndrml -0.135 -0.230  0.256\n\n# with the anova() function, you will get the typical anova table with main effects and interaction!\nanova(mod_sim)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nR uses per default a coding of the factor levels called dummy coding. This means that one factor level is coded as 0, another as 1 (and if there are more than two levels, there will be several dummy coded variables used for the models).\nThe problem with dummy coding is that the output is hard to interpret, especially if interactions are involved. Therefore, it is preferable to use effects or sum coding, which uses e.g. -.5 and .5 as codes for the factor levels.\nYou can change this before running the model using:\n\n## use sum coding instead of default 'dummy' (treatment) coding\n\ncontrasts(dat_sim2$gender) &lt;- contr.sum\n\n\nmod_sim &lt;- lmer(Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id), dat_sim2, REML = FALSE)\n\nsummary(mod_sim)\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n             Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   793.293     16.259 101.954  48.791  &lt; 2e-16 ***\ncond           77.652     26.175  50.671   2.967  0.00458 ** \ngender1        -2.751     10.131  99.624  -0.272  0.78651    \ncond:gender1   -1.567      6.180  99.160  -0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond  gendr1\ncond        0.038              \ngender1     0.000  0.000       \ncond:gendr1 0.000  0.000 0.256 \n\nanova(mod_sim)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nWe can use the check_model() function of the performance package also for LMMs:\n\ncheck_model(mod_sim)\n\n\n\n\nLooks good!\n\n\n\nYou can also use the emmeans package for comparing different groups/factor levels. For example, you could do pairwise comparisons for the main effect of gender, if that was significant. This is especially relevant if you have more than two factor levels/groups/conditions, because with two you can already read out the effect from the lmer() output (the estimate for gender1 is the difference between the two genders if you use dummy coding, and 2* the estimate if you use sum coding!). We would use the emmeans() function:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ gender)\n\nYou could also investigate further in which direction an interaction goes. If you have a categorical and a continuous predictor, we would probably use emtrends() to see how the slope of the continuous variable differs between groups of the categorical variable.\nIf we have two categorical variables, like we have in our example, we can use emmeans() similarly to the code above, only that we include the interaction:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ cond:gender)\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'pbkrtest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(pbkrtest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'lmerTest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(lmerTest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\ntest(emm1)\n\n$emmeans\n cond gender emmean   SE  df z.ratio p.value\n -0.5 female    752 22.7 Inf  33.134  &lt;.0001\n  0.5 female    829 24.1 Inf  34.410  &lt;.0001\n -0.5 male      756 22.7 Inf  33.307  &lt;.0001\n  0.5 male      836 24.1 Inf  34.703  &lt;.0001\n\nDegrees-of-freedom method: asymptotic \n\n$contrasts\n contrast                            estimate   SE  df z.ratio p.value\n (cond-0.5 female) - cond0.5 female    -76.08 26.9 Inf  -2.829  0.0241\n (cond-0.5 female) - (cond-0.5 male)    -3.94 19.6 Inf  -0.201  0.9971\n (cond-0.5 female) - cond0.5 male      -83.15 33.1 Inf  -2.512  0.0580\n cond0.5 female - (cond-0.5 male)       72.15 33.1 Inf   2.180  0.1289\n cond0.5 female - cond0.5 male          -7.07 22.6 Inf  -0.312  0.9895\n (cond-0.5 male) - cond0.5 male        -79.22 26.9 Inf  -2.946  0.0170\n\nDegrees-of-freedom method: asymptotic \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nYou would then select the comparisons in the $contrasts output that are of interest (you can also run only those, but that’s a bit more difficult).\nYou can also use the emmip() function to make interaction plots, e.g.\n\nemmip(mod_sim, cond ~ gender)\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'pbkrtest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(pbkrtest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'lmerTest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(lmerTest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\n\n\n\nBut since the interaction is not significant, we don’t need to do any post-hoc comparisons!\n\n\n\nYou can calculate the R², the explained variance of the DV Y, as an overall model fit index. For LMMs, you can calculate two R²: One for the fixed effects only (marginal), one when also accounting for the random effect (i.e. the individual differences, conditional).\n\n# use r2() from the performance package:\n\nr2(mod_sim)\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.323\n     Marginal R2: 0.025\n\n\nIn addition, you can calculate the effect sizes per effect. This is not as straight-forward for LMMs, but you could use the following function from the effectsize package to obtain the partial eta² (you would have to manually - or with R code - plug in the F values etc. from the ANOVA table!):\n\nlibrary(effectsize)\noptions(es.use_symbols = TRUE) # get nice symbols when printing! (On Windows, requires R &gt;= 4.2.0)\n\nF_to_eta2(\n  f = c(8.8013, 0.0738, 0.0643),\n  df = c(1, 1, 1),\n  df_error = c(50.671, 99.624,99.160)\n)\n\nη² (partial) |       95% CI\n---------------------------\n0.15         | [0.03, 1.00]\n7.40e-04     | [0.00, 1.00]\n6.48e-04     | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\n\n\nWe ran a linear mixed model with condition and gender as fixed effect, Y as dependent variable, and random slopes for condition for each subject, as well as random intercepts for subjects and items. All assumptions of linear mixed models were met (see figure…) and the model explains 32,3% of the variance in Y if accounting for the random effects (marginal R²) and 2,5% if only accounting for the fixed effects (conditional R²).\nWe found a main effect of condition (F(1, 50.67) = 8.8, p = .005, partial η² = 0.15), but neither a main effect of gender (F(…, …) = .. , p = …, partial η² = …) nor a significant interaction between gender and condition (F(…, …) = .. , p = …, partial η² = …).\nThe Ys in one cond (-.5) are significantly lower (Mean = 754, SD =…) than in the other cond (.5; mean = 832, SD = …, see also figure …).\n[Add visualization where you can see the difference between conditions!]"
  },
  {
    "objectID": "W12_LMM.html#setup",
    "href": "W12_LMM.html#setup",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "We will use a package called lme4 for the statistical models. The package includes a dataset called sleepstudy, which we will be using. You don’t have to load the data separately, just load the package and you have access to the data:\n\nlibrary(lme4)\n\nLade nötiges Paket: Matrix\n\n\n\nAttache Paket: 'Matrix'\n\n\nDie folgenden Objekte sind maskiert von 'package:tidyr':\n\n    expand, pack, unpack\n\nhead(sleepstudy)\n\n  Reaction Days Subject\n1 249.5600    0     308\n2 258.7047    1     308\n3 250.8006    2     308\n4 321.4398    3     308\n5 356.8519    4     308\n6 414.6901    5     308\n\n# for information about the dataset, check out:\n# ?sleepstudy\n\nDescription:\n\n     The average reaction time per day (in milliseconds) for subjects\n     in a sleep deprivation study.\n\n     Days 0-1 were adaptation and training (T1/T2), day 2 was baseline\n     (B); sleep deprivation started after day 2.\n\nFormat:\n\n     A data frame with 180 observations on the following 3 variables.\n\n     ‘Reaction’ Average reaction time (ms)\n\n     ‘Days’ Number of days of sleep deprivation\n\n     ‘Subject’ Subject number on which the observation was made."
  },
  {
    "objectID": "W12_LMM.html#multilevel-data",
    "href": "W12_LMM.html#multilevel-data",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Multilevel data are nested data, which means that the are clustered:\n\n\nFor example, repeated measures of the same subjects will result in data that are more strongly correlated within subjects than between.\nBut LMMs can also account for other kinds of nesting/clustering, such as patients who share therapists or mice from the same cage/experimenter.\n\n\n. . .\nData is usually multilevel for one of the three reasons below (multiple reasons could simultaneously apply):\n\nyou have a within-subject factor, and/or\nyou have pseudoreplications (several trials/measurements), and/or\nyou have multiple stimulus items.\n\n. . .\n\n\n\n\n\nLevels of a Multilevel Model\n\n\n\n\n\n\n3-level LMM\n\n\n\n\n. . .\nThese kind of data are extremely common in neuroscientific research!\n. . .\nUnfortunately, LMMs are hardly every covered in statistics classes. Instead, these data are often analyzed using t-tests or ANOVAs, but sometimes these models are not sufficient (e.g. because they only allow for categorical predictors, but time in our example data is continuous…).\n. . .\nMoreover, LMMs have less of a problem with missing data.\n\nWe can often use t-tests or ANOVAs, but we might have to calculate the means per condition or the like before we run the analysis. This means throwing away a lot of information!"
  },
  {
    "objectID": "W12_LMM.html#the-sleepstudy-data",
    "href": "W12_LMM.html#the-sleepstudy-data",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "In the dataset, we have measurements of 18 participants across 10 days of sleep deprivation. Each day, the participants performed a “psychomotor vigilance test” where they had to monitor a display and press a button as quickly as possible as soon as a stimulus appeared.\nThe dependent measure (DV) is response times (RT).\nLet’s take a look at the data, with a separate plot per participant:\n\nsleep &lt;- sleepstudy\n\nggplot(sleep, aes(x = Days, y = Reaction)) +\n  geom_point() +\n  scale_x_continuous(breaks = 0:9) +\n  facet_wrap(~Subject)\n\n\n\n\nIt looks like RT is increasing with each additional day of sleep deprivation, starting from day 2 and increasing until day 10."
  },
  {
    "objectID": "W12_LMM.html#preparing-the-data",
    "href": "W12_LMM.html#preparing-the-data",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "We have some more information about the model that is helpful:\n\nThe first two days were adaptation and training, the third day was a baseline measurement (8h time in bed)\nOn the 4th day (until the 10th, so for 7 days), the sleep deprivation began:\n\nThere were four groups: 9h, 7h, 5h, 3h time in bed\n\n\n. . .\nWe thus have to remove the first two days, as they might bias our results.\nTask:\n\nRemove (filter) observations where Days is 0 or 1.\nMake a new variable, days_deprived, where day 2 is recoded as 0, day 3 as 1 etc.\nStore the data in a dataframe called sleep2.\n\n. . .\n\nsleep2 &lt;- sleepstudy %&gt;%\n  filter(Days &gt;= 2) %&gt;%\n  mutate(days_deprived = Days - 2)\n\nhead(sleep2)\n\n  Reaction Days Subject days_deprived\n1 250.8006    2     308             0\n2 321.4398    3     308             1\n3 356.8519    4     308             2\n4 414.6901    5     308             3\n5 382.2038    6     308             4\n6 290.1486    7     308             5"
  },
  {
    "objectID": "W12_LMM.html#fitting-the-model",
    "href": "W12_LMM.html#fitting-the-model",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "How might we model the relationship between days_deprived and Reaction?\n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n\n\n\n\n. . .\nIt looks like we could fit an (increasing) line to each participant’s data.\nRemember the general formula for fitting lines:\n\\(Y = \\beta_0 + \\beta_1 X\\)\nwhere \\(\\beta_0\\) is the y-intercept and \\(\\beta_1\\) is the slope, which we both estimate from the data.\n. . .\nIf we fit such a line for every participant, the lines will differ in their intercept (mean RT at baseline, people differ in RTs!) and slope (the change in RT with each additional day of sleep deprivation).\nShould we fit the same line for every participant? Or individual lines? Or something in between?\nThese three approaches are also called complete pooling, no pooling, and partial pooling."
  },
  {
    "objectID": "W12_LMM.html#complete-pooling",
    "href": "W12_LMM.html#complete-pooling",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "With complete pooling, we would estimate the same intercept and slope for every participant (“one size fits all”). This approach ignores that certain data points belong to certain individuals and just fits a line across all data points.\nWe could fit such a model simply with lm(), which means we ignore the repeated measures within person and pretend that all observations are independent:\n\ncp_model &lt;- lm(Reaction ~ days_deprived, sleep2)\n\nsummary(cp_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived, data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-112.284  -26.732    2.143   27.734  140.453 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    267.967      7.737  34.633  &lt; 2e-16 ***\ndays_deprived   11.435      1.850   6.183 6.32e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 50.85 on 142 degrees of freedom\nMultiple R-squared:  0.2121,    Adjusted R-squared:  0.2066 \nF-statistic: 38.23 on 1 and 142 DF,  p-value: 6.316e-09\n\n\n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_abline(intercept = coef(cp_model)[1],\n              slope = coef(cp_model)[2],\n              color = 'blue') +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")\n\n\n\n\n\nFits the data badly!\nthe predicted mean response time on Day 0 is about 268 milliseconds, with an increase of about 11 milliseconds per day of deprivation, on average. We can’t trust the standard errors for our regression coefficients, however, because we are assuming that all of the observations are independent (technically, that the residuals are). However, we can be pretty sure this is a bad assumption."
  },
  {
    "objectID": "W12_LMM.html#no-pooling",
    "href": "W12_LMM.html#no-pooling",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Another approach would be to fit separate lines for each participant.\nThis approach implies that the estimates for one participant are completely uninformed by the estimates for the other participants - we could fit 18 separate models.\nWe could also include Subject as a predictor, or a so-called fixed effect.\nFor this approach, we have to make sure Subject is a factor (because the subject ID is meaningless, 310 is not 1 better than 309 etc.).\n\nstr(sleep2)\n\n'data.frame':   144 obs. of  4 variables:\n $ Reaction     : num  251 321 357 415 382 ...\n $ Days         : num  2 3 4 5 6 7 8 9 2 3 ...\n $ Subject      : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 2 2 ...\n $ days_deprived: num  0 1 2 3 4 5 6 7 0 1 ...\n\n# fit the model\n\nnp_model &lt;- lm(Reaction ~ days_deprived + Subject + days_deprived:Subject, data = sleep2)\n\nsummary(np_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived + Subject + days_deprived:Subject, \n    data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-106.521   -8.541    1.143    8.889  128.545 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              288.2175    16.4772  17.492  &lt; 2e-16 ***\ndays_deprived             21.6905     3.9388   5.507 2.49e-07 ***\nSubject309               -87.9262    23.3023  -3.773 0.000264 ***\nSubject310               -62.2856    23.3023  -2.673 0.008685 ** \nSubject330               -14.9533    23.3023  -0.642 0.522422    \nSubject331                 9.9658    23.3023   0.428 0.669740    \nSubject332                27.8157    23.3023   1.194 0.235215    \nSubject333                -2.7581    23.3023  -0.118 0.906000    \nSubject334               -50.2051    23.3023  -2.155 0.033422 *  \nSubject335               -25.3429    23.3023  -1.088 0.279207    \nSubject337                24.6143    23.3023   1.056 0.293187    \nSubject349               -59.2183    23.3023  -2.541 0.012464 *  \nSubject350               -40.2023    23.3023  -1.725 0.087343 .  \nSubject351               -24.2467    23.3023  -1.041 0.300419    \nSubject352                43.0655    23.3023   1.848 0.067321 .  \nSubject369               -21.5040    23.3023  -0.923 0.358154    \nSubject370               -53.3072    23.3023  -2.288 0.024107 *  \nSubject371               -30.4896    23.3023  -1.308 0.193504    \nSubject372                 2.4772    23.3023   0.106 0.915535    \ndays_deprived:Subject309 -17.3334     5.5703  -3.112 0.002380 ** \ndays_deprived:Subject310 -17.7915     5.5703  -3.194 0.001839 ** \ndays_deprived:Subject330 -13.6849     5.5703  -2.457 0.015613 *  \ndays_deprived:Subject331 -16.8231     5.5703  -3.020 0.003154 ** \ndays_deprived:Subject332 -19.2947     5.5703  -3.464 0.000765 ***\ndays_deprived:Subject333 -10.8151     5.5703  -1.942 0.054796 .  \ndays_deprived:Subject334  -3.5745     5.5703  -0.642 0.522423    \ndays_deprived:Subject335 -25.8995     5.5703  -4.650 9.47e-06 ***\ndays_deprived:Subject337   0.7518     5.5703   0.135 0.892895    \ndays_deprived:Subject349  -5.2644     5.5703  -0.945 0.346731    \ndays_deprived:Subject350   1.6007     5.5703   0.287 0.774382    \ndays_deprived:Subject351 -13.1681     5.5703  -2.364 0.019867 *  \ndays_deprived:Subject352 -14.4019     5.5703  -2.585 0.011057 *  \ndays_deprived:Subject369  -7.8948     5.5703  -1.417 0.159273    \ndays_deprived:Subject370  -1.0495     5.5703  -0.188 0.850912    \ndays_deprived:Subject371  -9.3443     5.5703  -1.678 0.096334 .  \ndays_deprived:Subject372 -10.6041     5.5703  -1.904 0.059613 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.53 on 108 degrees of freedom\nMultiple R-squared:  0.849, Adjusted R-squared:  0.8001 \nF-statistic: 17.35 on 35 and 108 DF,  p-value: &lt; 2.2e-16\n\n\n\nalso uses lm()\nintercept and slope = 308, other values are deviations from 308\nThis model does not give us an overall intercept and slope! (Can average of course…) -&gt; suboptimal if we want to generalize to new participants!\n\n\nall_intercepts &lt;- c(coef(np_model)[\"(Intercept)\"],\n                    coef(np_model)[3:19] + coef(np_model)[\"(Intercept)\"])\n\nall_slopes  &lt;- c(coef(np_model)[\"days_deprived\"],\n                 coef(np_model)[20:36] + coef(np_model)[\"days_deprived\"])\n\nids &lt;- sleep2 %&gt;% pull(Subject) %&gt;% levels() %&gt;% factor()\n\n# make a tibble with the data extracted above\nnp_coef &lt;- tibble(Subject = ids,\n                  intercept = all_intercepts,\n                  slope = all_slopes)\n\nnp_coef\n\n# A tibble: 18 × 3\n   Subject intercept slope\n   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 308          288. 21.7 \n 2 309          200.  4.36\n 3 310          226.  3.90\n 4 330          273.  8.01\n 5 331          298.  4.87\n 6 332          316.  2.40\n 7 333          285. 10.9 \n 8 334          238. 18.1 \n 9 335          263. -4.21\n10 337          313. 22.4 \n11 349          229. 16.4 \n12 350          248. 23.3 \n13 351          264.  8.52\n14 352          331.  7.29\n15 369          267. 13.8 \n16 370          235. 20.6 \n17 371          258. 12.3 \n18 372          291. 11.1 \n\nggplot(sleep2, aes(x = days_deprived, y = Reaction)) +\n  geom_abline(data = np_coef,\n              mapping = aes(intercept = intercept,\n                            slope = slope),\n              color = 'blue') +\n  geom_point() +\n  scale_x_continuous(breaks = 0:7) +\n  facet_wrap(~Subject) +\n  labs(y = \"Reaction Time\", x = \"Days deprived of sleep (0 = baseline)\")"
  },
  {
    "objectID": "W12_LMM.html#partial-pooling",
    "href": "W12_LMM.html#partial-pooling",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Neither the complete or no-pooling approach is satisfactory.\nIt would be desirable to improve our estimates for individual participants by taking advantage of what we know about the other participants.\n. . .\nThis is called partial pooling: We treat a factor (e.g. subject) as random instead of as fixed.\nA random factor is a factor whose levels are considered to represent a proper subset of all the levels in the population (remember sampling!).\n. . .\nIn partial pooling used in LMMs, estimates at each factor level (i.e. subject) become informed by the information at other levels.\nThe model estimates values for the population, and pulls the estimates for individual subjects toward those values, a statistical phenomenon known as shrinkage.\n. . .\nWe thus estimate a model like this:\n\\(Y_{sd} = \\gamma_{0} + S_{0s} + \\left(\\gamma_{1} + S_{1s}\\right) X_{sd} + e_{sd}\\)\nwhere \\(\\gamma_{0}\\) is the “overall”/population intercept and \\(\\gamma_{1}\\) is the population slope. These are the fixed effects which are usually of interest and they are estimated from the data.\n\\(S_{0s}\\) are the random intercepts per participant and \\(S_{1s}\\) the random slopes for \\(X_{sd}\\) per participant. These values vary over subjects and are the offsets from the fixed effects (i.e. how much do individuals differ from the overall intercept/slope? Some subjects will have slower RTs, for some the effect of sleep deprivation will be stronger…).\n(See textbook for further mathematical formula descriptions and details!)\n\nWill help us distinguish signal from error for each participant\nimprove generalization to the population\nespecially important if we have missing data\n---\nRF: result of sampling, want to generalize beyond those levels\n---\nFE: assume that they reflect true pop para, don’t vary from sample to sample"
  },
  {
    "objectID": "W12_LMM.html#partial-pooling-2",
    "href": "W12_LMM.html#partial-pooling-2",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Different Pooling Models\n\n\n\n\n\nShrinkage\n\n\n\nthe further away (the more “unnormal), the more changed/drawn towards overall estimates/penalized.\nThe fewer observations in a cluster, the more information borrowed from others, greater pull (373 and 374)\nAvoids overfitting by taming extreme estimates!"
  },
  {
    "objectID": "W12_LMM.html#fitting-the-model-1",
    "href": "W12_LMM.html#fitting-the-model-1",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "To fit a LMM, we can use the function lmer() from the lme4 package (you could also use functions from the afex package, which might be more user friendly).\nThe notation is very similar to that of fitting lm() models, we only need to add the random effects:\n\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\n\n. . .\nHere we can see that we only have one predictor/IV/fixed effect: days_deprived.\nRandom effects are denoted in the parentheses (). On the right side of the |, you write down what uniquely identifies the clustering variable, e.g. Subjects. On the left side of the |, you put the effects that you want to vary over the levels of the clustering variable. The right side thus denotes the random intercept, the left side the random slope.\n. . .\nThere are a number of ways to specify random effects. The most common you will see are:\n\n\n\n\n\n\n\nModel\nSyntax\n\n\n\n\nRandom intercepts only\nReaction ~ days_deprived + (1 | Subject)\n\n\nRandom intercepts and slopes\nReaction ~ days_deprived + (1 + days_deprived | Subject)\n(or the one above, which is identical)\n\n\n\nRandom-intercepts-only models are appropriate if you have within-subjects factors without pseudo-replications (i.e. one measurement per subject/level). If you have more than one observation per subject per cell, you need random slopes.\n\nalways good to include random slopes, but sometimes the model does not converge –&gt; only random intercepts\nrmANOVA ~ random intercept model\nYou can add other random effects!"
  },
  {
    "objectID": "W12_LMM.html#interpreting-the-model---fixed-effects",
    "href": "W12_LMM.html#interpreting-the-model---fixed-effects",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Let’s look at the model output:\n\nsummary(pp_mod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error t value\n(Intercept)    267.967      8.266  32.418\ndays_deprived   11.435      1.845   6.197\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062\n\n\nThe section called Fixed effects is similar to what you have seen so far for lm() models. This is also the section that will likely be of main interest to you.\nYou can see that the estimated mean reaction time for participants at Day 0 was about 268 milliseconds, with each day of sleep deprivation adding an additional 11 milliseconds to the response time, on average.\n. . .\nYou might also notice that you don’t see p-values in the output. There is a huge discussion on how to best estimate the degrees of freedom for these models… If you don’t want to go into the details, one option is to use the lmerTest package to obtain p-values:\n\nlibrary(lmerTest)\n\n\nAttache Paket: 'lmerTest'\n\n\nDas folgende Objekt ist maskiert 'package:lme4':\n\n    lmer\n\n\nDas folgende Objekt ist maskiert 'package:stats':\n\n    step\n\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\nsummary(pp_mod)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)    267.967      8.266  17.000  32.418  &lt; 2e-16 ***\ndays_deprived   11.435      1.845  16.999   6.197 9.75e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062"
  },
  {
    "objectID": "W12_LMM.html#interpreting-the-model---random-effects",
    "href": "W12_LMM.html#interpreting-the-model---random-effects",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "The random effects part of the output provides you with the variance-covariance matrix of the random effects and the residual variance.\nThe residual variance is the variance of the residuals, i.e. the error variance which is not explained by the model.\nThe variance-covariance matrix above gives us the variance of each random effect component as well as the correlation between random intercept and slope. Often, you would not need to interpret these effects in too much detail (unless you’re interested in floor/ceiling effect visible in a big correlation), but you should make sure the variance is not 0 or 1."
  },
  {
    "objectID": "W12_LMM.html#lmm-with-crossed-random-factors",
    "href": "W12_LMM.html#lmm-with-crossed-random-factors",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Often, we have a set of stimuli that we use for all subjects, e.g. pictures. Each specific stimulus might have its own effects, some might be more efficient in eliciting the measured response than others. In such a case, the stimuli would also explain some of the variance and would be a random factor.\n. . .\nData would be clustered not only within subject but also within stimulus (more similar)\nStimuli would also be assumed to be drawn randomly from a population of possible stimuli and we want to be able to generalize beyond the ones used.\n\nwhy “crossed”? Every participant provides an observation (or several) for every stimulus…\n\n. . .\nWith lmer(), it is quite easy to add other random effects, such as crossed random effects:\n\ny ~ x + (1 + x | subject_id) + (1 + x | stimulus_id)"
  },
  {
    "objectID": "W12_LMM.html#convergence-issues-and-singular-fits",
    "href": "W12_LMM.html#convergence-issues-and-singular-fits",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "It often happens that you get an error message: Either your model does not converge (R tries but can’t find good estimates) or you have a singular fit (the random factors have variances close to 0 or correlate perfectly, -1 or 1, with each other).\nIn both cases, it makes sense to simplify your random effect structure:\n\nConstrain all covariance parameters to zero. This is accomplished using the double-bar || syntax, e.g., changing (a * b | subject) to (a * b || subject). If you still run into estimation problems, then:\nInspect the parameter estimates from the non-converging or singular model. Are any of the slope variables zero or near to zero? Remove these and re-fit the model, repeating this step until the convergence warnings / singular fit messages go away.\n\n\nthis might not make sense right now, but you can look at it once you run into these problems"
  },
  {
    "objectID": "W12_LMM.html#example",
    "href": "W12_LMM.html#example",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "Let’s fit a model with simulated data, which you can find in the file dat_sim2.csv.\n\ndat_sim2 &lt;- read_csv(\"Data/dat_sim2.csv\")\n\nRows: 5000 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (4): subj_id, item_id, cond, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(dat_sim2)\n\n# A tibble: 6 × 5\n  subj_id item_id  cond gender     Y\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1       1       1  -0.5 male   1078.\n2       1       2   0.5 male    957.\n3       1       3  -0.5 male    698.\n4       1       4   0.5 male    464.\n5       1       5  -0.5 male    497.\n6       1       6   0.5 male    787.\n\n\nIn the file, you can see 100 participants (subj_id) and 50 observations per participants, one for each stimulus (item_id).\nYou can also see two predictors: cond and gender.\nAs you can see, cond is a within-subject, across-item variable (a categorical factor!), which means that some of the stimuli belong to one category, the others to a second category (e.g. positive and negative images). gender is a between-subjects variable (also a categorical factor!): Participants either identify as female or male but that doesn’t change.\nFinally, there is a dependent/outcome variable called Y, this could be reaction times.\n. . .\nIf we’re interested in the effects of cond and gender (including their interaction) on Y, how would you specify the model? Which would be the fixed effects, which would be random effects?\n. . .\n\n# make sure gender is a factor!\ndat_sim2$gender &lt;- as.factor(dat_sim2$gender)\nlevels(dat_sim2$gender)\n\n[1] \"female\" \"male\"  \n\nmod_sim &lt;- lmer(Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id), dat_sim2, REML = FALSE)\n\nsummary(mod_sim)\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n                Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)      790.541     19.157 134.091  41.267  &lt; 2e-16 ***\ncond              76.085     26.894  56.207   2.829  0.00646 ** \ngendermale         5.503     20.261  99.624   0.272  0.78651    \ncond:gendermale    3.134     12.361  99.160   0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond   gndrml\ncond         0.062              \ngendermale  -0.529 -0.059       \ncond:gndrml -0.135 -0.230  0.256\n\n# with the anova() function, you will get the typical anova table with main effects and interaction!\nanova(mod_sim)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "W12_LMM.html#contrasts",
    "href": "W12_LMM.html#contrasts",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "R uses per default a coding of the factor levels called dummy coding. This means that one factor level is coded as 0, another as 1 (and if there are more than two levels, there will be several dummy coded variables used for the models).\nThe problem with dummy coding is that the output is hard to interpret, especially if interactions are involved. Therefore, it is preferable to use effects or sum coding, which uses e.g. -.5 and .5 as codes for the factor levels.\nYou can change this before running the model using:\n\n## use sum coding instead of default 'dummy' (treatment) coding\n\ncontrasts(dat_sim2$gender) &lt;- contr.sum\n\n\nmod_sim &lt;- lmer(Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id), dat_sim2, REML = FALSE)\n\nsummary(mod_sim)\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n             Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   793.293     16.259 101.954  48.791  &lt; 2e-16 ***\ncond           77.652     26.175  50.671   2.967  0.00458 ** \ngender1        -2.751     10.131  99.624  -0.272  0.78651    \ncond:gender1   -1.567      6.180  99.160  -0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond  gendr1\ncond        0.038              \ngender1     0.000  0.000       \ncond:gendr1 0.000  0.000 0.256 \n\nanova(mod_sim)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "W12_LMM.html#assumption-check",
    "href": "W12_LMM.html#assumption-check",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "We can use the check_model() function of the performance package also for LMMs:\n\ncheck_model(mod_sim)\n\n\n\n\nLooks good!"
  },
  {
    "objectID": "W12_LMM.html#planned-comparisons",
    "href": "W12_LMM.html#planned-comparisons",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "You can also use the emmeans package for comparing different groups/factor levels. For example, you could do pairwise comparisons for the main effect of gender, if that was significant. This is especially relevant if you have more than two factor levels/groups/conditions, because with two you can already read out the effect from the lmer() output (the estimate for gender1 is the difference between the two genders if you use dummy coding, and 2* the estimate if you use sum coding!). We would use the emmeans() function:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ gender)\n\nYou could also investigate further in which direction an interaction goes. If you have a categorical and a continuous predictor, we would probably use emtrends() to see how the slope of the continuous variable differs between groups of the categorical variable.\nIf we have two categorical variables, like we have in our example, we can use emmeans() similarly to the code above, only that we include the interaction:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ cond:gender)\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'pbkrtest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(pbkrtest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'lmerTest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(lmerTest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\ntest(emm1)\n\n$emmeans\n cond gender emmean   SE  df z.ratio p.value\n -0.5 female    752 22.7 Inf  33.134  &lt;.0001\n  0.5 female    829 24.1 Inf  34.410  &lt;.0001\n -0.5 male      756 22.7 Inf  33.307  &lt;.0001\n  0.5 male      836 24.1 Inf  34.703  &lt;.0001\n\nDegrees-of-freedom method: asymptotic \n\n$contrasts\n contrast                            estimate   SE  df z.ratio p.value\n (cond-0.5 female) - cond0.5 female    -76.08 26.9 Inf  -2.829  0.0241\n (cond-0.5 female) - (cond-0.5 male)    -3.94 19.6 Inf  -0.201  0.9971\n (cond-0.5 female) - cond0.5 male      -83.15 33.1 Inf  -2.512  0.0580\n cond0.5 female - (cond-0.5 male)       72.15 33.1 Inf   2.180  0.1289\n cond0.5 female - cond0.5 male          -7.07 22.6 Inf  -0.312  0.9895\n (cond-0.5 male) - cond0.5 male        -79.22 26.9 Inf  -2.946  0.0170\n\nDegrees-of-freedom method: asymptotic \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nYou would then select the comparisons in the $contrasts output that are of interest (you can also run only those, but that’s a bit more difficult).\nYou can also use the emmip() function to make interaction plots, e.g.\n\nemmip(mod_sim, cond ~ gender)\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'pbkrtest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(pbkrtest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\nNote: D.f. calculations have been disabled because the number of observations exceeds 3000.\nTo enable adjustments, add the argument 'lmerTest.limit = 5000' (or larger)\n[or, globally, 'set emm_options(lmerTest.limit = 5000)' or larger];\nbut be warned that this may result in large computation time and memory use.\n\n\n\n\n\nBut since the interaction is not significant, we don’t need to do any post-hoc comparisons!"
  },
  {
    "objectID": "W12_LMM.html#effect-sizes",
    "href": "W12_LMM.html#effect-sizes",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "You can calculate the R², the explained variance of the DV Y, as an overall model fit index. For LMMs, you can calculate two R²: One for the fixed effects only (marginal), one when also accounting for the random effect (i.e. the individual differences, conditional).\n\n# use r2() from the performance package:\n\nr2(mod_sim)\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.323\n     Marginal R2: 0.025\n\n\nIn addition, you can calculate the effect sizes per effect. This is not as straight-forward for LMMs, but you could use the following function from the effectsize package to obtain the partial eta² (you would have to manually - or with R code - plug in the F values etc. from the ANOVA table!):\n\nlibrary(effectsize)\noptions(es.use_symbols = TRUE) # get nice symbols when printing! (On Windows, requires R &gt;= 4.2.0)\n\nF_to_eta2(\n  f = c(8.8013, 0.0738, 0.0643),\n  df = c(1, 1, 1),\n  df_error = c(50.671, 99.624,99.160)\n)\n\nη² (partial) |       95% CI\n---------------------------\n0.15         | [0.03, 1.00]\n7.40e-04     | [0.00, 1.00]\n6.48e-04     | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00]."
  },
  {
    "objectID": "W12_LMM.html#interpretation",
    "href": "W12_LMM.html#interpretation",
    "title": "12 Linear Mixed Models",
    "section": "",
    "text": "We ran a linear mixed model with condition and gender as fixed effect, Y as dependent variable, and random slopes for condition for each subject, as well as random intercepts for subjects and items. All assumptions of linear mixed models were met (see figure…) and the model explains 32,3% of the variance in Y if accounting for the random effects (marginal R²) and 2,5% if only accounting for the fixed effects (conditional R²).\nWe found a main effect of condition (F(1, 50.67) = 8.8, p = .005, partial η² = 0.15), but neither a main effect of gender (F(…, …) = .. , p = …, partial η² = …) nor a significant interaction between gender and condition (F(…, …) = .. , p = …, partial η² = …).\nThe Ys in one cond (-.5) are significantly lower (Mean = 754, SD =…) than in the other cond (.5; mean = 832, SD = …, see also figure …).\n[Add visualization where you can see the difference between conditions!]"
  },
  {
    "objectID": "W12_LMM.html#why-not-model-discrete-data-as-continuous",
    "href": "W12_LMM.html#why-not-model-discrete-data-as-continuous",
    "title": "12 Linear Mixed Models",
    "section": "Why not Model Discrete Data as Continuous?",
    "text": "Why not Model Discrete Data as Continuous?\nThis is actually what happens a lot (you can see it in published papers): Researchers treat percentages, counts, or (sums of) responses on a Likert scale as continuous data and simply run a linear model.\nBut there are a number of reasons why this is a bad idea:\n\nBounded scale: There are usually no negative numbers and often an upper limit as well. A normal linear model would try to assign probability to these impossible values. This can lead to spurious interaction effects (think of improvements from 90% - there’s a ceiling effect)!\nVariance depends on mean: In LMs, the variance is independent from the mean (related to the assumption of homogeneity of variance). This is not necessarily the case for discrete data (e.g. binary or count data).\n\nIt thus makes sense to model the data as best as possible."
  },
  {
    "objectID": "W12_LMM.html#how-to-run-a-generalized-linear-model",
    "href": "W12_LMM.html#how-to-run-a-generalized-linear-model",
    "title": "12 Linear Mixed Models",
    "section": "How to run a Generalized Linear Model",
    "text": "How to run a Generalized Linear Model\nThe basic idea is to use a link function that transforms the response space so that we can perform our usual linear regression. The parameters will be hard to interpret because they are in the model space (~different units), but we can transform them back to our response space (data units) using an inverse link function.\n. . .\nThere are a lot of different kinds of generalized linear models that you would use depending on your data. The most common ones are the logistic regression (for binary data) and the Poisson regression (for count data).\nI will just give you an example with logistic regression."
  },
  {
    "objectID": "W12_LMM.html#logistic-regression",
    "href": "W12_LMM.html#logistic-regression",
    "title": "12 Linear Mixed Models",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nDefinitions:\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nBernoulli trial\nAn event with an binary outcome, with one outcome being considered “success”\n\n\nproportion\nThe ratio of successes to the total number of Bernoulli trials\n\n\nodds\nThe ratio of successes to failures\n\n\nlog odds\nThe (natural) log of the odds\n\n\n\nIn logisitc regression, we are modeling the relationship between response (DV) and predictors (IVs) in log odds space (= model space).\n. . .\nLogistic regression is used when the individual outcomes are Bernoulli trials. The outcome of a sequence of trials is communicated as a proportion:\nIf we flip a coin 100 times and get 47 heads, we have a proportion of .47. This is our estimate of the probability of the event.\n. . .\nWe can also calculate the (natural) odds of heads: 47:53 = .89 (heads:not heads).\nThe natural log of the odds or logit is the scale of the logistic regression.\nRecall that the logarithm of some value Y gives the exponent that would yield Y for a given base. For instance, the log2 (log to the base 2) of 16 is 4, because 24 = 16.\nIn logistic regression, the base is usually e (Euler’s number). To get the log odds from the natural odds, we can use log() and to get the inverse, the natural from the log odds, we can use exp().\n\nBernoulli: 0,1 / success, failure… arbitrary what is success!\nodds = p/1-p\n0 to +inf\nnice properties of log odds:\n\nsymmetric around 0\n0 = max. uncertainty, both outcomes equally likely\npos: success more likely than failure"
  },
  {
    "objectID": "W12_LMM.html#link-function",
    "href": "W12_LMM.html#link-function",
    "title": "12 Linear Mixed Models",
    "section": "Link Function",
    "text": "Link Function\nThe link function for logistic regression is:\n\\(\\eta = \\log \\left(\\frac{p}{1-p}\\right)\\)\nThe inverse link function is:\n\\(p = \\frac{1}{1 + e^{-\\eta}}\\)\n\n\n\nModel vs. response space\n\n\n\neta = outcome variable?!"
  },
  {
    "objectID": "W12_LMM.html#estimating-logistic-regression-in-r",
    "href": "W12_LMM.html#estimating-logistic-regression-in-r",
    "title": "12 Linear Mixed Models",
    "section": "Estimating Logistic Regression in R",
    "text": "Estimating Logistic Regression in R\nEstimating logistic regressions is not very difficult in R (the interpretation might be, though), because you simply use the function glm() instead of lm() or glmer() instead of lmer().\nIn addition, you’d add an argument to the function, which specifies the link function. For logistic regression, this would be family = binomial(link = \"logit\") or family = binomial would be sufficient if you want to use the default logit link.\nSo the code would look like this:\n\nglm(DV ~ IV1 + IV2 + ..., data, family = binomial)\n\n# for multi-level data:\nglmer(DV ~ IV1 + IV2 + ... (1 | subject), data, family = binomial)"
  },
  {
    "objectID": "W15_RepResearchR.html",
    "href": "W15_RepResearchR.html",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "code.sourceCode {\n  font-size: 1.4em;\n}\n\ndiv.cell-output-stdout {\n  font-size: 1.4em;\n}\n\n\nTraditionally, there has been a lot of trust in scientific results. In the last years, however, this trust has decreased, and we know that science may not always work as well (“replication crisis”).\n\n\n\n\nYou have a hypothesis\n\nBranding food with popular characters causes children to choose “healthy” food\n\nYou collect some data\n\nChildren can choose between cookie and apple with either Elmo-sticker or control\n\nYou do statistics (often to test the null hypothesis)\n\n“The preplanned comparison shows Elmo-branded apples were associated with an increase in a child’s selection of an apple over a cookie, from 20.7% to 33.8% (χ2=5.158; P=.02)” (Wansink, Just, and Payne 2012)\n\nYou make a conclusion based on the data\n\nBranding can increase healthy choices in young children…\n\n\n\n. . .\n\n\n\nThe Research Cycle (Munafo et.al., 2017)\n\n\n\n= scientific cycle\n\n\n\n\nThe example on the last slide summarized a study by Brian Wansink. He was a very popular eating researcher - until in 2017 some researchers looked at his publications more closely and found a lot of inconsistencies and statistical problems. Wansink refused to share the data.\n. . .\nThere was a Buzzfeed article, which reported\n\nThe p-value was 0.06, just shy of the gold standard cutoff of 0.05. It was a “sticking point,” as he put it in a Jan. 7, 2012, email. … “It seems to me it should be lower,” he wrote, attaching a draft. “Do you want to take a look at it and see what you think. If you can get the data, and it needs some tweeking, it would be good to get that one value below .05.” …\n\n. . .\nWansink eventually resigned after a number of his papers had been retracted.\n\n\n\nIn 2015, the paper “Estimating the reproducibility of psychological science”(Open Science Collaboration 2015) was published. It showed that out of 100 published studies with originally 97% significant results, only 37% could be replicated (i.e. were also significant in the replication).\n. . .\nThis was actually predicted already in 2005 in a paper by the (now in-)famous John Ioannidis. In the paper “Why most published research findings are false”, he argued that the use of Null Hypothesis Significance Testing (NHST) will necessarily lead to high levels of false results\n\n\n\nPositive Predictive Value (PPV): Statistically significant findings that are actually true. \\(P(\\text{Effect true |  significant result})\\)!\nType I error/False positives: How many of the statistically significant findings do we expect to be false? Usually 5% if \\(\\alpha=0.05\\).\nType II error/False negatives: How many of the non-significant findings do we expect to actually be true effects? Usually something like \\(\\beta=0.20\\).\nStatistical Power: How likely are we with our study design to actually find a true effect? I.e. if we have a power of 50%, we would only find a true effect at chance level. Power is the inverse of the Type II error: e.g. \\(\\text{power} = 1\\) \\(- \\beta = .80\\).\nWe can increase power with increasing sample size!\n. . .\n\\[PPV = \\frac{P(\\text{true positive result})}{P(\\text{true positive result}) + P(\\text{false positive result})}\\]\n\\[P(\\text{true positive result}) = P(\\text{H is true}) * Power\\]\n\\[P(\\text{false positive result}) = (1 - P(\\text{H is true})) * \\alpha\\]\nWe don’t know \\(P(\\text{H is true})\\)! But we can assume how likely it is for the specific research field…\n. . .\nPPV App\n\n\n\nEffect sizes estimated from a significant result are usually an overestimate of the true effect size!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(cowplot)\n\n\nAttache Paket: 'cowplot'\n\nDas folgende Objekt ist maskiert 'package:lubridate':\n\n    stamp\n\ntrueEffectSize=0.2\ndfCurse=data.frame(sampSize=seq(20,300,20)) %&gt;%\n  mutate(effectSize=trueEffectSize,\n         alpha=0.05)\nsimCurse = function(df,nruns=1000){\n  sigResults=0\n  sigEffects=c()\n  for (i in 1:nruns){\n    tmpData=rnorm(df$sampSize,mean=df$effectSize,sd=1)\n    ttestResult=t.test(tmpData)\n    if (ttestResult$p.value&lt;df$alpha){\n      sigResults = sigResults + 1\n      sigEffects=c(sigEffects,ttestResult$estimate)\n    }\n  }\n  df$power=sigResults/nruns\n  df$effectSizeEstimate=mean(sigEffects)\n  return(df)\n}\ndfCurse = dfCurse %&gt;% group_by(sampSize) %&gt;% do(simCurse(.))\np1 &lt;- ggplot(dfCurse,aes(power,effectSizeEstimate)) +\n  geom_line(size=1) +\n  ylim(0,max(dfCurse$effectSizeEstimate)*1.2) +\n  geom_hline(yintercept = trueEffectSize,size=1,linetype='dotted',color='red')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# single\nsampSize=60\neffectSize=0.2\nnruns=1000\nalpha=0.05\ndf=data.frame(idx=seq(1,nruns)) %&gt;%\n  mutate(pval=NA,\n         estimate=NA)\nfor (i in 1:nruns){\n  tmpData=rnorm(sampSize,mean=effectSize,sd=1)\n  ttestResult=t.test(tmpData)\n  df$pval[i]=ttestResult$p.value\n  df$estimate[i]=ttestResult$estimate\n}\ndf = df %&gt;%\n  mutate(significant=pval&lt;alpha) %&gt;%\n  group_by(significant)\npower=mean(df$pval&lt;alpha)\nmeanSigEffect=mean(df$estimate[df$pval&lt;alpha])\nmeanTrueEffect=mean(df$estimate)\np2 &lt;- ggplot(df,aes(estimate,fill=significant)) + \n  geom_histogram(bins=50)\nplot_grid(p1, p2)\n\n\n\n\nOn the left, you can see that Effect Sizes are especially overestimated for low-power studies (dotted line is true ES). On the right is a histogram showing effect size estimates for a number of samples from a dataset with sign. results shown in blue/non-sign. in red.\n\nThis shows us that only if power is high and the effect is large will the ES estimate be close to realistic.\n\n\n\n\nBem in “The Compleat Academic: A Career Guide”, (Darley, Zanna, and Roediger 2004)\n\nWhich article should you write? There are two possible articles you can write: (1) the article you planned to write when you designed your study or (2) the article that makes the most sense now that you have seen the results. They are rarely the same, and the correct answer is (2).\n\n. .\nThis is highly problematic!\nHARKing: Hypothesizing After the Results are Known - reframing a post-hoc conclusion as an a priori prediction (in which we have stronger faith). Results –&gt; Theory instead of Theory –&gt; Predictions.\n. . .\n\nAnalyzing data Examine them from every angle. Analyze the sexes separately. Make up new composite indices. If a datum suggests a new hypothesis, try to find further evidence for it elsewhere in the data. If you see dim traces of interesting patterns, try to reorganize the data to bring them into bolder relief. If there are participants you don’t like, or trials, observers, or interviewers who gave you anomalous results,drop them (temporarily). Go on a fishing expedition for something — anything — interesting. No, this is not immoral.\n\n. . .\np-hacking: trying different analyses until one finds a significant result.\n-&gt; Increases false positive rate!\n\nHARKing: moving the goalpost so that it ends up wherever the ball goes. Difficult to disconfirm ideas.\np-hacking:\n\nAnalyze data after every subject, and stop collecting data once p&lt;.05\nAnalyze many different variables, but only report those with p&lt;.05\nCollect many different experimental conditions, but only report those with p&lt;.05\nExclude participants to get p&lt;.05\nTransform the data to get p&lt;.05\n\nAdd publication pressure etc. 7 sins?\n\n\n\n\n\n\n\nThe Research Cycle - and where QRPs play a role"
  },
  {
    "objectID": "W15_RepResearchR.html#how-we-think-science-should-work",
    "href": "W15_RepResearchR.html#how-we-think-science-should-work",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "You have a hypothesis\n\nBranding food with popular characters causes children to choose “healthy” food\n\nYou collect some data\n\nChildren can choose between cookie and apple with either Elmo-sticker or control\n\nYou do statistics (often to test the null hypothesis)\n\n“The preplanned comparison shows Elmo-branded apples were associated with an increase in a child’s selection of an apple over a cookie, from 20.7% to 33.8% (χ2=5.158; P=.02)” (Wansink, Just, and Payne 2012)\n\nYou make a conclusion based on the data\n\nBranding can increase healthy choices in young children…\n\n\n\n. . .\n\n\n\nThe Research Cycle (Munafo et.al., 2017)\n\n\n\n= scientific cycle"
  },
  {
    "objectID": "W15_RepResearchR.html#how-science-sometimes-actually-works",
    "href": "W15_RepResearchR.html#how-science-sometimes-actually-works",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "The example on the last slide summarized a study by Brian Wansink. He was a very popular eating researcher - until in 2017 some researchers looked at his publications more closely and found a lot of inconsistencies and statistical problems. Wansink refused to share the data.\n. . .\nThere was a Buzzfeed article, which reported\n\nThe p-value was 0.06, just shy of the gold standard cutoff of 0.05. It was a “sticking point,” as he put it in a Jan. 7, 2012, email. … “It seems to me it should be lower,” he wrote, attaching a draft. “Do you want to take a look at it and see what you think. If you can get the data, and it needs some tweeking, it would be good to get that one value below .05.” …\n\n. . .\nWansink eventually resigned after a number of his papers had been retracted."
  },
  {
    "objectID": "W15_RepResearchR.html#the-reproducibility-crisis-in-science",
    "href": "W15_RepResearchR.html#the-reproducibility-crisis-in-science",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "In 2015, the paper “Estimating the reproducibility of psychological science”(Open Science Collaboration 2015) was published. It showed that out of 100 published studies with originally 97% significant results, only 37% could be replicated (i.e. were also significant in the replication).\n. . .\nThis was actually predicted already in 2005 in a paper by the (now in-)famous John Ioannidis. In the paper “Why most published research findings are false”, he argued that the use of Null Hypothesis Significance Testing (NHST) will necessarily lead to high levels of false results"
  },
  {
    "objectID": "W15_RepResearchR.html#positive-predictive-value-and-statistical-significance",
    "href": "W15_RepResearchR.html#positive-predictive-value-and-statistical-significance",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "Positive Predictive Value (PPV): Statistically significant findings that are actually true. \\(P(\\text{Effect true |  significant result})\\)!\nType I error/False positives: How many of the statistically significant findings do we expect to be false? Usually 5% if \\(\\alpha=0.05\\).\nType II error/False negatives: How many of the non-significant findings do we expect to actually be true effects? Usually something like \\(\\beta=0.20\\).\nStatistical Power: How likely are we with our study design to actually find a true effect? I.e. if we have a power of 50%, we would only find a true effect at chance level. Power is the inverse of the Type II error: e.g. \\(\\text{power} = 1\\) \\(- \\beta = .80\\).\nWe can increase power with increasing sample size!\n. . .\n\\[PPV = \\frac{P(\\text{true positive result})}{P(\\text{true positive result}) + P(\\text{false positive result})}\\]\n\\[P(\\text{true positive result}) = P(\\text{H is true}) * Power\\]\n\\[P(\\text{false positive result}) = (1 - P(\\text{H is true})) * \\alpha\\]\nWe don’t know \\(P(\\text{H is true})\\)! But we can assume how likely it is for the specific research field…\n. . .\nPPV App"
  },
  {
    "objectID": "W15_RepResearchR.html#the-winners-curse",
    "href": "W15_RepResearchR.html#the-winners-curse",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "Effect sizes estimated from a significant result are usually an overestimate of the true effect size!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(cowplot)\n\n\nAttache Paket: 'cowplot'\n\nDas folgende Objekt ist maskiert 'package:lubridate':\n\n    stamp\n\ntrueEffectSize=0.2\ndfCurse=data.frame(sampSize=seq(20,300,20)) %&gt;%\n  mutate(effectSize=trueEffectSize,\n         alpha=0.05)\nsimCurse = function(df,nruns=1000){\n  sigResults=0\n  sigEffects=c()\n  for (i in 1:nruns){\n    tmpData=rnorm(df$sampSize,mean=df$effectSize,sd=1)\n    ttestResult=t.test(tmpData)\n    if (ttestResult$p.value&lt;df$alpha){\n      sigResults = sigResults + 1\n      sigEffects=c(sigEffects,ttestResult$estimate)\n    }\n  }\n  df$power=sigResults/nruns\n  df$effectSizeEstimate=mean(sigEffects)\n  return(df)\n}\ndfCurse = dfCurse %&gt;% group_by(sampSize) %&gt;% do(simCurse(.))\np1 &lt;- ggplot(dfCurse,aes(power,effectSizeEstimate)) +\n  geom_line(size=1) +\n  ylim(0,max(dfCurse$effectSizeEstimate)*1.2) +\n  geom_hline(yintercept = trueEffectSize,size=1,linetype='dotted',color='red')\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# single\nsampSize=60\neffectSize=0.2\nnruns=1000\nalpha=0.05\ndf=data.frame(idx=seq(1,nruns)) %&gt;%\n  mutate(pval=NA,\n         estimate=NA)\nfor (i in 1:nruns){\n  tmpData=rnorm(sampSize,mean=effectSize,sd=1)\n  ttestResult=t.test(tmpData)\n  df$pval[i]=ttestResult$p.value\n  df$estimate[i]=ttestResult$estimate\n}\ndf = df %&gt;%\n  mutate(significant=pval&lt;alpha) %&gt;%\n  group_by(significant)\npower=mean(df$pval&lt;alpha)\nmeanSigEffect=mean(df$estimate[df$pval&lt;alpha])\nmeanTrueEffect=mean(df$estimate)\np2 &lt;- ggplot(df,aes(estimate,fill=significant)) + \n  geom_histogram(bins=50)\nplot_grid(p1, p2)\n\n\n\n\nOn the left, you can see that Effect Sizes are especially overestimated for low-power studies (dotted line is true ES). On the right is a histogram showing effect size estimates for a number of samples from a dataset with sign. results shown in blue/non-sign. in red.\n\nThis shows us that only if power is high and the effect is large will the ES estimate be close to realistic."
  },
  {
    "objectID": "W15_RepResearchR.html#questionable-research-practices",
    "href": "W15_RepResearchR.html#questionable-research-practices",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "Bem in “The Compleat Academic: A Career Guide”, (Darley, Zanna, and Roediger 2004)\n\nWhich article should you write? There are two possible articles you can write: (1) the article you planned to write when you designed your study or (2) the article that makes the most sense now that you have seen the results. They are rarely the same, and the correct answer is (2).\n\n. .\nThis is highly problematic!\nHARKing: Hypothesizing After the Results are Known - reframing a post-hoc conclusion as an a priori prediction (in which we have stronger faith). Results –&gt; Theory instead of Theory –&gt; Predictions.\n. . .\n\nAnalyzing data Examine them from every angle. Analyze the sexes separately. Make up new composite indices. If a datum suggests a new hypothesis, try to find further evidence for it elsewhere in the data. If you see dim traces of interesting patterns, try to reorganize the data to bring them into bolder relief. If there are participants you don’t like, or trials, observers, or interviewers who gave you anomalous results,drop them (temporarily). Go on a fishing expedition for something — anything — interesting. No, this is not immoral.\n\n. . .\np-hacking: trying different analyses until one finds a significant result.\n-&gt; Increases false positive rate!\n\nHARKing: moving the goalpost so that it ends up wherever the ball goes. Difficult to disconfirm ideas.\np-hacking:\n\nAnalyze data after every subject, and stop collecting data once p&lt;.05\nAnalyze many different variables, but only report those with p&lt;.05\nCollect many different experimental conditions, but only report those with p&lt;.05\nExclude participants to get p&lt;.05\nTransform the data to get p&lt;.05\n\nAdd publication pressure etc. 7 sins?"
  },
  {
    "objectID": "W15_RepResearchR.html#questionable-research-practices-2",
    "href": "W15_RepResearchR.html#questionable-research-practices-2",
    "title": "15 Reproducible Research",
    "section": "",
    "text": "The Research Cycle - and where QRPs play a role"
  },
  {
    "objectID": "W15_RepResearchR.html#preregistration",
    "href": "W15_RepResearchR.html#preregistration",
    "title": "15 Reproducible Research",
    "section": "Preregistration",
    "text": "Preregistration\nOne submits a detailed description of a study (incl. all data analyses) to a trusted, time-stamped repository (osf.io or aspredicted.org).\n-&gt; Provides greater transparency and trust that the analyses are not p-hacked or other QRPs were used.\n-&gt; Resulted in increase in published non-significant findings."
  },
  {
    "objectID": "W15_RepResearchR.html#reproducible-practices",
    "href": "W15_RepResearchR.html#reproducible-practices",
    "title": "15 Reproducible Research",
    "section": "Reproducible Practices",
    "text": "Reproducible Practices\nSimmons, Nelson, and Simonsohn (2011) suggested the following standards for making research more reproducible:\n\n\nAuthors must decide the rule for terminating data collection before data collection begins and report this rule in the article.\nAuthors must collect at least 20 observations per cell or else provide a compelling cost-of-data-collection justification.\nAuthors must list all variables collected in a study.\nAuthors must report all experimental conditions, including failed manipulations.\nIf observations are eliminated, authors must also report what the statistical results are if those observations are included.\nIf an analysis include a covariate, authors must report the statistical results of the analysis without the covariate."
  },
  {
    "objectID": "W15_RepResearchR.html#replication",
    "href": "W15_RepResearchR.html#replication",
    "title": "15 Reproducible Research",
    "section": "Replication",
    "text": "Replication\nOther researchers should be able to perform the same study and obtain the same result.\n. . .\nIt would be a good practice to replicate your own finding in a new (sufficiently powered) sample. Not every replication will be successful (80% power = 1/5 chance of getting a non-significant finding although there is a true effect!).\nA small p-value does not provide stronger evidence for your hypothesis (it is about the probability of the null hypothesis)! (Although a p-value close to .05 is not very strong evidence…)."
  },
  {
    "objectID": "W1_Intro.html",
    "href": "W1_Intro.html",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Who am I?\n. . .\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?\n\n\n\nSurvey (Zoom) + Moodmeter (pick a stamp - top of screen, select annotate…)\nToo many people to have an introduction round!\nI know that you probably don’t know each other yet, there will be some break-out sessions where you can get to know each other a bit (and talk about stats!) ;)\nStats Anxiety: It will be packed, but it will be ok (You can always reach me with questions!)!\n\n\n\n\n\nThese slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\n\n\n\n. . .\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n. . .\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is an option via Zoom\n\n\n. . .\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked in WueCampus):\n\nStatistical Thinking for the 21st Century: https://statsthinking21.github.io/statsthinking21-core-site/index.html\nFor the R part: Fundamentals of Quantitative Analysis: https://psyteachr.github.io/quant-fun-v2/\n\n\n\n\nOnline: Participation, videos, chat…\nOr R Session on Tuesday and video before? Some can’t make it on Wednesdays… (chat or speak out)\nAttendance: If 2x per week sync: max. 3 missed classes, if 1x per week: max. 2 missed classes (unless I know your reasons for missing Wednesdays!) –&gt; if you missed more, I can’t admit you for the exam/report\nThe input and hands-on sessions will be highly based on these two textbooks. You don’t need to read the textbooks, but it will of course help if you either read the chapter before or after the sessions: Repetition is always helpful!\n\n\n\n\n\n\nFrom basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset (exam with pass or fail grading)\n\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy –&gt; so that you can go through the slides afterwards again (but textbook might also be helpful)\n\n\n\n\n. . .\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n. . .\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)\n\nThe first four weeks will be basics, the next 4 will be analyses."
  },
  {
    "objectID": "W1_Intro.html#calendar",
    "href": "W1_Intro.html#calendar",
    "title": "01a Introduction to Biostatistics",
    "section": "",
    "text": "Date\nTopic\nReading\nProject Deadlines\n\n\n\n\n17.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\n\n\n\n24.10.\nProbability\nST21: 4, QF: 4-6\n\n\n\n31.10.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n07.11.\nData Visualization\nQF: 7\n\n\n\n14.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n21.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\n\n\n\n28.11.\nHypothesis Testing\nST21: 9-10\n\n\n\n05.12.\nComparing Means & Categories\nST21: 12, 15\nDataset\n\n\n12.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n19.12.\n(Generalized) Linear Models\nST21: 12-13\nResearch Question & Hypotheses\n\n\n26.12. & 02.01.\nChristmas & New Year’s\n\n\n\n\n09.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n16.01.\nLinear Mixed Models\nST21: 14\n\n\n\n23.01.\nExercises (LMM)\nST21: 14\nAnalysis\n\n\n30.01.\nTroubleshooting Your Report\n\n\n\n\n06.02.\nReproducible Research\nST21: 18\nReport\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)\n\nThe first four weeks will be basics, the next 4 will be analyses."
  }
]